{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPRKzTnlSZ9OSfs37nPjM4i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","active_directory = '/content/drive/MyDrive/Desktop/DP_Finetuning_Harnet_Submission'\n","os.chdir(active_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eymmo6y9JD7u","executionInfo":{"status":"ok","timestamp":1752578395709,"user_tz":-120,"elapsed":20845,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"4c67c08c-5566-4be7-d245-2b0f79d00db1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## IMPORT LIBRARIES"],"metadata":{"id":"dzNlWhrLKslJ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import json\n","import pickle\n","from warnings import filterwarnings\n","from pandas.errors import SettingWithCopyWarning\n","\n","filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n","filterwarnings('ignore', category=UserWarning)"],"metadata":{"id":"G6y8_dI6KsAB","executionInfo":{"status":"ok","timestamp":1752578425232,"user_tz":-120,"elapsed":5655,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## READ SUBJECT FILES"],"metadata":{"id":"8C8j3rF9Ki9p"}},{"cell_type":"markdown","source":["Each of the data-files contains 54 columns per row, the columns contain the following data:\n","\n","-  1 timestamp (s)\n","- 2 activityID (see II.2. for the mapping to the activities)\n","- 3 heart rate (bpm)\n","- 4-20 IMU hand\n","- 21-37 IMU chest\n","- 38-54 IMU ankle\n","\n","The IMU sensory data contains the following columns:\n","\n","- 1 temperature (°C)\n","- 2-4 3D-acceleration data (ms-2), scale: ±16g, resolution: 13-bit\n","-  5-7 3D-acceleration data (ms-2), scale: ±6g, resolution: 13-bit*\n","- 8-10 3D-gyroscope data (rad/s)\n","- 11-13 3D-magnetometer data (μT)\n","- 14-17 orientation (invalid in this data collection)"],"metadata":{"id":"QO9a5LuNLPdL"}},{"cell_type":"markdown","source":["16g acceleration hand -> indexes [4, 5, 6]\n","\n","timestamp -> [0]\n","\n","activity_id -> [1]"],"metadata":{"id":"LZP8FRWEL1tZ"}},{"cell_type":"code","source":["def read_subject_file(file_path:str)->pd.DataFrame:\n","    subject_name = file_path.split('/')[-1].rstrip('.dat')\n","    subject = pd.read_table(file_path, header=None, sep='\\s+')\n","    return subject, subject_name\n","\n","class DataProcessor:\n","  def __init__(self, subject_dataframe:pd.DataFrame, subject_name:str):\n","    self.subject_dataframe = subject_dataframe\n","    self.subject_name = subject_name\n","    self.acc_x_col = 'acc_x'\n","    self.acc_y_col = 'acc_y'\n","    self.acc_z_col = 'acc_z'\n","    self.timestamp = 'timestamp'\n","    self.activity_id = 'activity_id'\n","\n","  def _extract_data(self)->pd.DataFrame:\n","    \"\"\"\n","    Extract the relevant columns from the data\n","    \"\"\"\n","    # timestamp, activity_id, 16g_acc_x, 16g_acc_y, 16g_acc_z\n","    raw_data = self.subject_dataframe.iloc[:, [0, 1, 4, 5, 6]]\n","    raw_data.columns = [self.timestamp , self.activity_id , self.acc_x_col, self.acc_y_col, self.acc_z_col]\n","    return raw_data\n","\n","  def _handle_missing_values(self, data:pd.DataFrame)->pd.DataFrame:\n","    \"\"\"\n","    Used linear interpolation for the acceleration data\n","    \"\"\"\n","    data[self.acc_x_col] = data[self.acc_x_col].interpolate(method='linear', limit_direction='both')\n","    data[self.acc_y_col] = data[self.acc_y_col].interpolate(method='linear', limit_direction='both')\n","    data[self.acc_z_col] = data[self.acc_z_col].interpolate(method='linear', limit_direction='both')\n","    return data\n","\n","  def sorted_timestamps(self, data:pd.DataFrame)->pd.DataFrame:\n","    \"\"\"\n","    Sort the timestamps in ascending order\n","    \"\"\"\n","    data = data.sort_values(by=self.timestamp, ascending=True).reset_index(drop=True)\n","    return data\n","\n","\n","  def downsample_from_100_to_30hz(self, data:pd.DataFrame)->pd.DataFrame:\n","    \"\"\"\n","    Downsample the data from 100Hz to 30Hz\n","    \"\"\"\n","\n","    data_copy = data.copy()\n","    data_copy.set_index(self.timestamp, inplace=True)\n","    data_copy.index = pd.to_timedelta(data_copy.index, unit=\"s\")\n","    data_copy = data_copy.resample('0.0333s').agg({self.activity_id: lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],\n","                                        self.acc_x_col:\"mean\",\n","                                        self.acc_y_col:\"mean\",\n","                                        self.acc_z_col:\"mean\"}).reset_index()\n","    return data_copy\n","\n","\n","def activity_mapping(value:int):\n","  mapping_dict = {\n","        0: \"other\",\n","        1: \"lying\",\n","        2: \"sitting\",\n","        3: \"standing\",\n","        4: \"walking\",\n","        5: \"running\",\n","        6: \"cycling\",\n","        7: \"Nordic walking\",\n","        9: \"watching TV\",\n","        10: \"computer work\",\n","        11: \"car driving\",\n","        12: \"ascending stairs\",\n","        13: \"descending stairs\",\n","        16: \"vacuum cleaning\",\n","        17: \"ironing\",\n","        18: \"folding laundry\",\n","        19: \"house cleaning\",\n","        20: \"playing soccer\",\n","        24: \"rope jumping\"\n","   }\n","  return mapping_dict.get(value, 'Unknown')\n","\n","\n","def create_sliding_windows(dataframe, window_length_sec, sampling_rate_hz, step_duration_sec):\n","  import scipy.stats as stats\n","\n","\n","  N_FEATURES = 3\n","  window_length_samples = int(window_length_sec * sampling_rate_hz)\n","  step_duration_samples = int(step_duration_sec * sampling_rate_hz)\n","  windows = []\n","  labels = []\n","  for i in range(0, len(dataframe)-window_length_samples, step_duration_samples):\n","    x = dataframe['acc_x'].values[i: i + window_length_samples]\n","    y = dataframe['acc_y'].values[i: i + window_length_samples]\n","    z = dataframe['acc_z'].values[i: i + window_length_samples]\n","    window = np.array([x, y, z])\n","    label = dataframe['activity_id'][i: i + window_length_samples]\n","\n","    windows.append(window)\n","    labels.append(label)\n","\n","  windows = np.asarray(windows).reshape(-1, N_FEATURES, window_length_samples, )\n","  labels = np.asarray(labels)\n","\n","  return windows, labels\n","\n","\n","\n","def clean_window_labels(window_X, window_y):\n","  \"\"\"\n","  Remove the windows that have activity id = 0 ratio > 0.5\n","  \"\"\"\n","  clean_window_X = []\n","  clean_window_y = []\n","\n","  for i in range(len(window_y)):\n","    if np.sum(window_y[i] == 0) / len(window_y[i]) < 0.5:\n","      clean_window_X.append(window_X[i])\n","      clean_window_y.append(window_y[i])\n","\n","  clean_window_X = np.array(clean_window_X)\n","  clean_window_y = np.array(clean_window_y)\n","\n","  return clean_window_X, clean_window_y\n","\n","\n","def majority_voting(window_y):\n","  \"\"\"\n","  Most frequent activity id in a window\n","  \"\"\"\n","  from scipy import stats as st\n","\n","  major_window_y = st.mode(window_y, axis=1).mode\n","  return major_window_y\n","\n","\n","def reshaped_windows(window_X, window_y):\n","  \"\"\"\n","  Reshape the windows to fit the model (n_windows, n_features, n_timestamps)\n","  \"\"\"\n","  window_X = window_X.reshape(window_X.shape[0], window_X.shape[2], window_X.shape[1])\n","  window_y = window_y.reshape(window_y.shape[0], )\n","  return window_X, window_y\n","\n","\n","def activity_filter(window_X, window_y):\n","  \"\"\"\n","  Filtering the activities that everybody does. (1, 2, 3, 4, 12, 13, 16, 17)\n","  \"\"\"\n","  filtered_window_X = []\n","  filtered_window_y = []\n","\n","  valid_indices = (\n","            (window_y == 1) | (window_y == 2) | (window_y == 3) | (window_y == 4) | (window_y == 12) | (window_y == 13) | (window_y == 16) | (window_y == 17)\n","        )\n","\n","  filtered_window_X = window_X[valid_indices]\n","  filtered_window_y = window_y[valid_indices]\n","\n","  return filtered_window_X, filtered_window_y\n","\n"],"metadata":{"id":"jXkn2boTOIk6","executionInfo":{"status":"ok","timestamp":1752578448076,"user_tz":-120,"elapsed":40,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["file_dir = 'Protocol'\n","subject_raw_files = os.listdir(file_dir)"],"metadata":{"id":"9I_bcSQThePN","executionInfo":{"status":"ok","timestamp":1752578455173,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["subject_arr_Xs = []\n","subject_arr_ys = []\n","subject_names = []\n","\n","window_length_sec = 10\n","step_duration_sec = 5\n","sampling_rate_hz = 30\n","overlap_ratio = round((100*(window_length_sec-step_duration_sec)/window_length_sec), 2)\n","\n","\n","print(f'WINDOW LENGTH in SAMPLES: {int(window_length_sec * sampling_rate_hz)}')\n","print(f'STEP DURATION in SAMPLES: {int(step_duration_sec * sampling_rate_hz)}')\n","print(f'OVERLAPPING WINDOW RATIO: {overlap_ratio}%')\n","\n","\n","for f in subject_raw_files:\n","  file_path = os.path.join(file_dir, f)\n","  subject, subject_name = read_subject_file(file_path)\n","  if subject_name != 'subject109':\n","    print('-----------------------------------------------------------')\n","    print(f'Data preprocessing is starting for {subject_name}...')\n","    processor = DataProcessor(subject, subject_name)\n","    raw_data = processor._extract_data()\n","\n","    subject_df = processor._handle_missing_values(raw_data)   # Missing axes values are filled by applying linear interpolation\n","    subject_df = processor.sorted_timestamps(subject_df)    # Update if the timestamps is not ascending\n","    downsampled_subject_df = processor.downsample_from_100_to_30hz(subject_df)    # Downsample the data from 100Hz to 30Hz\n","\n","    win_X, win_y = create_sliding_windows(downsampled_subject_df, window_length_sec=window_length_sec, sampling_rate_hz=sampling_rate_hz, step_duration_sec=step_duration_sec)\n","    clean_win_X, clean_win_y = clean_window_labels(win_X, win_y)    # Remove the windows that have activity id = 0 ratio > 0.5\n","    major_win_y = majority_voting(clean_win_y)    # Majority voting for the labels in a window\n","    filtered_window_X, filtered_window_y = activity_filter(clean_win_X, major_win_y)   # Filtering the activities that everybody does. (1, 2, 3, 4, 12, 13, 16, 17)\n","\n","    print(f'Final remaining shapes X: {filtered_window_X.shape}, y: {filtered_window_y.shape}')\n","\n","    subject_arr_Xs.append(filtered_window_X)\n","    subject_arr_ys.append(filtered_window_y)\n","    subject_names.append(subject_name)\n","\n","\n","all_subject_infos = list(zip(subject_names, subject_arr_Xs, subject_arr_ys))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reuKBAhbR8MS","executionInfo":{"status":"ok","timestamp":1752578752285,"user_tz":-120,"elapsed":206018,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"7abe50e5-a1ed-4b46-b7b8-00382038cb44"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["WINDOW LENGTH in SAMPLES: 300\n","STEP DURATION in SAMPLES: 150\n","OVERLAPPING WINDOW RATIO: 50.0%\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject101...\n","Final remaining shapes X: (345, 3, 300), y: (345,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject102...\n","Final remaining shapes X: (373, 3, 300), y: (373,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject103...\n","Final remaining shapes X: (348, 3, 300), y: (348,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject104...\n","Final remaining shapes X: (364, 3, 300), y: (364,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject105...\n","Final remaining shapes X: (379, 3, 300), y: (379,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject106...\n","Final remaining shapes X: (359, 3, 300), y: (359,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject107...\n","Final remaining shapes X: (355, 3, 300), y: (355,)\n","-----------------------------------------------------------\n","Data preprocessing is starting for subject108...\n","Final remaining shapes X: (364, 3, 300), y: (364,)\n"]}]},{"cell_type":"code","source":["activity_dfs = []\n","\n","for sb_n, Xs, ys in all_subject_infos:\n","  print(f'Subject {sb_n}: {np.unique(ys, return_counts=True)}')\n","\n","  subject_activities = np.vectorize(activity_mapping)(ys)\n","  activity_counts = pd.Series(subject_activities).value_counts(normalize=True).reset_index()\n","  activity_counts.columns = ['Activity', 'Ratio']\n","  activity_counts['Ratio'] = activity_counts['Ratio'] * 100\n","  activity_counts['Subject'] = sb_n\n","\n","  activity_dfs.append(activity_counts)\n","\n","final_activity_df = pd.concat(activity_dfs, axis=0, ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OojE4BvZXePd","executionInfo":{"status":"ok","timestamp":1750147556928,"user_tz":-120,"elapsed":28,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"cb49aaa9-d02f-4b41-edeb-0d5494bb106e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Subject subject101: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([55, 47, 43, 45, 33, 29, 46, 47]))\n","Subject subject102: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([47, 45, 51, 65, 34, 31, 42, 58]))\n","Subject subject103: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([44, 57, 41, 58, 21, 30, 41, 56]))\n","Subject subject104: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([47, 51, 50, 64, 33, 29, 40, 50]))\n","Subject subject105: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([48, 53, 45, 64, 29, 25, 49, 66]))\n","Subject subject106: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([46, 46, 49, 51, 27, 22, 42, 76]))\n","Subject subject107: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([51, 25, 51, 67, 36, 22, 43, 60]))\n","Subject subject108: (array([ 1,  2,  3,  4, 12, 13, 16, 17]), array([48, 46, 50, 63, 23, 19, 49, 66]))\n"]}]},{"cell_type":"code","source":["plt.figure(figsize=(14, 6))\n","sns.barplot(data=final_activity_df, x='Activity', y='Ratio', hue='Subject')\n","plt.xlabel('Activity')\n","plt.ylabel('Ratio (%)')\n","plt.title('Activity Id Distribution by Subject')\n","plt.xticks(rotation=45, ha='right')\n","plt.show();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"f7gr0J3UvaDs","executionInfo":{"status":"ok","timestamp":1750147557524,"user_tz":-120,"elapsed":595,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"9ac5e5d8-43df-4b73-ce4f-248de24eb7aa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1400x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","def get_pretrained_harnet(class_num, model_name = 'harnet10'):\n","    repo = 'OxWearables/ssl-wearables'\n","    model = torch.hub.load(repo, model_name, class_num=class_num, pretrained=True, force_reload=True)\n","    return model\n","\n","def train(model, train_loader, optimizer, criterion, epoch, device, is_dp=False, privacy_engine=None, delta=None):\n","  model.train()\n","  total_loss = 0\n","  correct = 0\n","  total_samples = 0\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","      data, target = data.to(device), target.to(device)\n","      optimizer.zero_grad()\n","      output = model(data)\n","      loss = criterion(output, target)\n","      loss.backward()\n","      optimizer.step()\n","      total_loss += loss.item() * data.size(0)\n","      pred = output.argmax(dim=1, keepdim=True)\n","      correct += pred.eq(target.view_as(pred)).sum().item()\n","      total_samples += data.size(0)\n","      if batch_idx % 10 == 0:\n","          if is_dp and privacy_engine:\n","              epsilon = privacy_engine.get_epsilon(delta)\n","              print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n","                    f\"({100. * batch_idx / len(train_loader):.0f}%)]\\t\"\n","                    f\"Loss: {loss.item():.6f}\\tEpsilon: {epsilon:.2f}\")\n","          else:\n","              print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n","                    f\"({100. * batch_idx / len(train_loader):.0f}%)]\\t\"\n","                    f\"Loss: {loss.item():.6f}\")\n","\n","  avg_loss = total_loss / total_samples\n","  accuracy = 100. * correct / total_samples\n","  print(f\"Epoch {epoch} - Training: Average loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n","  return avg_loss, accuracy\n","\n","\n","def evaluate(model, test_loader, criterion, device):\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  all_preds = []\n","  all_targets = []\n","  with torch.no_grad():\n","      for data, target in test_loader:\n","          data, target = data.to(device), target.to(device)\n","          output = model(data)\n","          test_loss += criterion(output, target).item() * data.size(0)\n","          pred = output.argmax(dim=1, keepdim=True)\n","          correct += pred.eq(target.view_as(pred)).sum().item()\n","          all_preds.extend(pred.cpu().numpy())\n","          all_targets.extend(target.cpu().numpy())\n","  test_loss /= len(test_loader.dataset)\n","  accuracy = 100. * correct / len(test_loader.dataset)\n","  f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n","  print(f\"Evaluation set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} \"\n","        f\"({accuracy:.2f}%), F1-score: {f1:.4f}\\n\")\n","  return test_loss, accuracy, f1\n","\n","\n","class CustomScaler:\n","  \"\"\"\n","  A wrapper for scikit-learn's StandardScaler that handles both 2D and 3D NumPy arrays.\n","  For 3D data, it reshapes to 2D, scales, and then reshapes back.\n","  \"\"\"\n","  def __init__(self):\n","      self._scaler = StandardScaler()\n","      self._is_fitted = False\n","      self._original_input_dims = None # To store the dimensionality of data it was fit on\n","  def fit(self, data: np.ndarray):\n","      self._original_input_dims = data.ndim\n","      if self._original_input_dims == 2:\n","          self._scaler.fit(data)\n","      elif self._original_input_dims == 3:\n","          n_samples, n_timesteps, n_features = data.shape\n","          reshaped_data = data.reshape((n_samples * n_timesteps, n_features))\n","          self._scaler.fit(reshaped_data)\n","      else:\n","          raise ValueError(\"Input data must have 2 or 3 dimensions for scaling.\")\n","      self._is_fitted = True\n","      return self\n","  def fit_transform(self, data: np.ndarray) -> np.ndarray:\n","      self._original_input_dims = data.ndim\n","\n","      if self._original_input_dims == 2:\n","          scaled_data = self._scaler.fit_transform(data)\n","      elif self._original_input_dims == 3:\n","          n_samples, n_timesteps, n_features = data.shape\n","          # Reshape 3D data to 2D for scaling\n","          reshaped_data = data.reshape((n_samples * n_timesteps, n_features))\n","          scaled_reshaped_data = self._scaler.fit_transform(reshaped_data)\n","          # Reshape scaled data back to original 3D shape\n","          scaled_data = scaled_reshaped_data.reshape((n_samples, n_timesteps, n_features))\n","      else:\n","          raise ValueError(\"Input data must have 2 or 3 dimensions for scaling.\")\n","\n","      self._is_fitted = True\n","      return scaled_data\n","\n","  def transform(self, data: np.ndarray) -> np.ndarray:\n","    if not self._is_fitted:\n","      raise RuntimeError(\"Scaler has not been fitted. Call fit_transform first.\")\n","    if data.ndim != self._original_input_dims:\n","      raise ValueError(f\"Input data has {data.ndim} dimensions, but scaler was fitted on \"\n","                            f\"data with {self._original_input_dims} dimensions.\")\n","    if self._original_input_dims == 2:\n","        scaled_data = self._scaler.transform(data)\n","    elif self._original_input_dims == 3:\n","        n_samples, n_timesteps, n_features = data.shape\n","        reshaped_data = data.reshape((n_samples * n_timesteps, n_features))\n","        scaled_reshaped_data = self._scaler.transform(reshaped_data)\n","        scaled_data = scaled_reshaped_data.reshape((n_samples, n_timesteps, n_features))\n","    else:\n","        raise ValueError(\"Input data must have 2 or 3 dimensions.\")\n","\n","    return scaled_data\n","\n","def get_data_loader(X_test, y_test, BATCH_SIZE, shuffle=False):\n","  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","  y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","  test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","  test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=shuffle)\n","  return test_loader\n","\n","class EarlyStopping:\n","  def __init__(self, patience=5, delta=0, verbose=False):\n","      self.patience = patience\n","      self.delta = delta\n","      self.best_score = None\n","      self.early_stop = False\n","      self.counter = 0\n","      self.best_model_state = None\n","      self.verbose = verbose\n","      self.best_epoch = 0\n","  def __call__(self, val_loss, model, epoch):\n","      score = -val_loss\n","      if self.best_score is None:\n","          self.best_score = score\n","          self.best_model_state = copy.deepcopy(model.state_dict())\n","          self.best_epoch = epoch\n","      elif score < self.best_score + self.delta:\n","          self.counter += 1\n","          if self.verbose:\n","              print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","          if self.counter >= self.patience:\n","              self.early_stop = True\n","      else:\n","          self.best_score = score\n","          self.best_model_state = copy.deepcopy(model.state_dict())\n","          self.best_epoch = epoch\n","          self.counter = 0\n","\n","  def load_best_model(self, model):\n","      if self.best_model_state:\n","          model.load_state_dict(self.best_model_state)\n","\n","\n","\n","def plot_distribution(arr:np.ndarray, title:str):\n","  pd.Series(arr).value_counts(normalize=True).plot(kind='bar')\n","  plt.title(title)\n","  plt.show()\n"],"metadata":{"id":"1-w4mckSNfRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fold_plot(fold_train_accuracies, fold_val_accuracies, val_subjects):\n","  import matplotlib.pyplot as plt\n","  import math\n","  # Get the list of train and val accuracies\n","  acc_list_zipped = list(zip(fold_train_accuracies, fold_val_accuracies, val_subjects))\n","\n","  # Get the total number of folds to plot\n","  num_folds = len(acc_list_zipped)\n","\n","  # --- Subplot Layout Calculation ---\n","  ncols = 2\n","  nrows = math.ceil(num_folds / ncols)\n","\n","  # --- Create the Figure and Subplots ---\n","  fig, axes = plt.subplots(nrows, ncols, figsize=(14, 5 * nrows))\n","  fig.suptitle('Training vs. Validation Accuracy Across Folds', fontsize=16, y=1.02)\n","  axes = axes.flatten()\n","\n","\n","  # --- Loop and Plot on Each Subplot ---\n","  for i, (tr_acc, vl_acc, vl_subjects) in enumerate(acc_list_zipped):\n","      ax = axes[i] # Get the current axis\n","      ax.plot(tr_acc, label='Train Accuracy', color='royalblue')\n","      ax.plot(vl_acc, label='Validation Accuracy', color='darkorange')\n","      ax.set_title(f'Fold: {i + 1} for  Validation Subjects {vl_subjects}')\n","      ax.set_xlabel('Epoch')\n","      ax.set_ylabel('Accuracy')\n","      ax.legend()\n","      ax.grid(True, linestyle='--', alpha=0.6)\n","\n","  # --- Clean Up and Display ---\n","  # If the number of folds is odd, the last subplot in the grid will be empty.\n","  # This loop hides any unused subplots.\n","  for i in range(num_folds, len(axes)):\n","      axes[i].axis('off')\n","\n","  # Adjusts subplot params so that subplots are nicely fit in the figure.\n","  fig.tight_layout(rect=[0, 0, 1, 0.98])\n","\n","  return fig\n","\n","\n","def plot_epochs(train_accs, val_accs, val_subj):\n","  import matplotlib.pyplot as plt\n","  epochs = np.arange(1, len(train_accs) + 1)\n","  fig, ax = plt.subplots()\n","  ax.plot(epochs, train_accs, label='Train Accuracy', color='royalblue')\n","  ax.plot(epochs, val_accs, label='Validation Accuracy', color='darkorange')\n","  ax.set_title(f'Training vs. Validation Accuracy for Validation Subjects {val_subj}')\n","  ax.set_xlabel('Epoch')\n","  ax.set_ylabel('Accuracy')\n","  ax.set_xticks(epochs)\n","  ax.legend()\n","  ax.grid(True, linestyle='--', alpha=0.6)\n","  return fig\n","\n","\n","def remove_module_prefix(state_dict):\n","    return {k.replace(\"_module.\", \"\"): v for k, v in state_dict.items()}\n"],"metadata":{"id":"lInWCAAv36dq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## FINE TUNING of CLASSIFIER HEADS\n","\n"],"metadata":{"id":"_LyIbpV_kgOC"}},{"cell_type":"code","source":["#%pip install opacus"],"metadata":{"id":"nj_qXZ8dR9eX","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import datetime as dt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold, LeaveOneGroupOut\n","import torch.nn as nn\n","import copy\n","from itertools import product\n","from opacus import PrivacyEngine\n","from opacus.accountants.utils import get_noise_multiplier\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","label_encoder = LabelEncoder()\n","\n","reports_save = True\n","\n","X_combined = []\n","y_combined = []\n","subject_groups_combined = []\n","\n","for sb_name, Xs, ys in all_subject_infos:\n","  X_combined.extend(Xs)\n","  y_combined.extend(ys)\n","  subject_groups_combined.extend([sb_name] * len(ys))\n","\n","X_combined = np.array(X_combined)\n","y_combined = np.array(y_combined)\n","subject_groups_combined = np.array(subject_groups_combined)\n","\n","label_encoder.fit(y_combined)\n","encoded_y_combined_raw = label_encoder.transform(y_combined)\n","\n","# Considering acitivities distribution\n","outer_skf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","\n","EPOCHS = 20\n","BATCH_SIZE_LIST = [32]\n","LRATE_LIST = [1e-3]\n","\n","\n","parameter_pairs = list(product(BATCH_SIZE_LIST, LRATE_LIST))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","N_CLASSES = len(label_encoder.classes_)\n","g_noise_multp = 1.0\n","C_value = 1.0\n","noise_scale = g_noise_multp * C_value\n","DELTA = 1e-5\n","\n","print(f'Noise scale: {noise_scale}')\n","\n","for BATCH_SIZE, LRATE in parameter_pairs:\n","  print('-------------------------------------------------------------------------------------------------')\n","  print(f'Batch size: {BATCH_SIZE}, Learning rate: {LRATE}')\n","  print('-------------------------------------------------------------------------------------------------')\n","\n","  test_outer_subject_list = []\n","  test_outer_losses = []\n","  test_outer_accuracies = []\n","  test_outer_f1s = []\n","  best_fold_train_losses = []\n","  best_fold_val_losses = []\n","  best_fold_val_f1s = []\n","  best_fold_train_accuracies = []\n","  best_fold_val_accuracies = []\n","  best_fold_epochs = []\n","  l_rates = []\n","  batch_sizes = []\n","  fold_details = {\"Test Subjects\": [], \"Batch_Size\": BATCH_SIZE, \"Learning_Rate\": LRATE, \"Epoch_Results\": []}\n","  for outer_fold, (train_outer_index, test_outer_index) in enumerate(outer_skf.split(X_combined, encoded_y_combined_raw, subject_groups_combined), start=1):\n","    print(f'Outer Fold {outer_fold} is starting ...')\n","    X_outer_train_val, X_outer_test = X_combined[train_outer_index], X_combined[test_outer_index]\n","    y_outer_train_val, y_outer_test = encoded_y_combined_raw[train_outer_index], encoded_y_combined_raw[test_outer_index]\n","\n","    train_val_subject_groups = subject_groups_combined[train_outer_index]\n","\n","    test_outer_subjects = np.unique(subject_groups_combined[test_outer_index] )\n","    train_outer_subjects = np.unique(train_val_subject_groups)\n","\n","    print(f'Test subjects: {test_outer_subjects}')\n","    print(f'Train-Validation subjects: {train_outer_subjects}')\n","\n","    # Leave One Group Out for inner fold\n","    inner_skf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n","\n","    fold_val_subjects = []\n","    fold_train_subjects = []\n","    fold_train_losses = []\n","    fold_val_losses = []\n","    fold_train_accuracies = []\n","    fold_val_accuracies = []\n","    fold_epochs = []\n","    fold_best_epochs = []\n","    fold_f1_scores = []\n","\n","    for fold, (train_index, val_index) in enumerate(inner_skf.split(X_outer_train_val, y_outer_train_val, train_val_subject_groups), start=1):\n","      print(f'Fold {fold} is starting ...')\n","\n","      X_train, X_val = X_outer_train_val[train_index], X_outer_train_val[val_index]\n","      y_train, y_val = y_outer_train_val[train_index], y_outer_train_val[val_index]\n","\n","      val_subjects = np.unique(train_val_subject_groups[val_index])\n","      train_subjects = np.unique(train_val_subject_groups[train_index])\n","      print(f'Validation subjects : {val_subjects}')\n","      print(f'Train subjects: {train_subjects}')\n","\n","      scaler = CustomScaler()\n","      scaled_X_train = scaler.fit_transform(X_train)\n","      scaled_X_val = scaler.transform(X_val)\n","\n","      train_data_loader = get_data_loader(scaled_X_train, y_train, BATCH_SIZE=BATCH_SIZE, shuffle=True)\n","      val_data_loader = get_data_loader(scaled_X_val, y_val, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n","\n","      model = get_pretrained_harnet(class_num=N_CLASSES, model_name='harnet10')\n","      model.to(device)\n","\n","      for name, param in model.named_parameters():\n","        if name.startswith('classifier'):\n","          param.requires_grad = True\n","        else:\n","          param.requires_grad = False\n","\n","      optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LRATE, weight_decay=0.01)\n","      criterion = nn.CrossEntropyLoss()\n","      early_stopping = EarlyStopping(patience=10, verbose=True)\n","      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n","      privacy_engine = PrivacyEngine(secure_mode=False)\n","      model, optimizer, train_data_loader = privacy_engine.make_private(\n","          module=model,\n","          optimizer=optimizer,\n","          data_loader=train_data_loader,\n","          noise_multiplier=g_noise_multp,\n","          max_grad_norm=C_value\n","      )\n","\n","      val_losses = []\n","      val_accuracies = []\n","      val_f1s = []\n","      train_losses = []\n","      train_accuracies = []\n","      epochs_list = []\n","\n","      epoch_results = {\"epoch\": [], \"val_subjects\":val_subjects, \"noise_scale\":[], \"achieved_epsilon\": [],\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n","      best_val_loss = float('inf')\n","      best_model_state = None\n","      best_scaler = None\n","      best_epoch = None\n","      for epoch in range(1, EPOCHS + 1):\n","        train_loss, train_acc = train(model, train_data_loader, optimizer, criterion, epoch, device)\n","        val_loss, val_acc, val_f1 = evaluate(model, val_data_loader, criterion, device)\n","\n","        scheduler.step(val_loss)\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_acc)\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_acc)\n","        val_f1s.append(val_f1)\n","        epochs_list.append(epoch)\n","\n","        a_epsilon = round(privacy_engine.get_epsilon(DELTA), 3)\n","        epoch_results[\"noise_scale\"].append(noise_scale)\n","        epoch_results[\"achieved_epsilon\"].append(a_epsilon)\n","        print(f'Epsilon Spent: {a_epsilon}, Noise_Scale: {noise_scale}')\n","\n","        epoch_results[\"epoch\"].append(epoch)\n","        epoch_results[\"train_loss\"].append(train_loss)\n","        epoch_results[\"train_acc\"].append(train_acc)\n","        epoch_results[\"val_loss\"].append(val_loss)\n","        epoch_results[\"val_acc\"].append(val_acc)\n","        epoch_results[\"val_f1\"].append(val_f1)\n","\n","        if val_loss < best_val_loss:\n","          best_val_loss = val_loss\n","          best_model_state = copy.deepcopy(model.state_dict())\n","          best_epoch = epoch\n","          best_scaler = copy.deepcopy(scaler)\n","\n","        early_stopping(val_loss, model, epoch)\n","        if early_stopping.early_stop:\n","          print(\"Early stopping\")\n","          break\n","\n","      # Scores are added based on the best epoch considering early stopping to prevent overfitting\n","      best_epoch_index = best_epoch - 1   # Since epoch loop starts with 1\n","\n","      # TEST SUBJECTS EVALUATION\n","      print(f' #### Test Evaluation is starting for {test_outer_subjects} #### ')\n","      final_val_model = get_pretrained_harnet(class_num=N_CLASSES, model_name='harnet10')\n","      final_val_model.load_state_dict(remove_module_prefix(best_model_state))\n","      final_val_model.to(device)\n","\n","      scaled_X_outer_test = best_scaler.transform(X_outer_test)\n","      test_data_loader = get_data_loader(scaled_X_outer_test, y_outer_test, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n","      test_loss, test_acc, test_f1 = evaluate(final_val_model, test_data_loader, criterion, device)\n","\n","      test_outer_subject_list.append(test_outer_subjects)\n","      test_outer_losses.append(test_loss)\n","      test_outer_accuracies.append(test_acc)\n","      test_outer_f1s.append(test_f1)\n","      best_fold_train_losses.append(train_losses[best_epoch_index])\n","      best_fold_val_losses.append(val_losses[best_epoch_index])\n","      best_fold_val_f1s.append(val_f1s[best_epoch_index])\n","      best_fold_train_accuracies.append(train_accuracies[best_epoch_index])\n","      best_fold_val_accuracies.append(val_accuracies[best_epoch_index])\n","      best_fold_epochs.append(epochs_list[best_epoch_index])\n","      fold_train_subjects.append(train_subjects)\n","      fold_val_subjects.append(val_subjects)\n","      fold_details['Test Subjects'].append(test_outer_subjects)\n","      fold_details['Epoch_Results'].append(epoch_results)\n","      batch_sizes.append(BATCH_SIZE)\n","      l_rates.append(LRATE)\n","\n","\n","directory_name = 'downsampled_results_DP'\n","os.makedirs(directory_name, exist_ok=True)\n","\n","\n","today_time = dt.date.today().strftime(\"%Y%m%d\")\n","vers = f'{window_length_sec}_{sampling_rate_hz}_{overlap_ratio}_{today_time}'\n","\n","fold_details_df = pd.DataFrame(fold_details)\n","\n","summary_df = pd.DataFrame({'Test_Subjects':test_outer_subject_list,\n","                           \"Test_Losses\":test_outer_losses,\n","                           \"Best_Val_Losses\":best_fold_val_losses,\n","                           \"Best_Train_Losses\":best_fold_train_losses,\n","                           \"Test_Accuracies\":test_outer_accuracies,\n","                           \"Best_Val_Accuracies\":best_fold_val_accuracies,\n","                           \"Best_Train_Accuracies\":best_fold_train_accuracies,\n","                           \"Test_F1s\":test_outer_f1s,\n","                           \"Best_Val_F1s\":best_fold_val_f1s,\n","                           \"Best_Val_Epochs\":best_fold_epochs,\n","                           \"Batch_Size\":batch_sizes,\n","                           \"Learning_Rate\":l_rates\n","                           })\n","\n","if reports_save:\n","  fold_details_df.to_csv(f'{directory_name}/fold_details_DP_CH_NS_{noise_scale}_{vers}_Split_4-2-2.csv')\n","  summary_df.to_csv(f'{directory_name}/summary_df_DP_CH_NS_{noise_scale}_{vers}_Split_4-2-2.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvk8tBk0I61W","executionInfo":{"status":"ok","timestamp":1750147241518,"user_tz":-120,"elapsed":395428,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"20ffd7ec-fd5b-46ec-f1a2-1441922da5c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Noise scale: 10.0\n","-------------------------------------------------------------------------------------------------\n","Batch size: 32, Learning rate: 0.001\n","-------------------------------------------------------------------------------------------------\n","Outer Fold 1 is starting ...\n","Test subjects: ['subject102' 'subject107']\n","Train-Validation subjects: ['subject101' 'subject103' 'subject104' 'subject105' 'subject106'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject104' 'subject105']\n","Train subjects: ['subject101' 'subject103' 'subject106' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1416 (0%)]\tLoss: 8.127763\n","Train Epoch: 1 [240/1416 (22%)]\tLoss: 9.218986\n","Train Epoch: 1 [580/1416 (44%)]\tLoss: 7.798280\n","Train Epoch: 1 [1050/1416 (67%)]\tLoss: 9.284518\n","Train Epoch: 1 [1440/1416 (89%)]\tLoss: 8.501242\n","Epoch 1 - Training: Average loss: 8.0615, Accuracy: 12.46%\n","Evaluation set: Average loss: 8.1701, Accuracy: 101/743 (13.59%), F1-score: 0.0988\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1416 (0%)]\tLoss: 5.793286\n","Train Epoch: 2 [270/1416 (22%)]\tLoss: 7.129116\n","Train Epoch: 2 [680/1416 (44%)]\tLoss: 6.771901\n","Train Epoch: 2 [930/1416 (67%)]\tLoss: 5.278381\n","Train Epoch: 2 [960/1416 (89%)]\tLoss: 6.672423\n","Epoch 2 - Training: Average loss: 7.1245, Accuracy: 15.36%\n","Evaluation set: Average loss: 7.9103, Accuracy: 133/743 (17.90%), F1-score: 0.1360\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1416 (0%)]\tLoss: 6.627154\n","Train Epoch: 3 [310/1416 (22%)]\tLoss: 6.185396\n","Train Epoch: 3 [720/1416 (44%)]\tLoss: 6.729771\n","Train Epoch: 3 [600/1416 (67%)]\tLoss: 5.016844\n","Train Epoch: 3 [1160/1416 (89%)]\tLoss: 5.537337\n","Epoch 3 - Training: Average loss: 6.4322, Accuracy: 18.25%\n","Evaluation set: Average loss: 7.2209, Accuracy: 146/743 (19.65%), F1-score: 0.1463\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1416 (0%)]\tLoss: 6.883389\n","Train Epoch: 4 [280/1416 (22%)]\tLoss: 7.433086\n","Train Epoch: 4 [580/1416 (44%)]\tLoss: 7.072057\n","Train Epoch: 4 [810/1416 (67%)]\tLoss: 6.688809\n","Train Epoch: 4 [1040/1416 (89%)]\tLoss: 6.636332\n","Epoch 4 - Training: Average loss: 6.6891, Accuracy: 18.51%\n","Evaluation set: Average loss: 7.0764, Accuracy: 153/743 (20.59%), F1-score: 0.1476\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1416 (0%)]\tLoss: 7.337355\n","Train Epoch: 5 [300/1416 (22%)]\tLoss: 7.497465\n","Train Epoch: 5 [600/1416 (44%)]\tLoss: 6.560977\n","Train Epoch: 5 [990/1416 (67%)]\tLoss: 6.629341\n","Train Epoch: 5 [1320/1416 (89%)]\tLoss: 5.996084\n","Epoch 5 - Training: Average loss: 6.4032, Accuracy: 18.71%\n","Evaluation set: Average loss: 6.5987, Accuracy: 147/743 (19.78%), F1-score: 0.1444\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1416 (0%)]\tLoss: 5.378116\n","Train Epoch: 6 [340/1416 (22%)]\tLoss: 6.541409\n","Train Epoch: 6 [780/1416 (44%)]\tLoss: 7.024357\n","Train Epoch: 6 [1050/1416 (67%)]\tLoss: 6.551267\n","Train Epoch: 6 [1440/1416 (89%)]\tLoss: 6.661532\n","Epoch 6 - Training: Average loss: 6.3458, Accuracy: 20.62%\n","Evaluation set: Average loss: 7.1760, Accuracy: 144/743 (19.38%), F1-score: 0.1459\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 7 [0/1416 (0%)]\tLoss: 5.256187\n","Train Epoch: 7 [330/1416 (22%)]\tLoss: 7.164982\n","Train Epoch: 7 [720/1416 (44%)]\tLoss: 5.358345\n","Train Epoch: 7 [990/1416 (67%)]\tLoss: 5.493872\n","Train Epoch: 7 [1160/1416 (89%)]\tLoss: 6.275689\n","Epoch 7 - Training: Average loss: 5.9655, Accuracy: 23.14%\n","Evaluation set: Average loss: 6.4569, Accuracy: 159/743 (21.40%), F1-score: 0.1677\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1416 (0%)]\tLoss: 6.117139\n","Train Epoch: 8 [330/1416 (22%)]\tLoss: 7.182091\n","Train Epoch: 8 [880/1416 (44%)]\tLoss: 5.512607\n","Train Epoch: 8 [990/1416 (67%)]\tLoss: 5.981698\n","Train Epoch: 8 [1240/1416 (89%)]\tLoss: 4.494243\n","Epoch 8 - Training: Average loss: 5.7516, Accuracy: 23.67%\n","Evaluation set: Average loss: 6.5444, Accuracy: 171/743 (23.01%), F1-score: 0.1841\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1416 (0%)]\tLoss: 5.550714\n","Train Epoch: 9 [230/1416 (22%)]\tLoss: 5.080528\n","Train Epoch: 9 [540/1416 (44%)]\tLoss: 6.360313\n","Train Epoch: 9 [810/1416 (67%)]\tLoss: 6.106340\n","Train Epoch: 9 [920/1416 (89%)]\tLoss: 7.359107\n","Epoch 9 - Training: Average loss: 5.8505, Accuracy: 23.50%\n","Evaluation set: Average loss: 6.3686, Accuracy: 186/743 (25.03%), F1-score: 0.1974\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1416 (0%)]\tLoss: 6.534767\n","Train Epoch: 10 [320/1416 (22%)]\tLoss: 5.426717\n","Train Epoch: 10 [580/1416 (44%)]\tLoss: 5.672402\n","Train Epoch: 10 [600/1416 (67%)]\tLoss: 5.396361\n","Train Epoch: 10 [1240/1416 (89%)]\tLoss: 4.644615\n","Epoch 10 - Training: Average loss: 5.3827, Accuracy: 26.10%\n","Evaluation set: Average loss: 5.7555, Accuracy: 190/743 (25.57%), F1-score: 0.2081\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1416 (0%)]\tLoss: 5.239501\n","Train Epoch: 11 [290/1416 (22%)]\tLoss: 7.978919\n","Train Epoch: 11 [640/1416 (44%)]\tLoss: 5.310856\n","Train Epoch: 11 [660/1416 (67%)]\tLoss: 5.180986\n","Train Epoch: 11 [1160/1416 (89%)]\tLoss: 5.934928\n","Epoch 11 - Training: Average loss: 5.0878, Accuracy: 26.59%\n","Evaluation set: Average loss: 5.7230, Accuracy: 184/743 (24.76%), F1-score: 0.2071\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1416 (0%)]\tLoss: 5.961968\n","Train Epoch: 12 [290/1416 (22%)]\tLoss: 5.523293\n","Train Epoch: 12 [740/1416 (44%)]\tLoss: 4.860808\n","Train Epoch: 12 [1170/1416 (67%)]\tLoss: 6.151800\n","Train Epoch: 12 [1440/1416 (89%)]\tLoss: 5.047041\n","Epoch 12 - Training: Average loss: 4.9877, Accuracy: 27.45%\n","Evaluation set: Average loss: 5.6664, Accuracy: 190/743 (25.57%), F1-score: 0.2062\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1416 (0%)]\tLoss: 6.420935\n","Train Epoch: 13 [210/1416 (22%)]\tLoss: 5.144331\n","Train Epoch: 13 [580/1416 (44%)]\tLoss: 4.201925\n","Train Epoch: 13 [900/1416 (67%)]\tLoss: 4.138913\n","Train Epoch: 13 [1520/1416 (89%)]\tLoss: 4.100224\n","Epoch 13 - Training: Average loss: 4.9585, Accuracy: 27.23%\n","Evaluation set: Average loss: 5.3476, Accuracy: 196/743 (26.38%), F1-score: 0.2121\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1416 (0%)]\tLoss: 3.821317\n","Train Epoch: 14 [380/1416 (22%)]\tLoss: 4.980258\n","Train Epoch: 14 [700/1416 (44%)]\tLoss: 5.073433\n","Train Epoch: 14 [780/1416 (67%)]\tLoss: 5.613385\n","Train Epoch: 14 [1120/1416 (89%)]\tLoss: 5.571674\n","Epoch 14 - Training: Average loss: 4.6184, Accuracy: 28.91%\n","Evaluation set: Average loss: 4.9941, Accuracy: 227/743 (30.55%), F1-score: 0.2369\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1416 (0%)]\tLoss: 4.122789\n","Train Epoch: 15 [290/1416 (22%)]\tLoss: 5.299893\n","Train Epoch: 15 [480/1416 (44%)]\tLoss: 3.955233\n","Train Epoch: 15 [960/1416 (67%)]\tLoss: 4.147265\n","Train Epoch: 15 [1640/1416 (89%)]\tLoss: 4.651581\n","Epoch 15 - Training: Average loss: 4.3418, Accuracy: 32.50%\n","Evaluation set: Average loss: 5.1038, Accuracy: 208/743 (27.99%), F1-score: 0.2269\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 16 [0/1416 (0%)]\tLoss: 5.557478\n","Train Epoch: 16 [350/1416 (22%)]\tLoss: 4.932739\n","Train Epoch: 16 [680/1416 (44%)]\tLoss: 4.719938\n","Train Epoch: 16 [1170/1416 (67%)]\tLoss: 5.154626\n","Train Epoch: 16 [1400/1416 (89%)]\tLoss: 4.982738\n","Epoch 16 - Training: Average loss: 4.5572, Accuracy: 31.27%\n","Evaluation set: Average loss: 5.1270, Accuracy: 211/743 (28.40%), F1-score: 0.2243\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 17 [0/1416 (0%)]\tLoss: 3.699260\n","Train Epoch: 17 [350/1416 (22%)]\tLoss: 4.824396\n","Train Epoch: 17 [540/1416 (44%)]\tLoss: 4.655966\n","Train Epoch: 17 [1050/1416 (67%)]\tLoss: 5.487177\n","Train Epoch: 17 [1600/1416 (89%)]\tLoss: 5.222531\n","Epoch 17 - Training: Average loss: 4.5304, Accuracy: 29.78%\n","Evaluation set: Average loss: 5.0328, Accuracy: 236/743 (31.76%), F1-score: 0.2488\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 18 [0/1416 (0%)]\tLoss: 4.877125\n","Train Epoch: 18 [310/1416 (22%)]\tLoss: 4.607172\n","Train Epoch: 18 [640/1416 (44%)]\tLoss: 3.189217\n","Train Epoch: 18 [840/1416 (67%)]\tLoss: 5.164378\n","Train Epoch: 18 [1200/1416 (89%)]\tLoss: 5.442563\n","Epoch 18 - Training: Average loss: 4.2290, Accuracy: 33.93%\n","Evaluation set: Average loss: 4.7357, Accuracy: 239/743 (32.17%), F1-score: 0.2577\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1416 (0%)]\tLoss: 5.423645\n","Train Epoch: 19 [290/1416 (22%)]\tLoss: 3.001801\n","Train Epoch: 19 [540/1416 (44%)]\tLoss: 4.728996\n","Train Epoch: 19 [990/1416 (67%)]\tLoss: 4.274727\n","Train Epoch: 19 [1440/1416 (89%)]\tLoss: 4.062049\n","Epoch 19 - Training: Average loss: 4.1533, Accuracy: 35.79%\n","Evaluation set: Average loss: 4.6170, Accuracy: 244/743 (32.84%), F1-score: 0.2621\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1416 (0%)]\tLoss: 2.554887\n","Train Epoch: 20 [370/1416 (22%)]\tLoss: 5.033238\n","Train Epoch: 20 [800/1416 (44%)]\tLoss: 3.820081\n","Train Epoch: 20 [810/1416 (67%)]\tLoss: 4.499302\n","Train Epoch: 20 [1000/1416 (89%)]\tLoss: 3.522454\n","Epoch 20 - Training: Average loss: 4.0004, Accuracy: 36.14%\n","Evaluation set: Average loss: 4.6554, Accuracy: 237/743 (31.90%), F1-score: 0.2532\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 5.0437, Accuracy: 202/728 (27.75%), F1-score: 0.2552\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject103' 'subject106']\n","Train subjects: ['subject101' 'subject104' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1452 (0%)]\tLoss: 8.249802\n","Train Epoch: 1 [390/1452 (22%)]\tLoss: 9.422999\n","Train Epoch: 1 [720/1452 (43%)]\tLoss: 8.508605\n","Train Epoch: 1 [990/1452 (65%)]\tLoss: 8.945186\n","Train Epoch: 1 [1640/1452 (87%)]\tLoss: 6.846384\n","Epoch 1 - Training: Average loss: 8.4120, Accuracy: 15.35%\n","Evaluation set: Average loss: 7.8218, Accuracy: 164/707 (23.20%), F1-score: 0.1660\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1452 (0%)]\tLoss: 7.509355\n","Train Epoch: 2 [330/1452 (22%)]\tLoss: 9.068376\n","Train Epoch: 2 [620/1452 (43%)]\tLoss: 8.728125\n","Train Epoch: 2 [930/1452 (65%)]\tLoss: 8.956030\n","Train Epoch: 2 [1360/1452 (87%)]\tLoss: 7.832045\n","Epoch 2 - Training: Average loss: 7.7450, Accuracy: 17.46%\n","Evaluation set: Average loss: 7.6439, Accuracy: 163/707 (23.06%), F1-score: 0.1506\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1452 (0%)]\tLoss: 6.858364\n","Train Epoch: 3 [290/1452 (22%)]\tLoss: 7.369998\n","Train Epoch: 3 [880/1452 (43%)]\tLoss: 7.401855\n","Train Epoch: 3 [1080/1452 (65%)]\tLoss: 6.943928\n","Train Epoch: 3 [1040/1452 (87%)]\tLoss: 7.759087\n","Epoch 3 - Training: Average loss: 7.3693, Accuracy: 17.46%\n","Evaluation set: Average loss: 7.1077, Accuracy: 188/707 (26.59%), F1-score: 0.1822\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1452 (0%)]\tLoss: 8.662956\n","Train Epoch: 4 [300/1452 (22%)]\tLoss: 6.137331\n","Train Epoch: 4 [580/1452 (43%)]\tLoss: 7.337694\n","Train Epoch: 4 [1110/1452 (65%)]\tLoss: 7.542575\n","Train Epoch: 4 [1160/1452 (87%)]\tLoss: 4.396621\n","Epoch 4 - Training: Average loss: 6.8289, Accuracy: 21.45%\n","Evaluation set: Average loss: 6.6424, Accuracy: 204/707 (28.85%), F1-score: 0.2056\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1452 (0%)]\tLoss: 6.922669\n","Train Epoch: 5 [280/1452 (22%)]\tLoss: 5.506671\n","Train Epoch: 5 [640/1452 (43%)]\tLoss: 7.123113\n","Train Epoch: 5 [870/1452 (65%)]\tLoss: 6.930820\n","Train Epoch: 5 [1120/1452 (87%)]\tLoss: 6.030685\n","Epoch 5 - Training: Average loss: 6.9763, Accuracy: 23.45%\n","Evaluation set: Average loss: 6.6388, Accuracy: 214/707 (30.27%), F1-score: 0.2178\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1452 (0%)]\tLoss: 6.876700\n","Train Epoch: 6 [260/1452 (22%)]\tLoss: 8.211041\n","Train Epoch: 6 [540/1452 (43%)]\tLoss: 6.680037\n","Train Epoch: 6 [930/1452 (65%)]\tLoss: 7.207044\n","Train Epoch: 6 [1320/1452 (87%)]\tLoss: 6.336576\n","Epoch 6 - Training: Average loss: 6.7697, Accuracy: 24.33%\n","Evaluation set: Average loss: 6.6444, Accuracy: 229/707 (32.39%), F1-score: 0.2386\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 7 [0/1452 (0%)]\tLoss: 6.081994\n","Train Epoch: 7 [320/1452 (22%)]\tLoss: 4.594835\n","Train Epoch: 7 [780/1452 (43%)]\tLoss: 5.601391\n","Train Epoch: 7 [1140/1452 (65%)]\tLoss: 6.724628\n","Train Epoch: 7 [1080/1452 (87%)]\tLoss: 5.920221\n","Epoch 7 - Training: Average loss: 6.5566, Accuracy: 24.89%\n","Evaluation set: Average loss: 6.2421, Accuracy: 233/707 (32.96%), F1-score: 0.2441\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1452 (0%)]\tLoss: 4.539354\n","Train Epoch: 8 [320/1452 (22%)]\tLoss: 5.923225\n","Train Epoch: 8 [600/1452 (43%)]\tLoss: 5.395533\n","Train Epoch: 8 [1260/1452 (65%)]\tLoss: 8.573595\n","Train Epoch: 8 [1240/1452 (87%)]\tLoss: 6.211225\n","Epoch 8 - Training: Average loss: 6.0931, Accuracy: 24.34%\n","Evaluation set: Average loss: 5.9357, Accuracy: 235/707 (33.24%), F1-score: 0.2468\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1452 (0%)]\tLoss: 7.279088\n","Train Epoch: 9 [250/1452 (22%)]\tLoss: 5.197042\n","Train Epoch: 9 [560/1452 (43%)]\tLoss: 8.674237\n","Train Epoch: 9 [900/1452 (65%)]\tLoss: 5.769116\n","Train Epoch: 9 [1240/1452 (87%)]\tLoss: 5.922685\n","Epoch 9 - Training: Average loss: 5.9549, Accuracy: 27.49%\n","Evaluation set: Average loss: 5.8410, Accuracy: 226/707 (31.97%), F1-score: 0.2411\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1452 (0%)]\tLoss: 7.274662\n","Train Epoch: 10 [410/1452 (22%)]\tLoss: 5.784118\n","Train Epoch: 10 [580/1452 (43%)]\tLoss: 5.324465\n","Train Epoch: 10 [1140/1452 (65%)]\tLoss: 6.546351\n","Train Epoch: 10 [1280/1452 (87%)]\tLoss: 4.712850\n","Epoch 10 - Training: Average loss: 5.7767, Accuracy: 27.21%\n","Evaluation set: Average loss: 5.7026, Accuracy: 232/707 (32.81%), F1-score: 0.2500\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1452 (0%)]\tLoss: 7.766648\n","Train Epoch: 11 [380/1452 (22%)]\tLoss: 4.373389\n","Train Epoch: 11 [560/1452 (43%)]\tLoss: 5.970201\n","Train Epoch: 11 [720/1452 (65%)]\tLoss: 4.973472\n","Train Epoch: 11 [1080/1452 (87%)]\tLoss: 4.937951\n","Epoch 11 - Training: Average loss: 5.5905, Accuracy: 27.02%\n","Evaluation set: Average loss: 5.4641, Accuracy: 243/707 (34.37%), F1-score: 0.2679\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1452 (0%)]\tLoss: 4.758581\n","Train Epoch: 12 [230/1452 (22%)]\tLoss: 6.914582\n","Train Epoch: 12 [640/1452 (43%)]\tLoss: 5.056297\n","Train Epoch: 12 [780/1452 (65%)]\tLoss: 5.558050\n","Train Epoch: 12 [1440/1452 (87%)]\tLoss: 5.137488\n","Epoch 12 - Training: Average loss: 5.2847, Accuracy: 31.70%\n","Evaluation set: Average loss: 5.2764, Accuracy: 246/707 (34.79%), F1-score: 0.2642\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1452 (0%)]\tLoss: 4.831340\n","Train Epoch: 13 [380/1452 (22%)]\tLoss: 5.305147\n","Train Epoch: 13 [860/1452 (43%)]\tLoss: 5.042916\n","Train Epoch: 13 [1170/1452 (65%)]\tLoss: 5.744808\n","Train Epoch: 13 [1400/1452 (87%)]\tLoss: 5.267275\n","Epoch 13 - Training: Average loss: 5.2819, Accuracy: 30.66%\n","Evaluation set: Average loss: 5.1204, Accuracy: 255/707 (36.07%), F1-score: 0.2746\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1452 (0%)]\tLoss: 5.236051\n","Train Epoch: 14 [300/1452 (22%)]\tLoss: 5.870969\n","Train Epoch: 14 [620/1452 (43%)]\tLoss: 5.864772\n","Train Epoch: 14 [1110/1452 (65%)]\tLoss: 7.315068\n","Train Epoch: 14 [1320/1452 (87%)]\tLoss: 5.673977\n","Epoch 14 - Training: Average loss: 5.1075, Accuracy: 30.90%\n","Evaluation set: Average loss: 4.8419, Accuracy: 268/707 (37.91%), F1-score: 0.2970\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1452 (0%)]\tLoss: 5.864349\n","Train Epoch: 15 [360/1452 (22%)]\tLoss: 6.485112\n","Train Epoch: 15 [560/1452 (43%)]\tLoss: 4.727729\n","Train Epoch: 15 [1050/1452 (65%)]\tLoss: 5.488652\n","Train Epoch: 15 [680/1452 (87%)]\tLoss: 4.304742\n","Epoch 15 - Training: Average loss: 4.9073, Accuracy: 32.40%\n","Evaluation set: Average loss: 4.4471, Accuracy: 275/707 (38.90%), F1-score: 0.3045\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1452 (0%)]\tLoss: 4.339532\n","Train Epoch: 16 [350/1452 (22%)]\tLoss: 3.945615\n","Train Epoch: 16 [680/1452 (43%)]\tLoss: 5.555674\n","Train Epoch: 16 [1080/1452 (65%)]\tLoss: 4.285675\n","Train Epoch: 16 [1360/1452 (87%)]\tLoss: 3.016303\n","Epoch 16 - Training: Average loss: 4.5909, Accuracy: 34.34%\n","Evaluation set: Average loss: 4.3242, Accuracy: 291/707 (41.16%), F1-score: 0.3240\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1452 (0%)]\tLoss: 4.960461\n","Train Epoch: 17 [220/1452 (22%)]\tLoss: 4.924252\n","Train Epoch: 17 [640/1452 (43%)]\tLoss: 4.217475\n","Train Epoch: 17 [870/1452 (65%)]\tLoss: 4.406410\n","Train Epoch: 17 [1440/1452 (87%)]\tLoss: 4.814783\n","Epoch 17 - Training: Average loss: 4.4654, Accuracy: 35.53%\n","Evaluation set: Average loss: 4.3291, Accuracy: 293/707 (41.44%), F1-score: 0.3302\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1452 (0%)]\tLoss: 4.712664\n","Train Epoch: 18 [280/1452 (22%)]\tLoss: 3.599555\n","Train Epoch: 18 [700/1452 (43%)]\tLoss: 4.482874\n","Train Epoch: 18 [600/1452 (65%)]\tLoss: 4.237831\n","Train Epoch: 18 [1560/1452 (87%)]\tLoss: 5.107460\n","Epoch 18 - Training: Average loss: 4.3788, Accuracy: 35.86%\n","Evaluation set: Average loss: 4.1599, Accuracy: 310/707 (43.85%), F1-score: 0.3555\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1452 (0%)]\tLoss: 5.644011\n","Train Epoch: 19 [360/1452 (22%)]\tLoss: 4.381583\n","Train Epoch: 19 [760/1452 (43%)]\tLoss: 4.268777\n","Train Epoch: 19 [630/1452 (65%)]\tLoss: 4.251214\n","Train Epoch: 19 [1280/1452 (87%)]\tLoss: 4.876827\n","Epoch 19 - Training: Average loss: 4.3357, Accuracy: 35.62%\n","Evaluation set: Average loss: 4.1496, Accuracy: 304/707 (43.00%), F1-score: 0.3487\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1452 (0%)]\tLoss: 4.560879\n","Train Epoch: 20 [260/1452 (22%)]\tLoss: 4.470808\n","Train Epoch: 20 [600/1452 (43%)]\tLoss: 4.087200\n","Train Epoch: 20 [810/1452 (65%)]\tLoss: 3.551274\n","Train Epoch: 20 [1320/1452 (87%)]\tLoss: 4.406480\n","Epoch 20 - Training: Average loss: 4.2612, Accuracy: 37.23%\n","Evaluation set: Average loss: 3.9952, Accuracy: 325/707 (45.97%), F1-score: 0.3772\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 3.9458, Accuracy: 310/728 (42.58%), F1-score: 0.3206\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject101' 'subject108']\n","Train subjects: ['subject103' 'subject104' 'subject105' 'subject106']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1450 (0%)]\tLoss: 9.879175\n","Train Epoch: 1 [260/1450 (22%)]\tLoss: 6.738648\n","Train Epoch: 1 [680/1450 (43%)]\tLoss: 7.894919\n","Train Epoch: 1 [1350/1450 (65%)]\tLoss: 8.444412\n","Train Epoch: 1 [1000/1450 (87%)]\tLoss: 8.624704\n","Epoch 1 - Training: Average loss: 8.2836, Accuracy: 10.40%\n","Evaluation set: Average loss: 7.6334, Accuracy: 56/709 (7.90%), F1-score: 0.0673\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1450 (0%)]\tLoss: 6.632285\n","Train Epoch: 2 [290/1450 (22%)]\tLoss: 6.928041\n","Train Epoch: 2 [800/1450 (43%)]\tLoss: 7.070390\n","Train Epoch: 2 [660/1450 (65%)]\tLoss: 7.017037\n","Train Epoch: 2 [1680/1450 (87%)]\tLoss: 8.223592\n","Epoch 2 - Training: Average loss: 7.8378, Accuracy: 13.87%\n","Evaluation set: Average loss: 7.3369, Accuracy: 71/709 (10.01%), F1-score: 0.0763\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1450 (0%)]\tLoss: 7.182078\n","Train Epoch: 3 [400/1450 (22%)]\tLoss: 8.231726\n","Train Epoch: 3 [640/1450 (43%)]\tLoss: 7.069358\n","Train Epoch: 3 [900/1450 (65%)]\tLoss: 6.383273\n","Train Epoch: 3 [880/1450 (87%)]\tLoss: 5.637765\n","Epoch 3 - Training: Average loss: 7.1691, Accuracy: 14.34%\n","Evaluation set: Average loss: 6.9399, Accuracy: 73/709 (10.30%), F1-score: 0.0923\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1450 (0%)]\tLoss: 7.683336\n","Train Epoch: 4 [220/1450 (22%)]\tLoss: 6.702425\n","Train Epoch: 4 [680/1450 (43%)]\tLoss: 7.998966\n","Train Epoch: 4 [750/1450 (65%)]\tLoss: 5.871706\n","Train Epoch: 4 [1480/1450 (87%)]\tLoss: 4.583028\n","Epoch 4 - Training: Average loss: 6.9671, Accuracy: 16.53%\n","Evaluation set: Average loss: 6.4980, Accuracy: 81/709 (11.42%), F1-score: 0.0954\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1450 (0%)]\tLoss: 7.220900\n","Train Epoch: 5 [320/1450 (22%)]\tLoss: 3.633088\n","Train Epoch: 5 [780/1450 (43%)]\tLoss: 6.385876\n","Train Epoch: 5 [810/1450 (65%)]\tLoss: 5.932888\n","Train Epoch: 5 [1360/1450 (87%)]\tLoss: 5.151882\n","Epoch 5 - Training: Average loss: 6.4496, Accuracy: 17.32%\n","Evaluation set: Average loss: 6.1489, Accuracy: 102/709 (14.39%), F1-score: 0.1228\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1450 (0%)]\tLoss: 6.668829\n","Train Epoch: 6 [290/1450 (22%)]\tLoss: 6.463684\n","Train Epoch: 6 [780/1450 (43%)]\tLoss: 7.923485\n","Train Epoch: 6 [720/1450 (65%)]\tLoss: 5.217819\n","Train Epoch: 6 [1360/1450 (87%)]\tLoss: 7.630085\n","Epoch 6 - Training: Average loss: 6.1832, Accuracy: 18.18%\n","Evaluation set: Average loss: 6.0697, Accuracy: 125/709 (17.63%), F1-score: 0.1397\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1450 (0%)]\tLoss: 5.095314\n","Train Epoch: 7 [430/1450 (22%)]\tLoss: 5.074819\n","Train Epoch: 7 [700/1450 (43%)]\tLoss: 5.414125\n","Train Epoch: 7 [930/1450 (65%)]\tLoss: 7.580263\n","Train Epoch: 7 [1200/1450 (87%)]\tLoss: 6.479873\n","Epoch 7 - Training: Average loss: 5.9422, Accuracy: 18.49%\n","Evaluation set: Average loss: 5.6016, Accuracy: 137/709 (19.32%), F1-score: 0.1528\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1450 (0%)]\tLoss: 5.526874\n","Train Epoch: 8 [260/1450 (22%)]\tLoss: 6.201989\n","Train Epoch: 8 [480/1450 (43%)]\tLoss: 3.569710\n","Train Epoch: 8 [1140/1450 (65%)]\tLoss: 5.844327\n","Train Epoch: 8 [1400/1450 (87%)]\tLoss: 5.312016\n","Epoch 8 - Training: Average loss: 5.7933, Accuracy: 22.38%\n","Evaluation set: Average loss: 5.4057, Accuracy: 146/709 (20.59%), F1-score: 0.1617\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1450 (0%)]\tLoss: 5.993741\n","Train Epoch: 9 [300/1450 (22%)]\tLoss: 5.607294\n","Train Epoch: 9 [580/1450 (43%)]\tLoss: 7.056180\n","Train Epoch: 9 [1080/1450 (65%)]\tLoss: 6.163700\n","Train Epoch: 9 [1040/1450 (87%)]\tLoss: 4.206127\n","Epoch 9 - Training: Average loss: 5.5293, Accuracy: 22.07%\n","Evaluation set: Average loss: 5.4651, Accuracy: 155/709 (21.86%), F1-score: 0.1664\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1450 (0%)]\tLoss: 6.439438\n","Train Epoch: 10 [360/1450 (22%)]\tLoss: 4.693263\n","Train Epoch: 10 [680/1450 (43%)]\tLoss: 5.009302\n","Train Epoch: 10 [990/1450 (65%)]\tLoss: 5.415595\n","Train Epoch: 10 [1400/1450 (87%)]\tLoss: 5.372289\n","Epoch 10 - Training: Average loss: 5.6426, Accuracy: 20.80%\n","Evaluation set: Average loss: 5.1227, Accuracy: 160/709 (22.57%), F1-score: 0.1806\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1450 (0%)]\tLoss: 7.814274\n","Train Epoch: 11 [230/1450 (22%)]\tLoss: 4.904701\n","Train Epoch: 11 [740/1450 (43%)]\tLoss: 4.800954\n","Train Epoch: 11 [1050/1450 (65%)]\tLoss: 4.790497\n","Train Epoch: 11 [1720/1450 (87%)]\tLoss: 4.418082\n","Epoch 11 - Training: Average loss: 4.9951, Accuracy: 25.41%\n","Evaluation set: Average loss: 5.0919, Accuracy: 152/709 (21.44%), F1-score: 0.1775\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1450 (0%)]\tLoss: 6.345585\n","Train Epoch: 12 [320/1450 (22%)]\tLoss: 5.206934\n","Train Epoch: 12 [600/1450 (43%)]\tLoss: 6.076252\n","Train Epoch: 12 [900/1450 (65%)]\tLoss: 4.370483\n","Train Epoch: 12 [1240/1450 (87%)]\tLoss: 6.210867\n","Epoch 12 - Training: Average loss: 5.0596, Accuracy: 25.27%\n","Evaluation set: Average loss: 4.5862, Accuracy: 163/709 (22.99%), F1-score: 0.1931\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1450 (0%)]\tLoss: 4.864921\n","Train Epoch: 13 [280/1450 (22%)]\tLoss: 5.275435\n","Train Epoch: 13 [540/1450 (43%)]\tLoss: 4.521142\n","Train Epoch: 13 [750/1450 (65%)]\tLoss: 5.214101\n","Train Epoch: 13 [1400/1450 (87%)]\tLoss: 4.897525\n","Epoch 13 - Training: Average loss: 4.6933, Accuracy: 28.45%\n","Evaluation set: Average loss: 4.7408, Accuracy: 169/709 (23.84%), F1-score: 0.1966\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 14 [0/1450 (0%)]\tLoss: 5.364983\n","Train Epoch: 14 [320/1450 (22%)]\tLoss: 4.181199\n","Train Epoch: 14 [740/1450 (43%)]\tLoss: 4.385968\n","Train Epoch: 14 [960/1450 (65%)]\tLoss: 3.762170\n","Train Epoch: 14 [1400/1450 (87%)]\tLoss: 3.747709\n","Epoch 14 - Training: Average loss: 4.6787, Accuracy: 29.90%\n","Evaluation set: Average loss: 4.4822, Accuracy: 189/709 (26.66%), F1-score: 0.2277\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1450 (0%)]\tLoss: 3.588008\n","Train Epoch: 15 [290/1450 (22%)]\tLoss: 5.870172\n","Train Epoch: 15 [580/1450 (43%)]\tLoss: 3.399353\n","Train Epoch: 15 [810/1450 (65%)]\tLoss: 3.220616\n","Train Epoch: 15 [1400/1450 (87%)]\tLoss: 3.907324\n","Epoch 15 - Training: Average loss: 4.2794, Accuracy: 28.74%\n","Evaluation set: Average loss: 4.4900, Accuracy: 190/709 (26.80%), F1-score: 0.2202\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 16 [0/1450 (0%)]\tLoss: 4.064110\n","Train Epoch: 16 [260/1450 (22%)]\tLoss: 4.985375\n","Train Epoch: 16 [760/1450 (43%)]\tLoss: 3.321795\n","Train Epoch: 16 [960/1450 (65%)]\tLoss: 4.435444\n","Train Epoch: 16 [1080/1450 (87%)]\tLoss: 6.082571\n","Epoch 16 - Training: Average loss: 4.3784, Accuracy: 30.90%\n","Evaluation set: Average loss: 4.4392, Accuracy: 202/709 (28.49%), F1-score: 0.2437\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1450 (0%)]\tLoss: 2.673414\n","Train Epoch: 17 [360/1450 (22%)]\tLoss: 3.510894\n","Train Epoch: 17 [560/1450 (43%)]\tLoss: 4.314298\n","Train Epoch: 17 [810/1450 (65%)]\tLoss: 2.660955\n","Train Epoch: 17 [1240/1450 (87%)]\tLoss: 5.088663\n","Epoch 17 - Training: Average loss: 4.2970, Accuracy: 31.12%\n","Evaluation set: Average loss: 4.3918, Accuracy: 207/709 (29.20%), F1-score: 0.2442\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1450 (0%)]\tLoss: 4.445664\n","Train Epoch: 18 [310/1450 (22%)]\tLoss: 3.893044\n","Train Epoch: 18 [560/1450 (43%)]\tLoss: 3.617485\n","Train Epoch: 18 [750/1450 (65%)]\tLoss: 3.426664\n","Train Epoch: 18 [1600/1450 (87%)]\tLoss: 3.859419\n","Epoch 18 - Training: Average loss: 4.3019, Accuracy: 31.09%\n","Evaluation set: Average loss: 4.2103, Accuracy: 208/709 (29.34%), F1-score: 0.2575\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1450 (0%)]\tLoss: 3.042071\n","Train Epoch: 19 [390/1450 (22%)]\tLoss: 4.727719\n","Train Epoch: 19 [640/1450 (43%)]\tLoss: 3.896812\n","Train Epoch: 19 [990/1450 (65%)]\tLoss: 4.558271\n","Train Epoch: 19 [1320/1450 (87%)]\tLoss: 3.238876\n","Epoch 19 - Training: Average loss: 4.1800, Accuracy: 32.98%\n","Evaluation set: Average loss: 4.0283, Accuracy: 215/709 (30.32%), F1-score: 0.2660\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1450 (0%)]\tLoss: 5.448379\n","Train Epoch: 20 [250/1450 (22%)]\tLoss: 4.436027\n","Train Epoch: 20 [680/1450 (43%)]\tLoss: 4.434658\n","Train Epoch: 20 [750/1450 (65%)]\tLoss: 3.237417\n","Train Epoch: 20 [1200/1450 (87%)]\tLoss: 4.577324\n","Epoch 20 - Training: Average loss: 4.1042, Accuracy: 32.13%\n","Evaluation set: Average loss: 4.1707, Accuracy: 218/709 (30.75%), F1-score: 0.2738\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 4.0963, Accuracy: 275/728 (37.77%), F1-score: 0.3254\n","\n","Outer Fold 2 is starting ...\n","Test subjects: ['subject105' 'subject108']\n","Train-Validation subjects: ['subject101' 'subject102' 'subject103' 'subject104' 'subject106'\n"," 'subject107']\n","Fold 1 is starting ...\n","Validation subjects : ['subject106' 'subject107']\n","Train subjects: ['subject101' 'subject102' 'subject103' 'subject104']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1430 (0%)]\tLoss: 6.841461\n","Train Epoch: 1 [250/1430 (22%)]\tLoss: 7.912283\n","Train Epoch: 1 [640/1430 (44%)]\tLoss: 7.647847\n","Train Epoch: 1 [840/1430 (67%)]\tLoss: 9.638056\n","Train Epoch: 1 [1040/1430 (89%)]\tLoss: 8.339092\n","Epoch 1 - Training: Average loss: 8.7546, Accuracy: 9.31%\n","Evaluation set: Average loss: 10.6025, Accuracy: 46/714 (6.44%), F1-score: 0.0530\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1430 (0%)]\tLoss: 8.943980\n","Train Epoch: 2 [340/1430 (22%)]\tLoss: 9.110826\n","Train Epoch: 2 [760/1430 (44%)]\tLoss: 8.312080\n","Train Epoch: 2 [930/1430 (67%)]\tLoss: 8.454617\n","Train Epoch: 2 [1120/1430 (89%)]\tLoss: 8.503174\n","Epoch 2 - Training: Average loss: 8.2299, Accuracy: 8.97%\n","Evaluation set: Average loss: 10.1233, Accuracy: 52/714 (7.28%), F1-score: 0.0602\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1430 (0%)]\tLoss: 7.724747\n","Train Epoch: 3 [370/1430 (22%)]\tLoss: 7.595621\n","Train Epoch: 3 [860/1430 (44%)]\tLoss: 6.405087\n","Train Epoch: 3 [1110/1430 (67%)]\tLoss: 7.889685\n","Train Epoch: 3 [1160/1430 (89%)]\tLoss: 6.474735\n","Epoch 3 - Training: Average loss: 7.8757, Accuracy: 10.66%\n","Evaluation set: Average loss: 9.5503, Accuracy: 59/714 (8.26%), F1-score: 0.0763\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1430 (0%)]\tLoss: 9.106261\n","Train Epoch: 4 [310/1430 (22%)]\tLoss: 9.801231\n","Train Epoch: 4 [560/1430 (44%)]\tLoss: 8.912932\n","Train Epoch: 4 [1350/1430 (67%)]\tLoss: 6.471844\n","Train Epoch: 4 [1240/1430 (89%)]\tLoss: 8.548719\n","Epoch 4 - Training: Average loss: 7.6721, Accuracy: 11.90%\n","Evaluation set: Average loss: 8.8578, Accuracy: 71/714 (9.94%), F1-score: 0.0877\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1430 (0%)]\tLoss: 7.686812\n","Train Epoch: 5 [280/1430 (22%)]\tLoss: 6.975209\n","Train Epoch: 5 [720/1430 (44%)]\tLoss: 6.014592\n","Train Epoch: 5 [870/1430 (67%)]\tLoss: 7.861834\n","Train Epoch: 5 [1040/1430 (89%)]\tLoss: 7.837164\n","Epoch 5 - Training: Average loss: 7.0953, Accuracy: 16.68%\n","Evaluation set: Average loss: 8.2485, Accuracy: 83/714 (11.62%), F1-score: 0.1002\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1430 (0%)]\tLoss: 5.936091\n","Train Epoch: 6 [340/1430 (22%)]\tLoss: 7.172894\n","Train Epoch: 6 [620/1430 (44%)]\tLoss: 5.899961\n","Train Epoch: 6 [720/1430 (67%)]\tLoss: 5.892577\n","Train Epoch: 6 [920/1430 (89%)]\tLoss: 7.406662\n","Epoch 6 - Training: Average loss: 6.7198, Accuracy: 18.26%\n","Evaluation set: Average loss: 7.5314, Accuracy: 101/714 (14.15%), F1-score: 0.1221\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1430 (0%)]\tLoss: 7.411391\n","Train Epoch: 7 [370/1430 (22%)]\tLoss: 6.553497\n","Train Epoch: 7 [780/1430 (44%)]\tLoss: 8.096671\n","Train Epoch: 7 [960/1430 (67%)]\tLoss: 6.215996\n","Train Epoch: 7 [1680/1430 (89%)]\tLoss: 5.793684\n","Epoch 7 - Training: Average loss: 6.4528, Accuracy: 18.86%\n","Evaluation set: Average loss: 7.2211, Accuracy: 111/714 (15.55%), F1-score: 0.1364\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1430 (0%)]\tLoss: 6.720776\n","Train Epoch: 8 [360/1430 (22%)]\tLoss: 6.585958\n","Train Epoch: 8 [740/1430 (44%)]\tLoss: 5.770007\n","Train Epoch: 8 [1140/1430 (67%)]\tLoss: 6.321204\n","Train Epoch: 8 [1560/1430 (89%)]\tLoss: 5.388695\n","Epoch 8 - Training: Average loss: 6.2674, Accuracy: 22.15%\n","Evaluation set: Average loss: 6.9184, Accuracy: 122/714 (17.09%), F1-score: 0.1441\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1430 (0%)]\tLoss: 7.009368\n","Train Epoch: 9 [300/1430 (22%)]\tLoss: 4.523992\n","Train Epoch: 9 [780/1430 (44%)]\tLoss: 4.976538\n","Train Epoch: 9 [960/1430 (67%)]\tLoss: 4.090090\n","Train Epoch: 9 [1160/1430 (89%)]\tLoss: 4.462813\n","Epoch 9 - Training: Average loss: 6.1359, Accuracy: 23.03%\n","Evaluation set: Average loss: 7.1341, Accuracy: 126/714 (17.65%), F1-score: 0.1478\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1430 (0%)]\tLoss: 5.699263\n","Train Epoch: 10 [290/1430 (22%)]\tLoss: 5.762528\n","Train Epoch: 10 [780/1430 (44%)]\tLoss: 5.471339\n","Train Epoch: 10 [990/1430 (67%)]\tLoss: 5.345715\n","Train Epoch: 10 [1480/1430 (89%)]\tLoss: 4.513090\n","Epoch 10 - Training: Average loss: 6.1535, Accuracy: 23.18%\n","Evaluation set: Average loss: 6.8949, Accuracy: 134/714 (18.77%), F1-score: 0.1525\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1430 (0%)]\tLoss: 6.299173\n","Train Epoch: 11 [330/1430 (22%)]\tLoss: 7.475065\n","Train Epoch: 11 [620/1430 (44%)]\tLoss: 4.803825\n","Train Epoch: 11 [840/1430 (67%)]\tLoss: 5.886729\n","Train Epoch: 11 [1240/1430 (89%)]\tLoss: 5.202139\n","Epoch 11 - Training: Average loss: 5.8611, Accuracy: 25.56%\n","Evaluation set: Average loss: 6.9773, Accuracy: 172/714 (24.09%), F1-score: 0.1985\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 12 [0/1430 (0%)]\tLoss: 5.738495\n","Train Epoch: 12 [260/1430 (22%)]\tLoss: 6.218402\n","Train Epoch: 12 [620/1430 (44%)]\tLoss: 5.446990\n","Train Epoch: 12 [720/1430 (67%)]\tLoss: 7.250391\n","Train Epoch: 12 [1440/1430 (89%)]\tLoss: 5.519800\n","Epoch 12 - Training: Average loss: 5.8221, Accuracy: 28.80%\n","Evaluation set: Average loss: 6.9108, Accuracy: 187/714 (26.19%), F1-score: 0.2112\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 13 [0/1430 (0%)]\tLoss: 4.891526\n","Train Epoch: 13 [280/1430 (22%)]\tLoss: 6.137576\n","Train Epoch: 13 [760/1430 (44%)]\tLoss: 5.796786\n","Train Epoch: 13 [780/1430 (67%)]\tLoss: 6.570811\n","Train Epoch: 13 [1320/1430 (89%)]\tLoss: 5.895629\n","Epoch 13 - Training: Average loss: 5.5856, Accuracy: 29.35%\n","Evaluation set: Average loss: 6.2695, Accuracy: 202/714 (28.29%), F1-score: 0.2265\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1430 (0%)]\tLoss: 5.706999\n","Train Epoch: 14 [370/1430 (22%)]\tLoss: 5.110429\n","Train Epoch: 14 [840/1430 (44%)]\tLoss: 5.092002\n","Train Epoch: 14 [840/1430 (67%)]\tLoss: 6.696764\n","Train Epoch: 14 [1080/1430 (89%)]\tLoss: 6.021867\n","Epoch 14 - Training: Average loss: 5.3951, Accuracy: 31.57%\n","Evaluation set: Average loss: 5.9590, Accuracy: 223/714 (31.23%), F1-score: 0.2500\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1430 (0%)]\tLoss: 2.606897\n","Train Epoch: 15 [470/1430 (22%)]\tLoss: 5.837690\n","Train Epoch: 15 [640/1430 (44%)]\tLoss: 4.072339\n","Train Epoch: 15 [720/1430 (67%)]\tLoss: 4.178568\n","Train Epoch: 15 [1280/1430 (89%)]\tLoss: 5.481294\n","Epoch 15 - Training: Average loss: 5.2461, Accuracy: 31.94%\n","Evaluation set: Average loss: 5.9483, Accuracy: 266/714 (37.25%), F1-score: 0.2893\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1430 (0%)]\tLoss: 4.947728\n","Train Epoch: 16 [350/1430 (22%)]\tLoss: 4.990090\n","Train Epoch: 16 [720/1430 (44%)]\tLoss: 6.961365\n","Train Epoch: 16 [660/1430 (67%)]\tLoss: 5.535740\n","Train Epoch: 16 [1440/1430 (89%)]\tLoss: 5.817236\n","Epoch 16 - Training: Average loss: 5.4329, Accuracy: 30.69%\n","Evaluation set: Average loss: 5.9847, Accuracy: 223/714 (31.23%), F1-score: 0.2502\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 17 [0/1430 (0%)]\tLoss: 4.019207\n","Train Epoch: 17 [290/1430 (22%)]\tLoss: 6.470801\n","Train Epoch: 17 [740/1430 (44%)]\tLoss: 5.259388\n","Train Epoch: 17 [1290/1430 (67%)]\tLoss: 4.799630\n","Train Epoch: 17 [1240/1430 (89%)]\tLoss: 4.904634\n","Epoch 17 - Training: Average loss: 5.1819, Accuracy: 33.66%\n","Evaluation set: Average loss: 5.8576, Accuracy: 218/714 (30.53%), F1-score: 0.2480\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1430 (0%)]\tLoss: 6.265373\n","Train Epoch: 18 [350/1430 (22%)]\tLoss: 6.251679\n","Train Epoch: 18 [540/1430 (44%)]\tLoss: 5.464904\n","Train Epoch: 18 [780/1430 (67%)]\tLoss: 5.963089\n","Train Epoch: 18 [1320/1430 (89%)]\tLoss: 5.469926\n","Epoch 18 - Training: Average loss: 5.2633, Accuracy: 34.81%\n","Evaluation set: Average loss: 5.5247, Accuracy: 247/714 (34.59%), F1-score: 0.2754\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1430 (0%)]\tLoss: 4.400503\n","Train Epoch: 19 [370/1430 (22%)]\tLoss: 4.411325\n","Train Epoch: 19 [740/1430 (44%)]\tLoss: 7.425403\n","Train Epoch: 19 [1380/1430 (67%)]\tLoss: 5.313711\n","Train Epoch: 19 [1200/1430 (89%)]\tLoss: 4.510964\n","Epoch 19 - Training: Average loss: 5.4368, Accuracy: 33.48%\n","Evaluation set: Average loss: 5.6036, Accuracy: 228/714 (31.93%), F1-score: 0.2606\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 20 [0/1430 (0%)]\tLoss: 5.039270\n","Train Epoch: 20 [250/1430 (22%)]\tLoss: 5.013609\n","Train Epoch: 20 [500/1430 (44%)]\tLoss: 3.492083\n","Train Epoch: 20 [1020/1430 (67%)]\tLoss: 6.011580\n","Train Epoch: 20 [1000/1430 (89%)]\tLoss: 4.395026\n","Epoch 20 - Training: Average loss: 5.3835, Accuracy: 33.33%\n","Evaluation set: Average loss: 5.6475, Accuracy: 250/714 (35.01%), F1-score: 0.2702\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 5.6639, Accuracy: 279/743 (37.55%), F1-score: 0.2809\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject101' 'subject103']\n","Train subjects: ['subject102' 'subject104' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1451 (0%)]\tLoss: 11.477790\n","Train Epoch: 1 [190/1451 (22%)]\tLoss: 8.694320\n","Train Epoch: 1 [500/1451 (43%)]\tLoss: 10.619532\n","Train Epoch: 1 [1170/1451 (65%)]\tLoss: 9.398643\n","Train Epoch: 1 [1520/1451 (87%)]\tLoss: 10.074601\n","Epoch 1 - Training: Average loss: 9.9596, Accuracy: 13.11%\n","Evaluation set: Average loss: 9.4379, Accuracy: 115/693 (16.59%), F1-score: 0.1076\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1451 (0%)]\tLoss: 8.585343\n","Train Epoch: 2 [430/1451 (22%)]\tLoss: 9.054233\n","Train Epoch: 2 [800/1451 (43%)]\tLoss: 8.912041\n","Train Epoch: 2 [900/1451 (65%)]\tLoss: 9.419222\n","Train Epoch: 2 [1240/1451 (87%)]\tLoss: 9.600208\n","Epoch 2 - Training: Average loss: 9.1166, Accuracy: 12.83%\n","Evaluation set: Average loss: 8.5525, Accuracy: 113/693 (16.31%), F1-score: 0.1138\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1451 (0%)]\tLoss: 8.737359\n","Train Epoch: 3 [210/1451 (22%)]\tLoss: 6.909981\n","Train Epoch: 3 [840/1451 (43%)]\tLoss: 7.597116\n","Train Epoch: 3 [900/1451 (65%)]\tLoss: 7.258745\n","Train Epoch: 3 [1320/1451 (87%)]\tLoss: 8.027345\n","Epoch 3 - Training: Average loss: 8.2904, Accuracy: 15.46%\n","Evaluation set: Average loss: 7.8823, Accuracy: 130/693 (18.76%), F1-score: 0.1440\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1451 (0%)]\tLoss: 7.093754\n","Train Epoch: 4 [320/1451 (22%)]\tLoss: 9.850171\n","Train Epoch: 4 [800/1451 (43%)]\tLoss: 7.542866\n","Train Epoch: 4 [810/1451 (65%)]\tLoss: 8.631697\n","Train Epoch: 4 [1040/1451 (87%)]\tLoss: 6.832487\n","Epoch 4 - Training: Average loss: 7.6740, Accuracy: 15.86%\n","Evaluation set: Average loss: 8.5509, Accuracy: 131/693 (18.90%), F1-score: 0.1433\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 5 [0/1451 (0%)]\tLoss: 8.391197\n","Train Epoch: 5 [280/1451 (22%)]\tLoss: 9.023867\n","Train Epoch: 5 [680/1451 (43%)]\tLoss: 7.463575\n","Train Epoch: 5 [840/1451 (65%)]\tLoss: 6.964474\n","Train Epoch: 5 [1000/1451 (87%)]\tLoss: 6.387508\n","Epoch 5 - Training: Average loss: 7.6087, Accuracy: 17.13%\n","Evaluation set: Average loss: 7.1541, Accuracy: 145/693 (20.92%), F1-score: 0.1604\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1451 (0%)]\tLoss: 6.379883\n","Train Epoch: 6 [260/1451 (22%)]\tLoss: 7.910726\n","Train Epoch: 6 [420/1451 (43%)]\tLoss: 8.258699\n","Train Epoch: 6 [750/1451 (65%)]\tLoss: 5.820864\n","Train Epoch: 6 [1320/1451 (87%)]\tLoss: 6.706820\n","Epoch 6 - Training: Average loss: 7.0764, Accuracy: 18.50%\n","Evaluation set: Average loss: 6.9162, Accuracy: 142/693 (20.49%), F1-score: 0.1629\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1451 (0%)]\tLoss: 6.918808\n","Train Epoch: 7 [230/1451 (22%)]\tLoss: 5.928958\n","Train Epoch: 7 [620/1451 (43%)]\tLoss: 7.318283\n","Train Epoch: 7 [930/1451 (65%)]\tLoss: 7.455244\n","Train Epoch: 7 [1520/1451 (87%)]\tLoss: 7.983372\n","Epoch 7 - Training: Average loss: 7.0717, Accuracy: 17.67%\n","Evaluation set: Average loss: 6.8940, Accuracy: 162/693 (23.38%), F1-score: 0.1825\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1451 (0%)]\tLoss: 6.762228\n","Train Epoch: 8 [390/1451 (22%)]\tLoss: 7.017994\n","Train Epoch: 8 [680/1451 (43%)]\tLoss: 6.773329\n","Train Epoch: 8 [870/1451 (65%)]\tLoss: 6.410562\n","Train Epoch: 8 [1080/1451 (87%)]\tLoss: 5.203712\n","Epoch 8 - Training: Average loss: 6.5560, Accuracy: 20.50%\n","Evaluation set: Average loss: 6.8890, Accuracy: 153/693 (22.08%), F1-score: 0.1771\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1451 (0%)]\tLoss: 6.119989\n","Train Epoch: 9 [390/1451 (22%)]\tLoss: 5.521031\n","Train Epoch: 9 [540/1451 (43%)]\tLoss: 7.566906\n","Train Epoch: 9 [960/1451 (65%)]\tLoss: 6.095087\n","Train Epoch: 9 [1320/1451 (87%)]\tLoss: 5.784110\n","Epoch 9 - Training: Average loss: 6.2407, Accuracy: 24.54%\n","Evaluation set: Average loss: 6.7644, Accuracy: 163/693 (23.52%), F1-score: 0.1856\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1451 (0%)]\tLoss: 7.401227\n","Train Epoch: 10 [240/1451 (22%)]\tLoss: 5.180243\n","Train Epoch: 10 [620/1451 (43%)]\tLoss: 4.988977\n","Train Epoch: 10 [870/1451 (65%)]\tLoss: 3.363638\n","Train Epoch: 10 [1400/1451 (87%)]\tLoss: 5.653509\n","Epoch 10 - Training: Average loss: 5.9290, Accuracy: 25.38%\n","Evaluation set: Average loss: 6.3541, Accuracy: 164/693 (23.67%), F1-score: 0.1884\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1451 (0%)]\tLoss: 4.948933\n","Train Epoch: 11 [290/1451 (22%)]\tLoss: 5.236067\n","Train Epoch: 11 [660/1451 (43%)]\tLoss: 4.563781\n","Train Epoch: 11 [930/1451 (65%)]\tLoss: 4.176591\n","Train Epoch: 11 [1400/1451 (87%)]\tLoss: 6.158823\n","Epoch 11 - Training: Average loss: 5.4958, Accuracy: 28.95%\n","Evaluation set: Average loss: 5.9618, Accuracy: 161/693 (23.23%), F1-score: 0.1834\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1451 (0%)]\tLoss: 5.121655\n","Train Epoch: 12 [370/1451 (22%)]\tLoss: 5.719757\n","Train Epoch: 12 [580/1451 (43%)]\tLoss: 3.549816\n","Train Epoch: 12 [960/1451 (65%)]\tLoss: 4.574968\n","Train Epoch: 12 [1160/1451 (87%)]\tLoss: 5.741042\n","Epoch 12 - Training: Average loss: 5.0408, Accuracy: 28.23%\n","Evaluation set: Average loss: 5.7047, Accuracy: 170/693 (24.53%), F1-score: 0.1899\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1451 (0%)]\tLoss: 4.177075\n","Train Epoch: 13 [340/1451 (22%)]\tLoss: 4.157835\n","Train Epoch: 13 [660/1451 (43%)]\tLoss: 4.957787\n","Train Epoch: 13 [660/1451 (65%)]\tLoss: 3.865778\n","Train Epoch: 13 [1120/1451 (87%)]\tLoss: 4.847743\n","Epoch 13 - Training: Average loss: 4.8955, Accuracy: 28.54%\n","Evaluation set: Average loss: 5.4693, Accuracy: 180/693 (25.97%), F1-score: 0.1997\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1451 (0%)]\tLoss: 5.855472\n","Train Epoch: 14 [300/1451 (22%)]\tLoss: 5.607749\n","Train Epoch: 14 [660/1451 (43%)]\tLoss: 4.530468\n","Train Epoch: 14 [870/1451 (65%)]\tLoss: 5.449401\n","Train Epoch: 14 [1440/1451 (87%)]\tLoss: 5.606856\n","Epoch 14 - Training: Average loss: 4.8008, Accuracy: 29.83%\n","Evaluation set: Average loss: 5.3634, Accuracy: 166/693 (23.95%), F1-score: 0.1965\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1451 (0%)]\tLoss: 4.224836\n","Train Epoch: 15 [390/1451 (22%)]\tLoss: 5.051063\n","Train Epoch: 15 [440/1451 (43%)]\tLoss: 2.983611\n","Train Epoch: 15 [810/1451 (65%)]\tLoss: 5.395090\n","Train Epoch: 15 [1080/1451 (87%)]\tLoss: 4.393770\n","Epoch 15 - Training: Average loss: 4.7124, Accuracy: 28.72%\n","Evaluation set: Average loss: 5.5587, Accuracy: 167/693 (24.10%), F1-score: 0.1827\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 16 [0/1451 (0%)]\tLoss: 4.210753\n","Train Epoch: 16 [330/1451 (22%)]\tLoss: 4.051833\n","Train Epoch: 16 [380/1451 (43%)]\tLoss: 5.977450\n","Train Epoch: 16 [780/1451 (65%)]\tLoss: 3.579586\n","Train Epoch: 16 [800/1451 (87%)]\tLoss: 8.092302\n","Epoch 16 - Training: Average loss: 4.6870, Accuracy: 31.11%\n","Evaluation set: Average loss: 5.5538, Accuracy: 182/693 (26.26%), F1-score: 0.1970\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 17 [0/1451 (0%)]\tLoss: 4.364387\n","Train Epoch: 17 [390/1451 (22%)]\tLoss: 4.977687\n","Train Epoch: 17 [640/1451 (43%)]\tLoss: 3.901593\n","Train Epoch: 17 [960/1451 (65%)]\tLoss: 3.949973\n","Train Epoch: 17 [1440/1451 (87%)]\tLoss: 4.665508\n","Epoch 17 - Training: Average loss: 4.6069, Accuracy: 32.31%\n","Evaluation set: Average loss: 5.2178, Accuracy: 195/693 (28.14%), F1-score: 0.2082\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1451 (0%)]\tLoss: 4.068110\n","Train Epoch: 18 [250/1451 (22%)]\tLoss: 4.682956\n","Train Epoch: 18 [560/1451 (43%)]\tLoss: 4.523182\n","Train Epoch: 18 [900/1451 (65%)]\tLoss: 3.795277\n","Train Epoch: 18 [1120/1451 (87%)]\tLoss: 3.119200\n","Epoch 18 - Training: Average loss: 4.3318, Accuracy: 33.17%\n","Evaluation set: Average loss: 4.9550, Accuracy: 198/693 (28.57%), F1-score: 0.2162\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1451 (0%)]\tLoss: 4.538242\n","Train Epoch: 19 [230/1451 (22%)]\tLoss: 3.269188\n","Train Epoch: 19 [620/1451 (43%)]\tLoss: 4.578143\n","Train Epoch: 19 [930/1451 (65%)]\tLoss: 5.236726\n","Train Epoch: 19 [1280/1451 (87%)]\tLoss: 4.147178\n","Epoch 19 - Training: Average loss: 4.1760, Accuracy: 34.83%\n","Evaluation set: Average loss: 4.9756, Accuracy: 195/693 (28.14%), F1-score: 0.2077\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 20 [0/1451 (0%)]\tLoss: 3.728756\n","Train Epoch: 20 [320/1451 (22%)]\tLoss: 4.015800\n","Train Epoch: 20 [560/1451 (43%)]\tLoss: 3.666281\n","Train Epoch: 20 [1050/1451 (65%)]\tLoss: 3.694031\n","Train Epoch: 20 [1560/1451 (87%)]\tLoss: 4.087750\n","Epoch 20 - Training: Average loss: 4.0893, Accuracy: 34.30%\n","Evaluation set: Average loss: 4.8779, Accuracy: 199/693 (28.72%), F1-score: 0.2203\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 4.8410, Accuracy: 233/743 (31.36%), F1-score: 0.2436\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject102' 'subject104']\n","Train subjects: ['subject101' 'subject103' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1407 (0%)]\tLoss: 10.006064\n","Train Epoch: 1 [470/1407 (23%)]\tLoss: 9.845948\n","Train Epoch: 1 [640/1407 (45%)]\tLoss: 8.652013\n","Train Epoch: 1 [1020/1407 (68%)]\tLoss: 10.478969\n","Train Epoch: 1 [1440/1407 (91%)]\tLoss: 8.257412\n","Epoch 1 - Training: Average loss: 9.7319, Accuracy: 12.41%\n","Evaluation set: Average loss: 10.9478, Accuracy: 95/737 (12.89%), F1-score: 0.0988\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1407 (0%)]\tLoss: 9.855058\n","Train Epoch: 2 [340/1407 (23%)]\tLoss: 8.342103\n","Train Epoch: 2 [720/1407 (45%)]\tLoss: 8.847007\n","Train Epoch: 2 [1110/1407 (68%)]\tLoss: 8.636465\n","Train Epoch: 2 [1360/1407 (91%)]\tLoss: 8.343483\n","Epoch 2 - Training: Average loss: 8.6824, Accuracy: 13.83%\n","Evaluation set: Average loss: 10.5200, Accuracy: 102/737 (13.84%), F1-score: 0.1129\n","\n","Epsilon Spent: 0.074, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1407 (0%)]\tLoss: 7.895535\n","Train Epoch: 3 [300/1407 (23%)]\tLoss: 8.281789\n","Train Epoch: 3 [380/1407 (45%)]\tLoss: 6.608826\n","Train Epoch: 3 [900/1407 (68%)]\tLoss: 6.935341\n","Train Epoch: 3 [1400/1407 (91%)]\tLoss: 6.340867\n","Epoch 3 - Training: Average loss: 7.8203, Accuracy: 14.38%\n","Evaluation set: Average loss: 9.8025, Accuracy: 103/737 (13.98%), F1-score: 0.1192\n","\n","Epsilon Spent: 0.09, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1407 (0%)]\tLoss: 8.746601\n","Train Epoch: 4 [240/1407 (23%)]\tLoss: 6.791473\n","Train Epoch: 4 [720/1407 (45%)]\tLoss: 7.730022\n","Train Epoch: 4 [1290/1407 (68%)]\tLoss: 7.600265\n","Train Epoch: 4 [1280/1407 (91%)]\tLoss: 8.192737\n","Epoch 4 - Training: Average loss: 7.0235, Accuracy: 15.96%\n","Evaluation set: Average loss: 9.4708, Accuracy: 104/737 (14.11%), F1-score: 0.1296\n","\n","Epsilon Spent: 0.103, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1407 (0%)]\tLoss: 7.697282\n","Train Epoch: 5 [360/1407 (23%)]\tLoss: 5.822041\n","Train Epoch: 5 [580/1407 (45%)]\tLoss: 4.047947\n","Train Epoch: 5 [960/1407 (68%)]\tLoss: 7.178436\n","Train Epoch: 5 [1320/1407 (91%)]\tLoss: 6.320398\n","Epoch 5 - Training: Average loss: 6.5787, Accuracy: 18.58%\n","Evaluation set: Average loss: 7.8120, Accuracy: 114/737 (15.47%), F1-score: 0.1362\n","\n","Epsilon Spent: 0.116, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1407 (0%)]\tLoss: 7.055564\n","Train Epoch: 6 [350/1407 (23%)]\tLoss: 7.092359\n","Train Epoch: 6 [760/1407 (45%)]\tLoss: 4.431733\n","Train Epoch: 6 [1290/1407 (68%)]\tLoss: 6.626923\n","Train Epoch: 6 [1000/1407 (91%)]\tLoss: 7.155964\n","Epoch 6 - Training: Average loss: 6.3455, Accuracy: 16.74%\n","Evaluation set: Average loss: 8.0387, Accuracy: 117/737 (15.88%), F1-score: 0.1412\n","\n","Epsilon Spent: 0.126, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 7 [0/1407 (0%)]\tLoss: 6.443193\n","Train Epoch: 7 [330/1407 (23%)]\tLoss: 5.679565\n","Train Epoch: 7 [680/1407 (45%)]\tLoss: 4.433959\n","Train Epoch: 7 [900/1407 (68%)]\tLoss: 6.643167\n","Train Epoch: 7 [1680/1407 (91%)]\tLoss: 6.123931\n","Epoch 7 - Training: Average loss: 5.5652, Accuracy: 20.42%\n","Evaluation set: Average loss: 7.7834, Accuracy: 126/737 (17.10%), F1-score: 0.1478\n","\n","Epsilon Spent: 0.137, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1407 (0%)]\tLoss: 5.169166\n","Train Epoch: 8 [390/1407 (23%)]\tLoss: 5.762011\n","Train Epoch: 8 [520/1407 (45%)]\tLoss: 6.311628\n","Train Epoch: 8 [810/1407 (68%)]\tLoss: 5.902020\n","Train Epoch: 8 [1640/1407 (91%)]\tLoss: 5.021746\n","Epoch 8 - Training: Average loss: 5.2956, Accuracy: 22.85%\n","Evaluation set: Average loss: 7.0776, Accuracy: 121/737 (16.42%), F1-score: 0.1403\n","\n","Epsilon Spent: 0.146, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1407 (0%)]\tLoss: 4.087286\n","Train Epoch: 9 [360/1407 (23%)]\tLoss: 4.489841\n","Train Epoch: 9 [300/1407 (45%)]\tLoss: 3.754628\n","Train Epoch: 9 [630/1407 (68%)]\tLoss: 5.564457\n","Train Epoch: 9 [760/1407 (91%)]\tLoss: 4.747273\n","Epoch 9 - Training: Average loss: 4.6520, Accuracy: 29.56%\n","Evaluation set: Average loss: 7.0852, Accuracy: 131/737 (17.77%), F1-score: 0.1594\n","\n","Epsilon Spent: 0.155, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1407 (0%)]\tLoss: 4.421154\n","Train Epoch: 10 [330/1407 (23%)]\tLoss: 4.257186\n","Train Epoch: 10 [740/1407 (45%)]\tLoss: 4.942493\n","Train Epoch: 10 [930/1407 (68%)]\tLoss: 3.825418\n","Train Epoch: 10 [1800/1407 (91%)]\tLoss: 5.216863\n","Epoch 10 - Training: Average loss: 4.4739, Accuracy: 29.79%\n","Evaluation set: Average loss: 6.1483, Accuracy: 127/737 (17.23%), F1-score: 0.1575\n","\n","Epsilon Spent: 0.164, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1407 (0%)]\tLoss: 2.521083\n","Train Epoch: 11 [390/1407 (23%)]\tLoss: 4.043202\n","Train Epoch: 11 [580/1407 (45%)]\tLoss: 2.210097\n","Train Epoch: 11 [900/1407 (68%)]\tLoss: 4.452854\n","Train Epoch: 11 [1200/1407 (91%)]\tLoss: 2.321392\n","Epoch 11 - Training: Average loss: 4.1631, Accuracy: 33.60%\n","Evaluation set: Average loss: 5.6577, Accuracy: 125/737 (16.96%), F1-score: 0.1623\n","\n","Epsilon Spent: 0.172, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1407 (0%)]\tLoss: 3.052254\n","Train Epoch: 12 [240/1407 (23%)]\tLoss: 4.967593\n","Train Epoch: 12 [560/1407 (45%)]\tLoss: 4.266765\n","Train Epoch: 12 [960/1407 (68%)]\tLoss: 2.812511\n","Train Epoch: 12 [1320/1407 (91%)]\tLoss: 4.064151\n","Epoch 12 - Training: Average loss: 3.8262, Accuracy: 35.42%\n","Evaluation set: Average loss: 6.3348, Accuracy: 135/737 (18.32%), F1-score: 0.1783\n","\n","Epsilon Spent: 0.18, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 13 [0/1407 (0%)]\tLoss: 4.620951\n","Train Epoch: 13 [380/1407 (23%)]\tLoss: 4.490499\n","Train Epoch: 13 [560/1407 (45%)]\tLoss: 3.987531\n","Train Epoch: 13 [1050/1407 (68%)]\tLoss: 4.593414\n","Train Epoch: 13 [1200/1407 (91%)]\tLoss: 3.160984\n","Epoch 13 - Training: Average loss: 4.0734, Accuracy: 37.83%\n","Evaluation set: Average loss: 5.5576, Accuracy: 144/737 (19.54%), F1-score: 0.1858\n","\n","Epsilon Spent: 0.187, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1407 (0%)]\tLoss: 4.297460\n","Train Epoch: 14 [350/1407 (23%)]\tLoss: 3.670344\n","Train Epoch: 14 [360/1407 (45%)]\tLoss: 3.961910\n","Train Epoch: 14 [720/1407 (68%)]\tLoss: 4.030846\n","Train Epoch: 14 [1080/1407 (91%)]\tLoss: 4.040690\n","Epoch 14 - Training: Average loss: 3.8599, Accuracy: 37.94%\n","Evaluation set: Average loss: 5.0662, Accuracy: 180/737 (24.42%), F1-score: 0.2297\n","\n","Epsilon Spent: 0.194, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1407 (0%)]\tLoss: 4.948140\n","Train Epoch: 15 [350/1407 (23%)]\tLoss: 3.585344\n","Train Epoch: 15 [520/1407 (45%)]\tLoss: 3.379160\n","Train Epoch: 15 [840/1407 (68%)]\tLoss: 3.897483\n","Train Epoch: 15 [1160/1407 (91%)]\tLoss: 4.260838\n","Epoch 15 - Training: Average loss: 3.7528, Accuracy: 39.13%\n","Evaluation set: Average loss: 4.7302, Accuracy: 211/737 (28.63%), F1-score: 0.2692\n","\n","Epsilon Spent: 0.201, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1407 (0%)]\tLoss: 4.304030\n","Train Epoch: 16 [360/1407 (23%)]\tLoss: 3.507205\n","Train Epoch: 16 [800/1407 (45%)]\tLoss: 4.275076\n","Train Epoch: 16 [870/1407 (68%)]\tLoss: 2.729034\n","Train Epoch: 16 [1640/1407 (91%)]\tLoss: 4.977244\n","Epoch 16 - Training: Average loss: 3.7027, Accuracy: 40.96%\n","Evaluation set: Average loss: 4.4155, Accuracy: 214/737 (29.04%), F1-score: 0.2743\n","\n","Epsilon Spent: 0.208, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1407 (0%)]\tLoss: 3.210780\n","Train Epoch: 17 [230/1407 (23%)]\tLoss: 2.913846\n","Train Epoch: 17 [660/1407 (45%)]\tLoss: 3.480142\n","Train Epoch: 17 [1440/1407 (68%)]\tLoss: 4.495461\n","Train Epoch: 17 [1520/1407 (91%)]\tLoss: 3.292173\n","Epoch 17 - Training: Average loss: 3.4748, Accuracy: 42.59%\n","Evaluation set: Average loss: 4.3868, Accuracy: 225/737 (30.53%), F1-score: 0.2887\n","\n","Epsilon Spent: 0.215, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1407 (0%)]\tLoss: 2.633353\n","Train Epoch: 18 [210/1407 (23%)]\tLoss: 2.655179\n","Train Epoch: 18 [660/1407 (45%)]\tLoss: 3.312725\n","Train Epoch: 18 [870/1407 (68%)]\tLoss: 2.556603\n","Train Epoch: 18 [1480/1407 (91%)]\tLoss: 5.098279\n","Epoch 18 - Training: Average loss: 3.4823, Accuracy: 44.12%\n","Evaluation set: Average loss: 4.5048, Accuracy: 226/737 (30.66%), F1-score: 0.2864\n","\n","Epsilon Spent: 0.221, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 19 [0/1407 (0%)]\tLoss: 3.903784\n","Train Epoch: 19 [320/1407 (23%)]\tLoss: 3.871326\n","Train Epoch: 19 [640/1407 (45%)]\tLoss: 3.547790\n","Train Epoch: 19 [930/1407 (68%)]\tLoss: 3.640539\n","Train Epoch: 19 [1080/1407 (91%)]\tLoss: 4.096998\n","Epoch 19 - Training: Average loss: 3.5640, Accuracy: 43.32%\n","Evaluation set: Average loss: 4.2069, Accuracy: 253/737 (34.33%), F1-score: 0.3303\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1407 (0%)]\tLoss: 3.839338\n","Train Epoch: 20 [330/1407 (23%)]\tLoss: 2.837727\n","Train Epoch: 20 [580/1407 (45%)]\tLoss: 2.701222\n","Train Epoch: 20 [780/1407 (68%)]\tLoss: 2.671791\n","Train Epoch: 20 [1320/1407 (91%)]\tLoss: 3.076278\n","Epoch 20 - Training: Average loss: 3.4741, Accuracy: 44.66%\n","Evaluation set: Average loss: 4.4693, Accuracy: 233/737 (31.61%), F1-score: 0.2989\n","\n","Epsilon Spent: 0.234, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 3.7136, Accuracy: 295/743 (39.70%), F1-score: 0.3137\n","\n","Outer Fold 3 is starting ...\n","Test subjects: ['subject103' 'subject106']\n","Train-Validation subjects: ['subject101' 'subject102' 'subject104' 'subject105' 'subject107'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject104' 'subject105']\n","Train subjects: ['subject101' 'subject102' 'subject107' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1437 (0%)]\tLoss: 10.827564\n","Train Epoch: 1 [280/1437 (22%)]\tLoss: 9.762156\n","Train Epoch: 1 [560/1437 (44%)]\tLoss: 11.217689\n","Train Epoch: 1 [930/1437 (67%)]\tLoss: 8.277426\n","Train Epoch: 1 [1280/1437 (89%)]\tLoss: 9.884490\n","Epoch 1 - Training: Average loss: 9.6936, Accuracy: 13.00%\n","Evaluation set: Average loss: 10.2250, Accuracy: 103/743 (13.86%), F1-score: 0.1253\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1437 (0%)]\tLoss: 7.265860\n","Train Epoch: 2 [310/1437 (22%)]\tLoss: 8.912353\n","Train Epoch: 2 [720/1437 (44%)]\tLoss: 6.384587\n","Train Epoch: 2 [1020/1437 (67%)]\tLoss: 8.649866\n","Train Epoch: 2 [1360/1437 (89%)]\tLoss: 8.939923\n","Epoch 2 - Training: Average loss: 8.5846, Accuracy: 15.81%\n","Evaluation set: Average loss: 9.2847, Accuracy: 113/743 (15.21%), F1-score: 0.1409\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1437 (0%)]\tLoss: 9.696498\n","Train Epoch: 3 [350/1437 (22%)]\tLoss: 8.579077\n","Train Epoch: 3 [500/1437 (44%)]\tLoss: 9.593116\n","Train Epoch: 3 [840/1437 (67%)]\tLoss: 7.275833\n","Train Epoch: 3 [1040/1437 (89%)]\tLoss: 6.865693\n","Epoch 3 - Training: Average loss: 8.0369, Accuracy: 17.12%\n","Evaluation set: Average loss: 9.0114, Accuracy: 121/743 (16.29%), F1-score: 0.1512\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1437 (0%)]\tLoss: 7.801254\n","Train Epoch: 4 [290/1437 (22%)]\tLoss: 8.070912\n","Train Epoch: 4 [760/1437 (44%)]\tLoss: 7.607367\n","Train Epoch: 4 [1050/1437 (67%)]\tLoss: 8.437966\n","Train Epoch: 4 [1280/1437 (89%)]\tLoss: 6.909573\n","Epoch 4 - Training: Average loss: 7.6786, Accuracy: 19.72%\n","Evaluation set: Average loss: 8.6295, Accuracy: 141/743 (18.98%), F1-score: 0.1715\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1437 (0%)]\tLoss: 7.171576\n","Train Epoch: 5 [360/1437 (22%)]\tLoss: 5.920385\n","Train Epoch: 5 [520/1437 (44%)]\tLoss: 10.754115\n","Train Epoch: 5 [1020/1437 (67%)]\tLoss: 5.976314\n","Train Epoch: 5 [1160/1437 (89%)]\tLoss: 6.233398\n","Epoch 5 - Training: Average loss: 7.1467, Accuracy: 22.77%\n","Evaluation set: Average loss: 8.5107, Accuracy: 141/743 (18.98%), F1-score: 0.1684\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1437 (0%)]\tLoss: 10.131034\n","Train Epoch: 6 [360/1437 (22%)]\tLoss: 6.921734\n","Train Epoch: 6 [560/1437 (44%)]\tLoss: 6.682095\n","Train Epoch: 6 [840/1437 (67%)]\tLoss: 7.467805\n","Train Epoch: 6 [1320/1437 (89%)]\tLoss: 7.256712\n","Epoch 6 - Training: Average loss: 7.4040, Accuracy: 24.01%\n","Evaluation set: Average loss: 8.0477, Accuracy: 148/743 (19.92%), F1-score: 0.1767\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1437 (0%)]\tLoss: 6.762884\n","Train Epoch: 7 [260/1437 (22%)]\tLoss: 7.401480\n","Train Epoch: 7 [720/1437 (44%)]\tLoss: 6.069313\n","Train Epoch: 7 [1230/1437 (67%)]\tLoss: 5.799644\n","Train Epoch: 7 [1280/1437 (89%)]\tLoss: 6.799681\n","Epoch 7 - Training: Average loss: 6.8167, Accuracy: 22.63%\n","Evaluation set: Average loss: 8.0578, Accuracy: 153/743 (20.59%), F1-score: 0.1862\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 8 [0/1437 (0%)]\tLoss: 6.204754\n","Train Epoch: 8 [290/1437 (22%)]\tLoss: 7.219169\n","Train Epoch: 8 [560/1437 (44%)]\tLoss: 6.798096\n","Train Epoch: 8 [990/1437 (67%)]\tLoss: 8.806417\n","Train Epoch: 8 [1240/1437 (89%)]\tLoss: 6.980816\n","Epoch 8 - Training: Average loss: 7.2702, Accuracy: 21.12%\n","Evaluation set: Average loss: 7.5181, Accuracy: 149/743 (20.05%), F1-score: 0.1786\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1437 (0%)]\tLoss: 7.648552\n","Train Epoch: 9 [350/1437 (22%)]\tLoss: 6.187553\n","Train Epoch: 9 [540/1437 (44%)]\tLoss: 6.343369\n","Train Epoch: 9 [1140/1437 (67%)]\tLoss: 5.306114\n","Train Epoch: 9 [960/1437 (89%)]\tLoss: 5.941045\n","Epoch 9 - Training: Average loss: 6.3540, Accuracy: 24.88%\n","Evaluation set: Average loss: 8.0605, Accuracy: 168/743 (22.61%), F1-score: 0.1964\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1437 (0%)]\tLoss: 7.354435\n","Train Epoch: 10 [250/1437 (22%)]\tLoss: 4.451612\n","Train Epoch: 10 [560/1437 (44%)]\tLoss: 4.838310\n","Train Epoch: 10 [1320/1437 (67%)]\tLoss: 6.410475\n","Train Epoch: 10 [1320/1437 (89%)]\tLoss: 7.800215\n","Epoch 10 - Training: Average loss: 6.4223, Accuracy: 23.49%\n","Evaluation set: Average loss: 8.2626, Accuracy: 181/743 (24.36%), F1-score: 0.2105\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 11 [0/1437 (0%)]\tLoss: 7.571102\n","Train Epoch: 11 [260/1437 (22%)]\tLoss: 7.026250\n","Train Epoch: 11 [620/1437 (44%)]\tLoss: 6.543812\n","Train Epoch: 11 [930/1437 (67%)]\tLoss: 4.304592\n","Train Epoch: 11 [1080/1437 (89%)]\tLoss: 6.793900\n","Epoch 11 - Training: Average loss: 5.9244, Accuracy: 28.31%\n","Evaluation set: Average loss: 8.2034, Accuracy: 179/743 (24.09%), F1-score: 0.2057\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 12 [0/1437 (0%)]\tLoss: 5.514611\n","Train Epoch: 12 [380/1437 (22%)]\tLoss: 5.421606\n","Train Epoch: 12 [760/1437 (44%)]\tLoss: 7.595167\n","Train Epoch: 12 [1110/1437 (67%)]\tLoss: 6.022957\n","Train Epoch: 12 [1400/1437 (89%)]\tLoss: 6.417478\n","Epoch 12 - Training: Average loss: 6.3365, Accuracy: 26.81%\n","Evaluation set: Average loss: 7.6644, Accuracy: 181/743 (24.36%), F1-score: 0.2185\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 13 [0/1437 (0%)]\tLoss: 5.204812\n","Train Epoch: 13 [220/1437 (22%)]\tLoss: 4.289968\n","Train Epoch: 13 [520/1437 (44%)]\tLoss: 5.611325\n","Train Epoch: 13 [960/1437 (67%)]\tLoss: 6.035501\n","Train Epoch: 13 [1400/1437 (89%)]\tLoss: 6.383835\n","Epoch 13 - Training: Average loss: 5.5715, Accuracy: 32.37%\n","Evaluation set: Average loss: 7.4995, Accuracy: 192/743 (25.84%), F1-score: 0.2320\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1437 (0%)]\tLoss: 4.967120\n","Train Epoch: 14 [320/1437 (22%)]\tLoss: 5.074634\n","Train Epoch: 14 [620/1437 (44%)]\tLoss: 6.353462\n","Train Epoch: 14 [720/1437 (67%)]\tLoss: 7.261030\n","Train Epoch: 14 [1320/1437 (89%)]\tLoss: 5.477699\n","Epoch 14 - Training: Average loss: 5.7185, Accuracy: 29.53%\n","Evaluation set: Average loss: 7.7221, Accuracy: 185/743 (24.90%), F1-score: 0.2191\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 15 [0/1437 (0%)]\tLoss: 5.332592\n","Train Epoch: 15 [230/1437 (22%)]\tLoss: 5.451727\n","Train Epoch: 15 [680/1437 (44%)]\tLoss: 6.006307\n","Train Epoch: 15 [1020/1437 (67%)]\tLoss: 7.839820\n","Train Epoch: 15 [920/1437 (89%)]\tLoss: 7.626934\n","Epoch 15 - Training: Average loss: 5.7617, Accuracy: 30.48%\n","Evaluation set: Average loss: 7.6707, Accuracy: 184/743 (24.76%), F1-score: 0.2193\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 16 [0/1437 (0%)]\tLoss: 4.720846\n","Train Epoch: 16 [300/1437 (22%)]\tLoss: 5.848303\n","Train Epoch: 16 [700/1437 (44%)]\tLoss: 8.030906\n","Train Epoch: 16 [810/1437 (67%)]\tLoss: 5.750905\n","Train Epoch: 16 [1160/1437 (89%)]\tLoss: 7.269915\n","Epoch 16 - Training: Average loss: 5.7233, Accuracy: 31.64%\n","Evaluation set: Average loss: 7.5003, Accuracy: 189/743 (25.44%), F1-score: 0.2304\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 17 [0/1437 (0%)]\tLoss: 5.415123\n","Train Epoch: 17 [260/1437 (22%)]\tLoss: 8.058224\n","Train Epoch: 17 [580/1437 (44%)]\tLoss: 5.258611\n","Train Epoch: 17 [930/1437 (67%)]\tLoss: 5.028636\n","Train Epoch: 17 [1800/1437 (89%)]\tLoss: 5.593379\n","Epoch 17 - Training: Average loss: 5.9109, Accuracy: 28.81%\n","Evaluation set: Average loss: 7.6207, Accuracy: 195/743 (26.24%), F1-score: 0.2321\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 18 [0/1437 (0%)]\tLoss: 6.002100\n","Train Epoch: 18 [280/1437 (22%)]\tLoss: 7.780532\n","Train Epoch: 18 [600/1437 (44%)]\tLoss: 4.280663\n","Train Epoch: 18 [870/1437 (67%)]\tLoss: 4.554946\n","Train Epoch: 18 [1320/1437 (89%)]\tLoss: 4.781678\n","Epoch 18 - Training: Average loss: 5.6953, Accuracy: 32.37%\n","Evaluation set: Average loss: 7.3906, Accuracy: 185/743 (24.90%), F1-score: 0.2247\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1437 (0%)]\tLoss: 6.257768\n","Train Epoch: 19 [270/1437 (22%)]\tLoss: 4.724307\n","Train Epoch: 19 [680/1437 (44%)]\tLoss: 4.618500\n","Train Epoch: 19 [1080/1437 (67%)]\tLoss: 6.402064\n","Train Epoch: 19 [1080/1437 (89%)]\tLoss: 5.858779\n","Epoch 19 - Training: Average loss: 5.7025, Accuracy: 30.69%\n","Evaluation set: Average loss: 7.5457, Accuracy: 182/743 (24.50%), F1-score: 0.2194\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 20 [0/1437 (0%)]\tLoss: 7.296834\n","Train Epoch: 20 [490/1437 (22%)]\tLoss: 6.138278\n","Train Epoch: 20 [880/1437 (44%)]\tLoss: 5.709683\n","Train Epoch: 20 [930/1437 (67%)]\tLoss: 7.255509\n","Train Epoch: 20 [1240/1437 (89%)]\tLoss: 5.071716\n","Epoch 20 - Training: Average loss: 6.0333, Accuracy: 28.71%\n","Evaluation set: Average loss: 7.1630, Accuracy: 187/743 (25.17%), F1-score: 0.2214\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 6.1813, Accuracy: 192/707 (27.16%), F1-score: 0.2630\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject102' 'subject107']\n","Train subjects: ['subject101' 'subject104' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1452 (0%)]\tLoss: 12.270166\n","Train Epoch: 1 [350/1452 (22%)]\tLoss: 10.882646\n","Train Epoch: 1 [540/1452 (43%)]\tLoss: 9.892595\n","Train Epoch: 1 [870/1452 (65%)]\tLoss: 11.596607\n","Train Epoch: 1 [1480/1452 (87%)]\tLoss: 12.636450\n","Epoch 1 - Training: Average loss: 10.5818, Accuracy: 13.63%\n","Evaluation set: Average loss: 10.6289, Accuracy: 112/728 (15.38%), F1-score: 0.0982\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1452 (0%)]\tLoss: 10.040211\n","Train Epoch: 2 [260/1452 (22%)]\tLoss: 8.055468\n","Train Epoch: 2 [680/1452 (43%)]\tLoss: 8.390655\n","Train Epoch: 2 [870/1452 (65%)]\tLoss: 8.290503\n","Train Epoch: 2 [1000/1452 (87%)]\tLoss: 6.965508\n","Epoch 2 - Training: Average loss: 9.4391, Accuracy: 16.06%\n","Evaluation set: Average loss: 10.6559, Accuracy: 120/728 (16.48%), F1-score: 0.1063\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 3 [0/1452 (0%)]\tLoss: 9.031260\n","Train Epoch: 3 [330/1452 (22%)]\tLoss: 8.085650\n","Train Epoch: 3 [620/1452 (43%)]\tLoss: 8.483714\n","Train Epoch: 3 [1050/1452 (65%)]\tLoss: 7.530221\n","Train Epoch: 3 [1320/1452 (87%)]\tLoss: 7.929614\n","Epoch 3 - Training: Average loss: 8.7249, Accuracy: 18.86%\n","Evaluation set: Average loss: 9.5095, Accuracy: 136/728 (18.68%), F1-score: 0.1275\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1452 (0%)]\tLoss: 7.072200\n","Train Epoch: 4 [320/1452 (22%)]\tLoss: 8.253769\n","Train Epoch: 4 [720/1452 (43%)]\tLoss: 8.299587\n","Train Epoch: 4 [1110/1452 (65%)]\tLoss: 8.790041\n","Train Epoch: 4 [1160/1452 (87%)]\tLoss: 10.853689\n","Epoch 4 - Training: Average loss: 7.9522, Accuracy: 17.06%\n","Evaluation set: Average loss: 8.8056, Accuracy: 131/728 (17.99%), F1-score: 0.1256\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1452 (0%)]\tLoss: 7.947499\n","Train Epoch: 5 [280/1452 (22%)]\tLoss: 8.773685\n","Train Epoch: 5 [620/1452 (43%)]\tLoss: 8.926744\n","Train Epoch: 5 [720/1452 (65%)]\tLoss: 6.168516\n","Train Epoch: 5 [1080/1452 (87%)]\tLoss: 5.063693\n","Epoch 5 - Training: Average loss: 7.1470, Accuracy: 20.74%\n","Evaluation set: Average loss: 8.2318, Accuracy: 156/728 (21.43%), F1-score: 0.1528\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1452 (0%)]\tLoss: 8.752029\n","Train Epoch: 6 [490/1452 (22%)]\tLoss: 5.520088\n","Train Epoch: 6 [440/1452 (43%)]\tLoss: 7.229565\n","Train Epoch: 6 [1020/1452 (65%)]\tLoss: 6.180363\n","Train Epoch: 6 [1560/1452 (87%)]\tLoss: 7.629013\n","Epoch 6 - Training: Average loss: 6.7337, Accuracy: 22.16%\n","Evaluation set: Average loss: 7.6697, Accuracy: 150/728 (20.60%), F1-score: 0.1640\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1452 (0%)]\tLoss: 6.104137\n","Train Epoch: 7 [270/1452 (22%)]\tLoss: 7.715451\n","Train Epoch: 7 [680/1452 (43%)]\tLoss: 6.240566\n","Train Epoch: 7 [1140/1452 (65%)]\tLoss: 6.823873\n","Train Epoch: 7 [1680/1452 (87%)]\tLoss: 7.225658\n","Epoch 7 - Training: Average loss: 6.2667, Accuracy: 22.91%\n","Evaluation set: Average loss: 7.4239, Accuracy: 161/728 (22.12%), F1-score: 0.1635\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1452 (0%)]\tLoss: 6.061532\n","Train Epoch: 8 [290/1452 (22%)]\tLoss: 6.048643\n","Train Epoch: 8 [640/1452 (43%)]\tLoss: 6.072132\n","Train Epoch: 8 [1110/1452 (65%)]\tLoss: 6.431224\n","Train Epoch: 8 [1520/1452 (87%)]\tLoss: 4.981021\n","Epoch 8 - Training: Average loss: 5.8381, Accuracy: 23.42%\n","Evaluation set: Average loss: 6.7080, Accuracy: 182/728 (25.00%), F1-score: 0.1875\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1452 (0%)]\tLoss: 5.740844\n","Train Epoch: 9 [350/1452 (22%)]\tLoss: 5.555538\n","Train Epoch: 9 [700/1452 (43%)]\tLoss: 6.024061\n","Train Epoch: 9 [930/1452 (65%)]\tLoss: 3.800836\n","Train Epoch: 9 [1440/1452 (87%)]\tLoss: 4.499980\n","Epoch 9 - Training: Average loss: 5.5239, Accuracy: 25.32%\n","Evaluation set: Average loss: 6.9191, Accuracy: 181/728 (24.86%), F1-score: 0.1733\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1452 (0%)]\tLoss: 4.884511\n","Train Epoch: 10 [400/1452 (22%)]\tLoss: 6.130516\n","Train Epoch: 10 [480/1452 (43%)]\tLoss: 5.635609\n","Train Epoch: 10 [1170/1452 (65%)]\tLoss: 4.416203\n","Train Epoch: 10 [1040/1452 (87%)]\tLoss: 4.815095\n","Epoch 10 - Training: Average loss: 5.4251, Accuracy: 26.68%\n","Evaluation set: Average loss: 5.9904, Accuracy: 199/728 (27.34%), F1-score: 0.2044\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1452 (0%)]\tLoss: 4.335311\n","Train Epoch: 11 [310/1452 (22%)]\tLoss: 3.779862\n","Train Epoch: 11 [600/1452 (43%)]\tLoss: 4.256045\n","Train Epoch: 11 [1050/1452 (65%)]\tLoss: 4.277525\n","Train Epoch: 11 [1320/1452 (87%)]\tLoss: 4.004293\n","Epoch 11 - Training: Average loss: 4.8732, Accuracy: 30.68%\n","Evaluation set: Average loss: 5.6065, Accuracy: 213/728 (29.26%), F1-score: 0.2269\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1452 (0%)]\tLoss: 4.351571\n","Train Epoch: 12 [300/1452 (22%)]\tLoss: 4.282471\n","Train Epoch: 12 [640/1452 (43%)]\tLoss: 3.282821\n","Train Epoch: 12 [780/1452 (65%)]\tLoss: 7.273472\n","Train Epoch: 12 [1840/1452 (87%)]\tLoss: 4.339772\n","Epoch 12 - Training: Average loss: 4.3365, Accuracy: 34.28%\n","Evaluation set: Average loss: 5.3464, Accuracy: 209/728 (28.71%), F1-score: 0.2358\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1452 (0%)]\tLoss: 4.336277\n","Train Epoch: 13 [340/1452 (22%)]\tLoss: 4.210078\n","Train Epoch: 13 [620/1452 (43%)]\tLoss: 4.679681\n","Train Epoch: 13 [1290/1452 (65%)]\tLoss: 4.416942\n","Train Epoch: 13 [1200/1452 (87%)]\tLoss: 2.965180\n","Epoch 13 - Training: Average loss: 4.0488, Accuracy: 33.99%\n","Evaluation set: Average loss: 5.1722, Accuracy: 210/728 (28.85%), F1-score: 0.2387\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1452 (0%)]\tLoss: 3.159291\n","Train Epoch: 14 [360/1452 (22%)]\tLoss: 4.781274\n","Train Epoch: 14 [780/1452 (43%)]\tLoss: 3.480782\n","Train Epoch: 14 [1080/1452 (65%)]\tLoss: 3.113724\n","Train Epoch: 14 [1600/1452 (87%)]\tLoss: 3.238341\n","Epoch 14 - Training: Average loss: 3.9461, Accuracy: 37.75%\n","Evaluation set: Average loss: 5.0724, Accuracy: 221/728 (30.36%), F1-score: 0.2474\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1452 (0%)]\tLoss: 5.449555\n","Train Epoch: 15 [330/1452 (22%)]\tLoss: 5.051752\n","Train Epoch: 15 [560/1452 (43%)]\tLoss: 5.027259\n","Train Epoch: 15 [870/1452 (65%)]\tLoss: 4.300478\n","Train Epoch: 15 [960/1452 (87%)]\tLoss: 3.427380\n","Epoch 15 - Training: Average loss: 4.0408, Accuracy: 35.61%\n","Evaluation set: Average loss: 5.2057, Accuracy: 218/728 (29.95%), F1-score: 0.2466\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 16 [0/1452 (0%)]\tLoss: 3.271180\n","Train Epoch: 16 [400/1452 (22%)]\tLoss: 4.343516\n","Train Epoch: 16 [580/1452 (43%)]\tLoss: 3.007199\n","Train Epoch: 16 [900/1452 (65%)]\tLoss: 3.333122\n","Train Epoch: 16 [1480/1452 (87%)]\tLoss: 3.928642\n","Epoch 16 - Training: Average loss: 3.9345, Accuracy: 37.45%\n","Evaluation set: Average loss: 5.0495, Accuracy: 235/728 (32.28%), F1-score: 0.2636\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1452 (0%)]\tLoss: 3.068558\n","Train Epoch: 17 [260/1452 (22%)]\tLoss: 3.096357\n","Train Epoch: 17 [580/1452 (43%)]\tLoss: 4.588964\n","Train Epoch: 17 [930/1452 (65%)]\tLoss: 3.632854\n","Train Epoch: 17 [1280/1452 (87%)]\tLoss: 4.751777\n","Epoch 17 - Training: Average loss: 3.9404, Accuracy: 38.63%\n","Evaluation set: Average loss: 4.6421, Accuracy: 257/728 (35.30%), F1-score: 0.2854\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1452 (0%)]\tLoss: 3.136582\n","Train Epoch: 18 [280/1452 (22%)]\tLoss: 4.976810\n","Train Epoch: 18 [620/1452 (43%)]\tLoss: 4.823087\n","Train Epoch: 18 [870/1452 (65%)]\tLoss: 5.550797\n","Train Epoch: 18 [1400/1452 (87%)]\tLoss: 3.513388\n","Epoch 18 - Training: Average loss: 3.8269, Accuracy: 39.29%\n","Evaluation set: Average loss: 4.5996, Accuracy: 264/728 (36.26%), F1-score: 0.2986\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1452 (0%)]\tLoss: 4.512221\n","Train Epoch: 19 [280/1452 (22%)]\tLoss: 3.112848\n","Train Epoch: 19 [700/1452 (43%)]\tLoss: 3.388357\n","Train Epoch: 19 [960/1452 (65%)]\tLoss: 4.375217\n","Train Epoch: 19 [960/1452 (87%)]\tLoss: 4.767922\n","Epoch 19 - Training: Average loss: 3.6131, Accuracy: 40.86%\n","Evaluation set: Average loss: 4.6693, Accuracy: 268/728 (36.81%), F1-score: 0.3018\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 20 [0/1452 (0%)]\tLoss: 4.190442\n","Train Epoch: 20 [270/1452 (22%)]\tLoss: 2.459850\n","Train Epoch: 20 [680/1452 (43%)]\tLoss: 3.659492\n","Train Epoch: 20 [840/1452 (65%)]\tLoss: 4.541015\n","Train Epoch: 20 [1240/1452 (87%)]\tLoss: 3.597611\n","Epoch 20 - Training: Average loss: 3.7338, Accuracy: 39.80%\n","Evaluation set: Average loss: 4.6872, Accuracy: 265/728 (36.40%), F1-score: 0.2997\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 4.3096, Accuracy: 294/707 (41.58%), F1-score: 0.3364\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject101' 'subject108']\n","Train subjects: ['subject102' 'subject104' 'subject105' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1471 (0%)]\tLoss: 9.425720\n","Train Epoch: 1 [290/1471 (22%)]\tLoss: 11.889615\n","Train Epoch: 1 [780/1471 (43%)]\tLoss: 9.698126\n","Train Epoch: 1 [750/1471 (65%)]\tLoss: 11.768811\n","Train Epoch: 1 [1520/1471 (87%)]\tLoss: 12.507796\n","Epoch 1 - Training: Average loss: 10.4975, Accuracy: 13.99%\n","Evaluation set: Average loss: 9.8140, Accuracy: 61/709 (8.60%), F1-score: 0.0701\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1471 (0%)]\tLoss: 11.281700\n","Train Epoch: 2 [370/1471 (22%)]\tLoss: 11.305045\n","Train Epoch: 2 [640/1471 (43%)]\tLoss: 9.695900\n","Train Epoch: 2 [990/1471 (65%)]\tLoss: 9.535005\n","Train Epoch: 2 [1360/1471 (87%)]\tLoss: 10.976604\n","Epoch 2 - Training: Average loss: 10.3754, Accuracy: 14.87%\n","Evaluation set: Average loss: 9.7566, Accuracy: 68/709 (9.59%), F1-score: 0.0775\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1471 (0%)]\tLoss: 10.025809\n","Train Epoch: 3 [340/1471 (22%)]\tLoss: 11.695146\n","Train Epoch: 3 [820/1471 (43%)]\tLoss: 9.323210\n","Train Epoch: 3 [870/1471 (65%)]\tLoss: 12.903454\n","Train Epoch: 3 [880/1471 (87%)]\tLoss: 9.283128\n","Epoch 3 - Training: Average loss: 9.7916, Accuracy: 17.44%\n","Evaluation set: Average loss: 8.0750, Accuracy: 71/709 (10.01%), F1-score: 0.0846\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1471 (0%)]\tLoss: 11.299565\n","Train Epoch: 4 [250/1471 (22%)]\tLoss: 8.670416\n","Train Epoch: 4 [580/1471 (43%)]\tLoss: 8.994357\n","Train Epoch: 4 [1170/1471 (65%)]\tLoss: 8.819916\n","Train Epoch: 4 [1240/1471 (87%)]\tLoss: 8.297158\n","Epoch 4 - Training: Average loss: 9.1996, Accuracy: 18.88%\n","Evaluation set: Average loss: 8.1652, Accuracy: 86/709 (12.13%), F1-score: 0.1032\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 5 [0/1471 (0%)]\tLoss: 8.945252\n","Train Epoch: 5 [410/1471 (22%)]\tLoss: 10.945179\n","Train Epoch: 5 [620/1471 (43%)]\tLoss: 9.426693\n","Train Epoch: 5 [1080/1471 (65%)]\tLoss: 8.611197\n","Train Epoch: 5 [1360/1471 (87%)]\tLoss: 10.055357\n","Epoch 5 - Training: Average loss: 9.0889, Accuracy: 18.59%\n","Evaluation set: Average loss: 7.9480, Accuracy: 84/709 (11.85%), F1-score: 0.0947\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1471 (0%)]\tLoss: 5.362349\n","Train Epoch: 6 [480/1471 (22%)]\tLoss: 7.961359\n","Train Epoch: 6 [540/1471 (43%)]\tLoss: 8.328559\n","Train Epoch: 6 [990/1471 (65%)]\tLoss: 8.623739\n","Train Epoch: 6 [1640/1471 (87%)]\tLoss: 9.108485\n","Epoch 6 - Training: Average loss: 8.1393, Accuracy: 20.36%\n","Evaluation set: Average loss: 7.4736, Accuracy: 93/709 (13.12%), F1-score: 0.1118\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1471 (0%)]\tLoss: 6.501915\n","Train Epoch: 7 [220/1471 (22%)]\tLoss: 9.615203\n","Train Epoch: 7 [740/1471 (43%)]\tLoss: 8.210079\n","Train Epoch: 7 [1110/1471 (65%)]\tLoss: 7.231093\n","Train Epoch: 7 [1080/1471 (87%)]\tLoss: 8.187156\n","Epoch 7 - Training: Average loss: 8.4229, Accuracy: 20.00%\n","Evaluation set: Average loss: 7.2000, Accuracy: 98/709 (13.82%), F1-score: 0.1190\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1471 (0%)]\tLoss: 8.523216\n","Train Epoch: 8 [330/1471 (22%)]\tLoss: 6.062018\n","Train Epoch: 8 [920/1471 (43%)]\tLoss: 7.427145\n","Train Epoch: 8 [900/1471 (65%)]\tLoss: 8.680418\n","Train Epoch: 8 [1120/1471 (87%)]\tLoss: 7.242381\n","Epoch 8 - Training: Average loss: 7.6590, Accuracy: 21.47%\n","Evaluation set: Average loss: 7.2690, Accuracy: 113/709 (15.94%), F1-score: 0.1330\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1471 (0%)]\tLoss: 7.178850\n","Train Epoch: 9 [350/1471 (22%)]\tLoss: 5.060944\n","Train Epoch: 9 [620/1471 (43%)]\tLoss: 5.475613\n","Train Epoch: 9 [900/1471 (65%)]\tLoss: 6.931504\n","Train Epoch: 9 [1360/1471 (87%)]\tLoss: 4.901344\n","Epoch 9 - Training: Average loss: 7.0609, Accuracy: 21.91%\n","Evaluation set: Average loss: 6.2905, Accuracy: 130/709 (18.34%), F1-score: 0.1530\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1471 (0%)]\tLoss: 6.815145\n","Train Epoch: 10 [280/1471 (22%)]\tLoss: 7.205851\n","Train Epoch: 10 [560/1471 (43%)]\tLoss: 5.608812\n","Train Epoch: 10 [780/1471 (65%)]\tLoss: 7.621490\n","Train Epoch: 10 [1440/1471 (87%)]\tLoss: 5.371756\n","Epoch 10 - Training: Average loss: 6.7276, Accuracy: 23.36%\n","Evaluation set: Average loss: 6.2925, Accuracy: 143/709 (20.17%), F1-score: 0.1634\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 11 [0/1471 (0%)]\tLoss: 8.252945\n","Train Epoch: 11 [290/1471 (22%)]\tLoss: 7.160406\n","Train Epoch: 11 [700/1471 (43%)]\tLoss: 6.643344\n","Train Epoch: 11 [810/1471 (65%)]\tLoss: 5.972205\n","Train Epoch: 11 [1400/1471 (87%)]\tLoss: 5.800704\n","Epoch 11 - Training: Average loss: 6.4235, Accuracy: 26.41%\n","Evaluation set: Average loss: 5.8487, Accuracy: 156/709 (22.00%), F1-score: 0.1776\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1471 (0%)]\tLoss: 7.464166\n","Train Epoch: 12 [260/1471 (22%)]\tLoss: 6.585544\n","Train Epoch: 12 [880/1471 (43%)]\tLoss: 5.268202\n","Train Epoch: 12 [900/1471 (65%)]\tLoss: 6.894227\n","Train Epoch: 12 [1400/1471 (87%)]\tLoss: 6.225105\n","Epoch 12 - Training: Average loss: 6.0633, Accuracy: 24.18%\n","Evaluation set: Average loss: 5.6291, Accuracy: 164/709 (23.13%), F1-score: 0.1895\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1471 (0%)]\tLoss: 5.230268\n","Train Epoch: 13 [320/1471 (22%)]\tLoss: 6.286900\n","Train Epoch: 13 [580/1471 (43%)]\tLoss: 7.146277\n","Train Epoch: 13 [750/1471 (65%)]\tLoss: 7.909760\n","Train Epoch: 13 [1280/1471 (87%)]\tLoss: 5.737422\n","Epoch 13 - Training: Average loss: 5.8797, Accuracy: 27.32%\n","Evaluation set: Average loss: 5.2897, Accuracy: 177/709 (24.96%), F1-score: 0.2120\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1471 (0%)]\tLoss: 6.063318\n","Train Epoch: 14 [450/1471 (22%)]\tLoss: 5.532044\n","Train Epoch: 14 [740/1471 (43%)]\tLoss: 4.919191\n","Train Epoch: 14 [1110/1471 (65%)]\tLoss: 5.519447\n","Train Epoch: 14 [1160/1471 (87%)]\tLoss: 6.257758\n","Epoch 14 - Training: Average loss: 5.6385, Accuracy: 28.32%\n","Evaluation set: Average loss: 5.0397, Accuracy: 178/709 (25.11%), F1-score: 0.2139\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1471 (0%)]\tLoss: 4.974143\n","Train Epoch: 15 [340/1471 (22%)]\tLoss: 5.555900\n","Train Epoch: 15 [600/1471 (43%)]\tLoss: 5.669769\n","Train Epoch: 15 [780/1471 (65%)]\tLoss: 5.541207\n","Train Epoch: 15 [1400/1471 (87%)]\tLoss: 3.673900\n","Epoch 15 - Training: Average loss: 5.4084, Accuracy: 29.36%\n","Evaluation set: Average loss: 4.9342, Accuracy: 197/709 (27.79%), F1-score: 0.2373\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1471 (0%)]\tLoss: 5.226853\n","Train Epoch: 16 [280/1471 (22%)]\tLoss: 6.794339\n","Train Epoch: 16 [840/1471 (43%)]\tLoss: 5.443050\n","Train Epoch: 16 [900/1471 (65%)]\tLoss: 5.686916\n","Train Epoch: 16 [960/1471 (87%)]\tLoss: 7.125663\n","Epoch 16 - Training: Average loss: 5.2025, Accuracy: 28.30%\n","Evaluation set: Average loss: 4.6781, Accuracy: 219/709 (30.89%), F1-score: 0.2658\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1471 (0%)]\tLoss: 3.454766\n","Train Epoch: 17 [350/1471 (22%)]\tLoss: 5.321699\n","Train Epoch: 17 [640/1471 (43%)]\tLoss: 5.915720\n","Train Epoch: 17 [840/1471 (65%)]\tLoss: 5.643709\n","Train Epoch: 17 [1120/1471 (87%)]\tLoss: 5.041553\n","Epoch 17 - Training: Average loss: 4.8811, Accuracy: 31.22%\n","Evaluation set: Average loss: 4.6426, Accuracy: 222/709 (31.31%), F1-score: 0.2683\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1471 (0%)]\tLoss: 5.571586\n","Train Epoch: 18 [280/1471 (22%)]\tLoss: 5.457673\n","Train Epoch: 18 [560/1471 (43%)]\tLoss: 4.175054\n","Train Epoch: 18 [930/1471 (65%)]\tLoss: 5.669927\n","Train Epoch: 18 [960/1471 (87%)]\tLoss: 3.603750\n","Epoch 18 - Training: Average loss: 4.6117, Accuracy: 32.19%\n","Evaluation set: Average loss: 4.3813, Accuracy: 246/709 (34.70%), F1-score: 0.2999\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1471 (0%)]\tLoss: 3.770092\n","Train Epoch: 19 [360/1471 (22%)]\tLoss: 4.191553\n","Train Epoch: 19 [660/1471 (43%)]\tLoss: 4.180435\n","Train Epoch: 19 [1140/1471 (65%)]\tLoss: 4.179100\n","Train Epoch: 19 [1280/1471 (87%)]\tLoss: 7.579441\n","Epoch 19 - Training: Average loss: 4.3687, Accuracy: 32.72%\n","Evaluation set: Average loss: 4.2280, Accuracy: 253/709 (35.68%), F1-score: 0.3102\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1471 (0%)]\tLoss: 4.682815\n","Train Epoch: 20 [330/1471 (22%)]\tLoss: 3.727418\n","Train Epoch: 20 [800/1471 (43%)]\tLoss: 4.331559\n","Train Epoch: 20 [990/1471 (65%)]\tLoss: 4.146773\n","Train Epoch: 20 [1320/1471 (87%)]\tLoss: 3.874386\n","Epoch 20 - Training: Average loss: 4.0741, Accuracy: 35.51%\n","Evaluation set: Average loss: 3.8126, Accuracy: 273/709 (38.50%), F1-score: 0.3404\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 5.0157, Accuracy: 227/707 (32.11%), F1-score: 0.2948\n","\n","Outer Fold 4 is starting ...\n","Test subjects: ['subject101' 'subject104']\n","Train-Validation subjects: ['subject102' 'subject103' 'subject105' 'subject106' 'subject107'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject102' 'subject105']\n","Train subjects: ['subject103' 'subject106' 'subject107' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1426 (0%)]\tLoss: 7.463390\n","Train Epoch: 1 [220/1426 (22%)]\tLoss: 6.036600\n","Train Epoch: 1 [540/1426 (44%)]\tLoss: 6.685976\n","Train Epoch: 1 [1320/1426 (67%)]\tLoss: 6.752883\n","Train Epoch: 1 [1360/1426 (89%)]\tLoss: 6.238689\n","Epoch 1 - Training: Average loss: 7.2537, Accuracy: 19.78%\n","Evaluation set: Average loss: 9.5670, Accuracy: 130/752 (17.29%), F1-score: 0.1337\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1426 (0%)]\tLoss: 7.638113\n","Train Epoch: 2 [290/1426 (22%)]\tLoss: 6.480011\n","Train Epoch: 2 [580/1426 (44%)]\tLoss: 8.023399\n","Train Epoch: 2 [930/1426 (67%)]\tLoss: 6.876013\n","Train Epoch: 2 [1080/1426 (89%)]\tLoss: 6.656732\n","Epoch 2 - Training: Average loss: 7.0478, Accuracy: 20.00%\n","Evaluation set: Average loss: 10.2540, Accuracy: 132/752 (17.55%), F1-score: 0.1368\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 3 [0/1426 (0%)]\tLoss: 7.546839\n","Train Epoch: 3 [390/1426 (22%)]\tLoss: 7.591151\n","Train Epoch: 3 [540/1426 (44%)]\tLoss: 7.320925\n","Train Epoch: 3 [720/1426 (67%)]\tLoss: 5.501614\n","Train Epoch: 3 [1520/1426 (89%)]\tLoss: 7.386916\n","Epoch 3 - Training: Average loss: 6.4938, Accuracy: 21.26%\n","Evaluation set: Average loss: 10.0475, Accuracy: 137/752 (18.22%), F1-score: 0.1465\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 4 [0/1426 (0%)]\tLoss: 5.854980\n","Train Epoch: 4 [410/1426 (22%)]\tLoss: 6.740366\n","Train Epoch: 4 [660/1426 (44%)]\tLoss: 5.292282\n","Train Epoch: 4 [780/1426 (67%)]\tLoss: 7.190139\n","Train Epoch: 4 [1120/1426 (89%)]\tLoss: 5.979829\n","Epoch 4 - Training: Average loss: 6.4483, Accuracy: 22.18%\n","Evaluation set: Average loss: 10.6529, Accuracy: 148/752 (19.68%), F1-score: 0.1601\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 5 [0/1426 (0%)]\tLoss: 6.134957\n","Train Epoch: 5 [280/1426 (22%)]\tLoss: 6.645501\n","Train Epoch: 5 [840/1426 (44%)]\tLoss: 5.657833\n","Train Epoch: 5 [630/1426 (67%)]\tLoss: 6.197628\n","Train Epoch: 5 [1600/1426 (89%)]\tLoss: 6.090269\n","Epoch 5 - Training: Average loss: 6.4867, Accuracy: 21.32%\n","Evaluation set: Average loss: 9.8828, Accuracy: 140/752 (18.62%), F1-score: 0.1519\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 6 [0/1426 (0%)]\tLoss: 4.586204\n","Train Epoch: 6 [430/1426 (22%)]\tLoss: 5.169127\n","Train Epoch: 6 [540/1426 (44%)]\tLoss: 7.721027\n","Train Epoch: 6 [810/1426 (67%)]\tLoss: 7.972248\n","Train Epoch: 6 [1160/1426 (89%)]\tLoss: 6.863102\n","Epoch 6 - Training: Average loss: 6.1597, Accuracy: 23.59%\n","Evaluation set: Average loss: 9.7854, Accuracy: 135/752 (17.95%), F1-score: 0.1532\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 7 [0/1426 (0%)]\tLoss: 6.894650\n","Train Epoch: 7 [220/1426 (22%)]\tLoss: 7.747801\n","Train Epoch: 7 [560/1426 (44%)]\tLoss: 6.544197\n","Train Epoch: 7 [1080/1426 (67%)]\tLoss: 5.124000\n","Train Epoch: 7 [1440/1426 (89%)]\tLoss: 6.148094\n","Epoch 7 - Training: Average loss: 6.1749, Accuracy: 23.17%\n","Evaluation set: Average loss: 9.6448, Accuracy: 141/752 (18.75%), F1-score: 0.1556\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 8 [0/1426 (0%)]\tLoss: 5.800722\n","Train Epoch: 8 [280/1426 (22%)]\tLoss: 7.850313\n","Train Epoch: 8 [680/1426 (44%)]\tLoss: 4.682973\n","Train Epoch: 8 [750/1426 (67%)]\tLoss: 6.618580\n","Train Epoch: 8 [1400/1426 (89%)]\tLoss: 6.561186\n","Epoch 8 - Training: Average loss: 6.2840, Accuracy: 23.41%\n","Evaluation set: Average loss: 9.3398, Accuracy: 133/752 (17.69%), F1-score: 0.1490\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1426 (0%)]\tLoss: 5.857322\n","Train Epoch: 9 [290/1426 (22%)]\tLoss: 4.646597\n","Train Epoch: 9 [600/1426 (44%)]\tLoss: 5.989250\n","Train Epoch: 9 [870/1426 (67%)]\tLoss: 7.672533\n","Train Epoch: 9 [1480/1426 (89%)]\tLoss: 7.133770\n","Epoch 9 - Training: Average loss: 6.1034, Accuracy: 22.74%\n","Evaluation set: Average loss: 9.7583, Accuracy: 147/752 (19.55%), F1-score: 0.1634\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1426 (0%)]\tLoss: 5.434766\n","Train Epoch: 10 [370/1426 (22%)]\tLoss: 5.643629\n","Train Epoch: 10 [640/1426 (44%)]\tLoss: 6.048777\n","Train Epoch: 10 [780/1426 (67%)]\tLoss: 5.793628\n","Train Epoch: 10 [1400/1426 (89%)]\tLoss: 6.573382\n","Epoch 10 - Training: Average loss: 6.1592, Accuracy: 23.39%\n","Evaluation set: Average loss: 9.4975, Accuracy: 145/752 (19.28%), F1-score: 0.1573\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 11 [0/1426 (0%)]\tLoss: 7.016455\n","Train Epoch: 11 [310/1426 (22%)]\tLoss: 4.983506\n","Train Epoch: 11 [640/1426 (44%)]\tLoss: 5.632744\n","Train Epoch: 11 [1170/1426 (67%)]\tLoss: 6.367995\n","Train Epoch: 11 [1440/1426 (89%)]\tLoss: 5.580725\n","Epoch 11 - Training: Average loss: 6.2993, Accuracy: 21.50%\n","Evaluation set: Average loss: 9.5771, Accuracy: 146/752 (19.41%), F1-score: 0.1621\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 12 [0/1426 (0%)]\tLoss: 7.557875\n","Train Epoch: 12 [290/1426 (22%)]\tLoss: 5.787054\n","Train Epoch: 12 [760/1426 (44%)]\tLoss: 5.391943\n","Train Epoch: 12 [750/1426 (67%)]\tLoss: 5.235456\n","Train Epoch: 12 [1360/1426 (89%)]\tLoss: 5.246477\n","Epoch 12 - Training: Average loss: 6.1279, Accuracy: 21.29%\n","Evaluation set: Average loss: 9.1938, Accuracy: 151/752 (20.08%), F1-score: 0.1659\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1426 (0%)]\tLoss: 4.702414\n","Train Epoch: 13 [330/1426 (22%)]\tLoss: 5.584378\n","Train Epoch: 13 [640/1426 (44%)]\tLoss: 5.968466\n","Train Epoch: 13 [780/1426 (67%)]\tLoss: 6.522984\n","Train Epoch: 13 [1080/1426 (89%)]\tLoss: 5.025288\n","Epoch 13 - Training: Average loss: 6.1084, Accuracy: 21.99%\n","Evaluation set: Average loss: 10.7258, Accuracy: 144/752 (19.15%), F1-score: 0.1610\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 14 [0/1426 (0%)]\tLoss: 5.438467\n","Train Epoch: 14 [310/1426 (22%)]\tLoss: 6.272120\n","Train Epoch: 14 [580/1426 (44%)]\tLoss: 6.031757\n","Train Epoch: 14 [840/1426 (67%)]\tLoss: 6.588987\n","Train Epoch: 14 [1440/1426 (89%)]\tLoss: 5.801403\n","Epoch 14 - Training: Average loss: 6.0638, Accuracy: 21.54%\n","Evaluation set: Average loss: 8.4138, Accuracy: 148/752 (19.68%), F1-score: 0.1615\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1426 (0%)]\tLoss: 7.026803\n","Train Epoch: 15 [470/1426 (22%)]\tLoss: 6.188006\n","Train Epoch: 15 [740/1426 (44%)]\tLoss: 4.809525\n","Train Epoch: 15 [960/1426 (67%)]\tLoss: 5.515522\n","Train Epoch: 15 [1040/1426 (89%)]\tLoss: 6.073589\n","Epoch 15 - Training: Average loss: 5.8953, Accuracy: 22.25%\n","Evaluation set: Average loss: 8.3057, Accuracy: 146/752 (19.41%), F1-score: 0.1579\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1426 (0%)]\tLoss: 5.315425\n","Train Epoch: 16 [290/1426 (22%)]\tLoss: 6.455754\n","Train Epoch: 16 [760/1426 (44%)]\tLoss: 6.971581\n","Train Epoch: 16 [1140/1426 (67%)]\tLoss: 5.557259\n","Train Epoch: 16 [1240/1426 (89%)]\tLoss: 6.241668\n","Epoch 16 - Training: Average loss: 5.6939, Accuracy: 23.11%\n","Evaluation set: Average loss: 8.2828, Accuracy: 143/752 (19.02%), F1-score: 0.1607\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1426 (0%)]\tLoss: 5.502089\n","Train Epoch: 17 [320/1426 (22%)]\tLoss: 7.069883\n","Train Epoch: 17 [540/1426 (44%)]\tLoss: 4.707397\n","Train Epoch: 17 [750/1426 (67%)]\tLoss: 5.093683\n","Train Epoch: 17 [920/1426 (89%)]\tLoss: 5.799532\n","Epoch 17 - Training: Average loss: 5.9270, Accuracy: 22.73%\n","Evaluation set: Average loss: 8.7685, Accuracy: 151/752 (20.08%), F1-score: 0.1673\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1426 (0%)]\tLoss: 5.570109\n","Train Epoch: 18 [320/1426 (22%)]\tLoss: 5.788561\n","Train Epoch: 18 [880/1426 (44%)]\tLoss: 5.769931\n","Train Epoch: 18 [840/1426 (67%)]\tLoss: 5.224583\n","Train Epoch: 18 [960/1426 (89%)]\tLoss: 5.317261\n","Epoch 18 - Training: Average loss: 5.5908, Accuracy: 23.81%\n","Evaluation set: Average loss: 10.0389, Accuracy: 138/752 (18.35%), F1-score: 0.1581\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 19 [0/1426 (0%)]\tLoss: 5.958040\n","Train Epoch: 19 [360/1426 (22%)]\tLoss: 6.152800\n","Train Epoch: 19 [720/1426 (44%)]\tLoss: 5.045834\n","Train Epoch: 19 [780/1426 (67%)]\tLoss: 4.576726\n","Train Epoch: 19 [1280/1426 (89%)]\tLoss: 5.095512\n","Epoch 19 - Training: Average loss: 5.7269, Accuracy: 22.55%\n","Evaluation set: Average loss: 9.4241, Accuracy: 140/752 (18.62%), F1-score: 0.1583\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 20 [0/1426 (0%)]\tLoss: 5.273581\n","Train Epoch: 20 [260/1426 (22%)]\tLoss: 5.055466\n","Train Epoch: 20 [640/1426 (44%)]\tLoss: 6.473022\n","Train Epoch: 20 [1050/1426 (67%)]\tLoss: 5.098650\n","Train Epoch: 20 [1360/1426 (89%)]\tLoss: 5.408885\n","Epoch 20 - Training: Average loss: 5.7937, Accuracy: 24.00%\n","Evaluation set: Average loss: 8.0546, Accuracy: 144/752 (19.15%), F1-score: 0.1630\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 7.5951, Accuracy: 156/709 (22.00%), F1-score: 0.1670\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject103' 'subject108']\n","Train subjects: ['subject102' 'subject105' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1466 (0%)]\tLoss: 8.289318\n","Train Epoch: 1 [350/1466 (22%)]\tLoss: 8.156281\n","Train Epoch: 1 [720/1466 (43%)]\tLoss: 8.663239\n","Train Epoch: 1 [900/1466 (65%)]\tLoss: 9.572957\n","Train Epoch: 1 [1040/1466 (87%)]\tLoss: 9.542991\n","Epoch 1 - Training: Average loss: 8.4033, Accuracy: 12.54%\n","Evaluation set: Average loss: 7.1188, Accuracy: 89/712 (12.50%), F1-score: 0.1057\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1466 (0%)]\tLoss: 7.852771\n","Train Epoch: 2 [300/1466 (22%)]\tLoss: 9.005122\n","Train Epoch: 2 [640/1466 (43%)]\tLoss: 7.724828\n","Train Epoch: 2 [870/1466 (65%)]\tLoss: 7.829278\n","Train Epoch: 2 [1320/1466 (87%)]\tLoss: 7.981921\n","Epoch 2 - Training: Average loss: 7.6662, Accuracy: 16.06%\n","Evaluation set: Average loss: 6.9134, Accuracy: 91/712 (12.78%), F1-score: 0.1042\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1466 (0%)]\tLoss: 6.211672\n","Train Epoch: 3 [290/1466 (22%)]\tLoss: 6.867005\n","Train Epoch: 3 [620/1466 (43%)]\tLoss: 7.355743\n","Train Epoch: 3 [990/1466 (65%)]\tLoss: 8.996533\n","Train Epoch: 3 [1440/1466 (87%)]\tLoss: 6.373221\n","Epoch 3 - Training: Average loss: 7.3626, Accuracy: 15.48%\n","Evaluation set: Average loss: 6.7927, Accuracy: 99/712 (13.90%), F1-score: 0.1087\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1466 (0%)]\tLoss: 7.618616\n","Train Epoch: 4 [290/1466 (22%)]\tLoss: 8.562931\n","Train Epoch: 4 [580/1466 (43%)]\tLoss: 6.856322\n","Train Epoch: 4 [780/1466 (65%)]\tLoss: 7.765206\n","Train Epoch: 4 [2000/1466 (87%)]\tLoss: 6.436874\n","Epoch 4 - Training: Average loss: 7.1271, Accuracy: 17.03%\n","Evaluation set: Average loss: 6.7997, Accuracy: 97/712 (13.62%), F1-score: 0.1092\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 5 [0/1466 (0%)]\tLoss: 6.516510\n","Train Epoch: 5 [370/1466 (22%)]\tLoss: 8.090662\n","Train Epoch: 5 [920/1466 (43%)]\tLoss: 6.630216\n","Train Epoch: 5 [1170/1466 (65%)]\tLoss: 7.621106\n","Train Epoch: 5 [880/1466 (87%)]\tLoss: 5.581508\n","Epoch 5 - Training: Average loss: 6.7800, Accuracy: 16.64%\n","Evaluation set: Average loss: 6.9170, Accuracy: 101/712 (14.19%), F1-score: 0.1122\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 6 [0/1466 (0%)]\tLoss: 6.662923\n","Train Epoch: 6 [270/1466 (22%)]\tLoss: 8.233312\n","Train Epoch: 6 [680/1466 (43%)]\tLoss: 6.888187\n","Train Epoch: 6 [930/1466 (65%)]\tLoss: 5.656241\n","Train Epoch: 6 [1240/1466 (87%)]\tLoss: 7.374681\n","Epoch 6 - Training: Average loss: 6.4742, Accuracy: 19.97%\n","Evaluation set: Average loss: 6.3771, Accuracy: 108/712 (15.17%), F1-score: 0.1249\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1466 (0%)]\tLoss: 7.322488\n","Train Epoch: 7 [360/1466 (22%)]\tLoss: 5.981777\n","Train Epoch: 7 [660/1466 (43%)]\tLoss: 5.403845\n","Train Epoch: 7 [990/1466 (65%)]\tLoss: 5.929871\n","Train Epoch: 7 [1360/1466 (87%)]\tLoss: 6.973995\n","Epoch 7 - Training: Average loss: 6.2386, Accuracy: 18.50%\n","Evaluation set: Average loss: 5.7180, Accuracy: 115/712 (16.15%), F1-score: 0.1358\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1466 (0%)]\tLoss: 5.860576\n","Train Epoch: 8 [290/1466 (22%)]\tLoss: 6.694176\n","Train Epoch: 8 [580/1466 (43%)]\tLoss: 6.966007\n","Train Epoch: 8 [1260/1466 (65%)]\tLoss: 6.080810\n","Train Epoch: 8 [1280/1466 (87%)]\tLoss: 4.312855\n","Epoch 8 - Training: Average loss: 5.8012, Accuracy: 22.54%\n","Evaluation set: Average loss: 5.9949, Accuracy: 121/712 (16.99%), F1-score: 0.1435\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1466 (0%)]\tLoss: 4.717907\n","Train Epoch: 9 [300/1466 (22%)]\tLoss: 7.255938\n","Train Epoch: 9 [520/1466 (43%)]\tLoss: 5.123669\n","Train Epoch: 9 [1050/1466 (65%)]\tLoss: 5.467243\n","Train Epoch: 9 [1160/1466 (87%)]\tLoss: 6.345105\n","Epoch 9 - Training: Average loss: 5.6094, Accuracy: 25.39%\n","Evaluation set: Average loss: 5.7017, Accuracy: 141/712 (19.80%), F1-score: 0.1695\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1466 (0%)]\tLoss: 4.220406\n","Train Epoch: 10 [260/1466 (22%)]\tLoss: 7.759723\n","Train Epoch: 10 [600/1466 (43%)]\tLoss: 5.051435\n","Train Epoch: 10 [870/1466 (65%)]\tLoss: 4.527524\n","Train Epoch: 10 [1160/1466 (87%)]\tLoss: 5.710220\n","Epoch 10 - Training: Average loss: 5.5620, Accuracy: 26.24%\n","Evaluation set: Average loss: 5.4828, Accuracy: 133/712 (18.68%), F1-score: 0.1545\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1466 (0%)]\tLoss: 4.623442\n","Train Epoch: 11 [290/1466 (22%)]\tLoss: 5.849738\n","Train Epoch: 11 [620/1466 (43%)]\tLoss: 5.538603\n","Train Epoch: 11 [930/1466 (65%)]\tLoss: 5.851629\n","Train Epoch: 11 [1680/1466 (87%)]\tLoss: 5.042960\n","Epoch 11 - Training: Average loss: 5.5538, Accuracy: 25.12%\n","Evaluation set: Average loss: 5.2330, Accuracy: 159/712 (22.33%), F1-score: 0.1800\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1466 (0%)]\tLoss: 4.840133\n","Train Epoch: 12 [450/1466 (22%)]\tLoss: 6.440548\n","Train Epoch: 12 [720/1466 (43%)]\tLoss: 4.614145\n","Train Epoch: 12 [990/1466 (65%)]\tLoss: 5.296375\n","Train Epoch: 12 [1240/1466 (87%)]\tLoss: 5.478073\n","Epoch 12 - Training: Average loss: 5.2466, Accuracy: 27.15%\n","Evaluation set: Average loss: 5.1452, Accuracy: 165/712 (23.17%), F1-score: 0.1980\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1466 (0%)]\tLoss: 5.560943\n","Train Epoch: 13 [340/1466 (22%)]\tLoss: 3.353325\n","Train Epoch: 13 [640/1466 (43%)]\tLoss: 4.532913\n","Train Epoch: 13 [930/1466 (65%)]\tLoss: 4.855060\n","Train Epoch: 13 [1360/1466 (87%)]\tLoss: 3.726602\n","Epoch 13 - Training: Average loss: 4.9105, Accuracy: 31.54%\n","Evaluation set: Average loss: 4.9282, Accuracy: 168/712 (23.60%), F1-score: 0.2024\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1466 (0%)]\tLoss: 5.773423\n","Train Epoch: 14 [380/1466 (22%)]\tLoss: 5.311398\n","Train Epoch: 14 [600/1466 (43%)]\tLoss: 4.337271\n","Train Epoch: 14 [1080/1466 (65%)]\tLoss: 4.102139\n","Train Epoch: 14 [1680/1466 (87%)]\tLoss: 5.410922\n","Epoch 14 - Training: Average loss: 4.5794, Accuracy: 34.83%\n","Evaluation set: Average loss: 5.0494, Accuracy: 167/712 (23.46%), F1-score: 0.1954\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 15 [0/1466 (0%)]\tLoss: 5.191076\n","Train Epoch: 15 [400/1466 (22%)]\tLoss: 5.591390\n","Train Epoch: 15 [760/1466 (43%)]\tLoss: 3.983061\n","Train Epoch: 15 [960/1466 (65%)]\tLoss: 5.020544\n","Train Epoch: 15 [1080/1466 (87%)]\tLoss: 3.897683\n","Epoch 15 - Training: Average loss: 4.7608, Accuracy: 30.81%\n","Evaluation set: Average loss: 5.0169, Accuracy: 174/712 (24.44%), F1-score: 0.2033\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 16 [0/1466 (0%)]\tLoss: 4.240139\n","Train Epoch: 16 [380/1466 (22%)]\tLoss: 4.767399\n","Train Epoch: 16 [600/1466 (43%)]\tLoss: 5.245811\n","Train Epoch: 16 [840/1466 (65%)]\tLoss: 4.590247\n","Train Epoch: 16 [1160/1466 (87%)]\tLoss: 6.501732\n","Epoch 16 - Training: Average loss: 4.8649, Accuracy: 31.34%\n","Evaluation set: Average loss: 4.9827, Accuracy: 172/712 (24.16%), F1-score: 0.2141\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 17 [0/1466 (0%)]\tLoss: 5.162449\n","Train Epoch: 17 [350/1466 (22%)]\tLoss: 5.524476\n","Train Epoch: 17 [680/1466 (43%)]\tLoss: 3.904508\n","Train Epoch: 17 [990/1466 (65%)]\tLoss: 3.463801\n","Train Epoch: 17 [1280/1466 (87%)]\tLoss: 4.074631\n","Epoch 17 - Training: Average loss: 4.4872, Accuracy: 33.51%\n","Evaluation set: Average loss: 4.8473, Accuracy: 179/712 (25.14%), F1-score: 0.2147\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1466 (0%)]\tLoss: 4.880956\n","Train Epoch: 18 [210/1466 (22%)]\tLoss: 5.488485\n","Train Epoch: 18 [740/1466 (43%)]\tLoss: 4.693738\n","Train Epoch: 18 [810/1466 (65%)]\tLoss: 4.669322\n","Train Epoch: 18 [1160/1466 (87%)]\tLoss: 4.828450\n","Epoch 18 - Training: Average loss: 4.5711, Accuracy: 30.77%\n","Evaluation set: Average loss: 4.4819, Accuracy: 192/712 (26.97%), F1-score: 0.2300\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1466 (0%)]\tLoss: 3.626101\n","Train Epoch: 19 [360/1466 (22%)]\tLoss: 4.212026\n","Train Epoch: 19 [740/1466 (43%)]\tLoss: 3.311371\n","Train Epoch: 19 [1020/1466 (65%)]\tLoss: 4.379405\n","Train Epoch: 19 [1240/1466 (87%)]\tLoss: 6.514532\n","Epoch 19 - Training: Average loss: 4.4747, Accuracy: 35.06%\n","Evaluation set: Average loss: 4.5620, Accuracy: 189/712 (26.54%), F1-score: 0.2301\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 20 [0/1466 (0%)]\tLoss: 5.356833\n","Train Epoch: 20 [230/1466 (22%)]\tLoss: 5.792510\n","Train Epoch: 20 [820/1466 (43%)]\tLoss: 4.923117\n","Train Epoch: 20 [1050/1466 (65%)]\tLoss: 3.306655\n","Train Epoch: 20 [1400/1466 (87%)]\tLoss: 4.025224\n","Epoch 20 - Training: Average loss: 4.4603, Accuracy: 32.35%\n","Evaluation set: Average loss: 4.9047, Accuracy: 189/712 (26.54%), F1-score: 0.2278\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 4.6606, Accuracy: 186/709 (26.23%), F1-score: 0.2267\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject106' 'subject107']\n","Train subjects: ['subject102' 'subject103' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1464 (0%)]\tLoss: 9.607776\n","Train Epoch: 1 [310/1464 (22%)]\tLoss: 8.411060\n","Train Epoch: 1 [660/1464 (43%)]\tLoss: 8.074698\n","Train Epoch: 1 [1050/1464 (65%)]\tLoss: 7.562699\n","Train Epoch: 1 [1400/1464 (87%)]\tLoss: 10.293065\n","Epoch 1 - Training: Average loss: 8.9959, Accuracy: 12.47%\n","Evaluation set: Average loss: 8.7495, Accuracy: 103/714 (14.43%), F1-score: 0.1075\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1464 (0%)]\tLoss: 8.208570\n","Train Epoch: 2 [270/1464 (22%)]\tLoss: 10.470430\n","Train Epoch: 2 [920/1464 (43%)]\tLoss: 8.018706\n","Train Epoch: 2 [780/1464 (65%)]\tLoss: 6.736745\n","Train Epoch: 2 [1200/1464 (87%)]\tLoss: 6.540472\n","Epoch 2 - Training: Average loss: 7.8003, Accuracy: 15.37%\n","Evaluation set: Average loss: 8.2175, Accuracy: 109/714 (15.27%), F1-score: 0.1165\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1464 (0%)]\tLoss: 7.799761\n","Train Epoch: 3 [300/1464 (22%)]\tLoss: 5.105722\n","Train Epoch: 3 [700/1464 (43%)]\tLoss: 6.139557\n","Train Epoch: 3 [1020/1464 (65%)]\tLoss: 4.916164\n","Train Epoch: 3 [1640/1464 (87%)]\tLoss: 6.823901\n","Epoch 3 - Training: Average loss: 6.8349, Accuracy: 19.23%\n","Evaluation set: Average loss: 8.1264, Accuracy: 120/714 (16.81%), F1-score: 0.1295\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1464 (0%)]\tLoss: 6.624695\n","Train Epoch: 4 [320/1464 (22%)]\tLoss: 6.336305\n","Train Epoch: 4 [380/1464 (43%)]\tLoss: 7.992229\n","Train Epoch: 4 [1170/1464 (65%)]\tLoss: 5.420290\n","Train Epoch: 4 [1040/1464 (87%)]\tLoss: 5.926178\n","Epoch 4 - Training: Average loss: 6.6421, Accuracy: 18.39%\n","Evaluation set: Average loss: 7.7881, Accuracy: 133/714 (18.63%), F1-score: 0.1560\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1464 (0%)]\tLoss: 5.448928\n","Train Epoch: 5 [290/1464 (22%)]\tLoss: 6.022750\n","Train Epoch: 5 [960/1464 (43%)]\tLoss: 6.416477\n","Train Epoch: 5 [810/1464 (65%)]\tLoss: 6.272548\n","Train Epoch: 5 [760/1464 (87%)]\tLoss: 6.440775\n","Epoch 5 - Training: Average loss: 6.1997, Accuracy: 20.30%\n","Evaluation set: Average loss: 7.1093, Accuracy: 164/714 (22.97%), F1-score: 0.2047\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1464 (0%)]\tLoss: 7.295630\n","Train Epoch: 6 [310/1464 (22%)]\tLoss: 6.046714\n","Train Epoch: 6 [640/1464 (43%)]\tLoss: 6.527349\n","Train Epoch: 6 [750/1464 (65%)]\tLoss: 6.208685\n","Train Epoch: 6 [1440/1464 (87%)]\tLoss: 6.220049\n","Epoch 6 - Training: Average loss: 6.0860, Accuracy: 23.64%\n","Evaluation set: Average loss: 6.8949, Accuracy: 176/714 (24.65%), F1-score: 0.2150\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1464 (0%)]\tLoss: 5.213763\n","Train Epoch: 7 [350/1464 (22%)]\tLoss: 5.365676\n","Train Epoch: 7 [540/1464 (43%)]\tLoss: 3.489373\n","Train Epoch: 7 [1230/1464 (65%)]\tLoss: 4.903203\n","Train Epoch: 7 [1680/1464 (87%)]\tLoss: 5.875909\n","Epoch 7 - Training: Average loss: 5.4115, Accuracy: 29.02%\n","Evaluation set: Average loss: 6.7045, Accuracy: 192/714 (26.89%), F1-score: 0.2313\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1464 (0%)]\tLoss: 7.171256\n","Train Epoch: 8 [330/1464 (22%)]\tLoss: 6.435247\n","Train Epoch: 8 [560/1464 (43%)]\tLoss: 4.276280\n","Train Epoch: 8 [990/1464 (65%)]\tLoss: 5.689753\n","Train Epoch: 8 [1520/1464 (87%)]\tLoss: 5.425323\n","Epoch 8 - Training: Average loss: 5.5129, Accuracy: 31.62%\n","Evaluation set: Average loss: 6.0950, Accuracy: 212/714 (29.69%), F1-score: 0.2526\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1464 (0%)]\tLoss: 5.169155\n","Train Epoch: 9 [330/1464 (22%)]\tLoss: 5.479393\n","Train Epoch: 9 [600/1464 (43%)]\tLoss: 5.403569\n","Train Epoch: 9 [1350/1464 (65%)]\tLoss: 5.481349\n","Train Epoch: 9 [1000/1464 (87%)]\tLoss: 4.144180\n","Epoch 9 - Training: Average loss: 5.1525, Accuracy: 30.74%\n","Evaluation set: Average loss: 5.9426, Accuracy: 229/714 (32.07%), F1-score: 0.2787\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1464 (0%)]\tLoss: 5.574330\n","Train Epoch: 10 [340/1464 (22%)]\tLoss: 4.998497\n","Train Epoch: 10 [520/1464 (43%)]\tLoss: 4.190244\n","Train Epoch: 10 [1200/1464 (65%)]\tLoss: 4.276525\n","Train Epoch: 10 [1200/1464 (87%)]\tLoss: 4.379295\n","Epoch 10 - Training: Average loss: 5.0575, Accuracy: 32.13%\n","Evaluation set: Average loss: 6.0085, Accuracy: 218/714 (30.53%), F1-score: 0.2547\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 11 [0/1464 (0%)]\tLoss: 6.038816\n","Train Epoch: 11 [330/1464 (22%)]\tLoss: 5.195840\n","Train Epoch: 11 [820/1464 (43%)]\tLoss: 4.660870\n","Train Epoch: 11 [1080/1464 (65%)]\tLoss: 5.681145\n","Train Epoch: 11 [1000/1464 (87%)]\tLoss: 4.437625\n","Epoch 11 - Training: Average loss: 4.7125, Accuracy: 33.54%\n","Evaluation set: Average loss: 5.5170, Accuracy: 220/714 (30.81%), F1-score: 0.2580\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1464 (0%)]\tLoss: 4.156446\n","Train Epoch: 12 [230/1464 (22%)]\tLoss: 2.923761\n","Train Epoch: 12 [740/1464 (43%)]\tLoss: 5.227216\n","Train Epoch: 12 [810/1464 (65%)]\tLoss: 5.350324\n","Train Epoch: 12 [1000/1464 (87%)]\tLoss: 6.428306\n","Epoch 12 - Training: Average loss: 4.6108, Accuracy: 35.44%\n","Evaluation set: Average loss: 5.5638, Accuracy: 233/714 (32.63%), F1-score: 0.2851\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 13 [0/1464 (0%)]\tLoss: 4.391645\n","Train Epoch: 13 [270/1464 (22%)]\tLoss: 3.403742\n","Train Epoch: 13 [660/1464 (43%)]\tLoss: 4.784922\n","Train Epoch: 13 [1050/1464 (65%)]\tLoss: 4.315495\n","Train Epoch: 13 [1360/1464 (87%)]\tLoss: 5.810416\n","Epoch 13 - Training: Average loss: 4.7545, Accuracy: 37.24%\n","Evaluation set: Average loss: 5.3247, Accuracy: 235/714 (32.91%), F1-score: 0.2978\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1464 (0%)]\tLoss: 3.480336\n","Train Epoch: 14 [300/1464 (22%)]\tLoss: 3.206877\n","Train Epoch: 14 [640/1464 (43%)]\tLoss: 4.109904\n","Train Epoch: 14 [990/1464 (65%)]\tLoss: 4.073132\n","Train Epoch: 14 [1600/1464 (87%)]\tLoss: 5.795300\n","Epoch 14 - Training: Average loss: 4.6937, Accuracy: 38.41%\n","Evaluation set: Average loss: 5.3538, Accuracy: 236/714 (33.05%), F1-score: 0.2875\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 15 [0/1464 (0%)]\tLoss: 4.596745\n","Train Epoch: 15 [250/1464 (22%)]\tLoss: 4.967311\n","Train Epoch: 15 [720/1464 (43%)]\tLoss: 4.495632\n","Train Epoch: 15 [840/1464 (65%)]\tLoss: 5.591629\n","Train Epoch: 15 [1360/1464 (87%)]\tLoss: 4.850217\n","Epoch 15 - Training: Average loss: 4.5013, Accuracy: 36.07%\n","Evaluation set: Average loss: 5.4267, Accuracy: 228/714 (31.93%), F1-score: 0.2615\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 16 [0/1464 (0%)]\tLoss: 4.986367\n","Train Epoch: 16 [360/1464 (22%)]\tLoss: 5.396384\n","Train Epoch: 16 [740/1464 (43%)]\tLoss: 4.171422\n","Train Epoch: 16 [870/1464 (65%)]\tLoss: 4.421007\n","Train Epoch: 16 [1240/1464 (87%)]\tLoss: 4.978322\n","Epoch 16 - Training: Average loss: 4.5711, Accuracy: 36.56%\n","Evaluation set: Average loss: 5.2859, Accuracy: 237/714 (33.19%), F1-score: 0.2739\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1464 (0%)]\tLoss: 5.742516\n","Train Epoch: 17 [300/1464 (22%)]\tLoss: 2.963011\n","Train Epoch: 17 [540/1464 (43%)]\tLoss: 4.631765\n","Train Epoch: 17 [1110/1464 (65%)]\tLoss: 4.873164\n","Train Epoch: 17 [1320/1464 (87%)]\tLoss: 2.947712\n","Epoch 17 - Training: Average loss: 4.3483, Accuracy: 37.80%\n","Evaluation set: Average loss: 5.1994, Accuracy: 234/714 (32.77%), F1-score: 0.2720\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1464 (0%)]\tLoss: 4.951766\n","Train Epoch: 18 [330/1464 (22%)]\tLoss: 3.952079\n","Train Epoch: 18 [640/1464 (43%)]\tLoss: 6.116956\n","Train Epoch: 18 [840/1464 (65%)]\tLoss: 2.760054\n","Train Epoch: 18 [1280/1464 (87%)]\tLoss: 4.765799\n","Epoch 18 - Training: Average loss: 4.1409, Accuracy: 38.70%\n","Evaluation set: Average loss: 5.1384, Accuracy: 260/714 (36.41%), F1-score: 0.2968\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1464 (0%)]\tLoss: 4.748797\n","Train Epoch: 19 [340/1464 (22%)]\tLoss: 4.815695\n","Train Epoch: 19 [700/1464 (43%)]\tLoss: 5.002723\n","Train Epoch: 19 [1020/1464 (65%)]\tLoss: 4.492395\n","Train Epoch: 19 [1240/1464 (87%)]\tLoss: 4.027802\n","Epoch 19 - Training: Average loss: 4.4301, Accuracy: 37.76%\n","Evaluation set: Average loss: 4.7390, Accuracy: 268/714 (37.54%), F1-score: 0.3236\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1464 (0%)]\tLoss: 4.551553\n","Train Epoch: 20 [310/1464 (22%)]\tLoss: 2.615655\n","Train Epoch: 20 [580/1464 (43%)]\tLoss: 3.290127\n","Train Epoch: 20 [900/1464 (65%)]\tLoss: 5.675477\n","Train Epoch: 20 [1560/1464 (87%)]\tLoss: 3.895380\n","Epoch 20 - Training: Average loss: 4.0868, Accuracy: 42.49%\n","Evaluation set: Average loss: 4.7134, Accuracy: 268/714 (37.54%), F1-score: 0.3113\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 5.7654, Accuracy: 235/709 (33.15%), F1-score: 0.2581\n","\n"]}]},{"cell_type":"markdown","source":["## FINE TUNING of ALL LAYERS"],"metadata":{"id":"Ey3nJyv3R-vx"}},{"cell_type":"code","source":["\n","import datetime as dt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold, LeaveOneGroupOut\n","import torch.nn as nn\n","import copy\n","from itertools import product\n","from opacus import PrivacyEngine\n","from opacus.accountants.utils import get_noise_multiplier\n","from opacus.validators import ModuleValidator\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","label_encoder = LabelEncoder()\n","\n","reports_save = True\n","\n","X_combined = []\n","y_combined = []\n","subject_groups_combined = []\n","\n","for sb_name, Xs, ys in all_subject_infos:\n","  X_combined.extend(Xs)\n","  y_combined.extend(ys)\n","  subject_groups_combined.extend([sb_name] * len(ys))\n","\n","X_combined = np.array(X_combined)\n","y_combined = np.array(y_combined)\n","subject_groups_combined = np.array(subject_groups_combined)\n","\n","label_encoder.fit(y_combined)\n","encoded_y_combined_raw = label_encoder.transform(y_combined)\n","\n","# Considering acitivities distribution\n","outer_skf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","\n","EPOCHS = 20\n","BATCH_SIZE_LIST = [32]\n","LRATE_LIST = [1e-3]\n","\n","parameter_pairs = list(product(BATCH_SIZE_LIST, LRATE_LIST))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","N_CLASSES = len(label_encoder.classes_)\n","g_noise_multp = 1.0\n","C_value = 1.0\n","noise_scale = g_noise_multp * C_value\n","DELTA = 1e-5\n","\n","\n","print(f'Noise scale: {noise_scale}')\n","\n","for BATCH_SIZE, LRATE in parameter_pairs:\n","  print('-------------------------------------------------------------------------------------------------')\n","  print(f'Batch size: {BATCH_SIZE}, Learning rate: {LRATE}')\n","  print('-------------------------------------------------------------------------------------------------')\n","\n","  test_outer_subject_list = []\n","  test_outer_losses = []\n","  test_outer_accuracies = []\n","  test_outer_f1s = []\n","  best_fold_train_losses = []\n","  best_fold_val_losses = []\n","  best_fold_val_f1s = []\n","  best_fold_train_accuracies = []\n","  best_fold_val_accuracies = []\n","  best_fold_epochs = []\n","  l_rates = []\n","  batch_sizes = []\n","  fold_details = {\"Test Subjects\": [], \"Batch_Size\": BATCH_SIZE, \"Learning_Rate\": LRATE, \"Epoch_Results\": []}\n","  for outer_fold, (train_outer_index, test_outer_index) in enumerate(outer_skf.split(X_combined, encoded_y_combined_raw, subject_groups_combined), start=1):\n","    print(f'Outer Fold {outer_fold} is starting ...')\n","    X_outer_train_val, X_outer_test = X_combined[train_outer_index], X_combined[test_outer_index]\n","    y_outer_train_val, y_outer_test = encoded_y_combined_raw[train_outer_index], encoded_y_combined_raw[test_outer_index]\n","\n","    train_val_subject_groups = subject_groups_combined[train_outer_index]\n","\n","    test_outer_subjects = np.unique(subject_groups_combined[test_outer_index] )\n","    train_outer_subjects = np.unique(train_val_subject_groups)\n","\n","    print(f'Test subjects: {test_outer_subjects}')\n","    print(f'Train-Validation subjects: {train_outer_subjects}')\n","\n","    # Leave One Group Out for inner fold\n","    inner_skf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n","\n","    fold_val_subjects = []\n","    fold_train_subjects = []\n","    fold_train_losses = []\n","    fold_val_losses = []\n","    fold_train_accuracies = []\n","    fold_val_accuracies = []\n","    fold_epochs = []\n","    fold_best_epochs = []\n","    fold_f1_scores = []\n","\n","    for fold, (train_index, val_index) in enumerate(inner_skf.split(X_outer_train_val, y_outer_train_val, train_val_subject_groups), start=1):\n","      print(f'Fold {fold} is starting ...')\n","\n","      X_train, X_val = X_outer_train_val[train_index], X_outer_train_val[val_index]\n","      y_train, y_val = y_outer_train_val[train_index], y_outer_train_val[val_index]\n","\n","      val_subjects = np.unique(train_val_subject_groups[val_index])\n","      train_subjects = np.unique(train_val_subject_groups[train_index])\n","      print(f'Validation subjects : {val_subjects}')\n","      print(f'Train subjects: {train_subjects}')\n","\n","      scaler = CustomScaler()\n","      scaled_X_train = scaler.fit_transform(X_train)\n","      scaled_X_val = scaler.transform(X_val)\n","\n","      train_data_loader = get_data_loader(scaled_X_train, y_train, BATCH_SIZE=BATCH_SIZE, shuffle=True)\n","      val_data_loader = get_data_loader(scaled_X_val, y_val, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n","\n","      model = get_pretrained_harnet(class_num=N_CLASSES, model_name='harnet10')\n","\n","      # Disable all inplace operations\n","      for module in model.modules():\n","          if hasattr(module, 'inplace'):\n","              module.inplace = False\n","\n","      model = ModuleValidator.fix(model)      # the BatchNorm layers are not supported because they compute the mean and variance across the batch, creating a dependency between samples in a batch, a privacy violation.\n","                                                                  # Recommended approach to deal with it is calling ModuleValidator.fix(model) - it tries to find the best replacement for incompatible modules. For example, for BatchNorm modules, it replaces them with GroupNorm.\n","      model.to(device)\n","\n","      for name, param in model.named_parameters():\n","        param.requires_grad = True\n","\n","\n","      optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LRATE, weight_decay=0.01)\n","      criterion = nn.CrossEntropyLoss()\n","      early_stopping = EarlyStopping(patience=10, verbose=True)\n","      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n","      privacy_engine = PrivacyEngine(secure_mode=False)\n","      model, optimizer, train_data_loader = privacy_engine.make_private(\n","          module=model,\n","          optimizer=optimizer,\n","          data_loader=train_data_loader,\n","          noise_multiplier=g_noise_multp,\n","          max_grad_norm=C_value\n","      )\n","\n","      val_losses = []\n","      val_accuracies = []\n","      val_f1s = []\n","      train_losses = []\n","      train_accuracies = []\n","      epochs_list = []\n","\n","      epoch_results = {\"epoch\": [], \"val_subjects\":val_subjects, \"noise_scale\":[], \"achieved_epsilon\": [],\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n","      best_val_loss = float('inf')\n","      best_model_state = None\n","      best_scaler = None\n","      best_epoch = None\n","      for epoch in range(1, EPOCHS + 1):\n","        train_loss, train_acc = train(model, train_data_loader, optimizer, criterion, epoch, device)\n","        val_loss, val_acc, val_f1 = evaluate(model, val_data_loader, criterion, device)\n","\n","        scheduler.step(val_loss)\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_acc)\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_acc)\n","        val_f1s.append(val_f1)\n","        epochs_list.append(epoch)\n","\n","        a_epsilon = round(privacy_engine.get_epsilon(DELTA), 3)\n","        epoch_results[\"noise_scale\"].append(noise_scale)\n","        epoch_results[\"achieved_epsilon\"].append(a_epsilon)\n","        print(f'Epsilon Spent: {a_epsilon}, Noise_Scale: {noise_scale}')\n","\n","        epoch_results[\"epoch\"].append(epoch)\n","        epoch_results[\"train_loss\"].append(train_loss)\n","        epoch_results[\"train_acc\"].append(train_acc)\n","        epoch_results[\"val_loss\"].append(val_loss)\n","        epoch_results[\"val_acc\"].append(val_acc)\n","        epoch_results[\"val_f1\"].append(val_f1)\n","\n","        if val_loss < best_val_loss:\n","          best_val_loss = val_loss\n","          best_model_state = copy.deepcopy(model.state_dict())\n","          best_epoch = epoch\n","          best_scaler = copy.deepcopy(scaler)\n","\n","        early_stopping(val_loss, model, epoch)\n","        if early_stopping.early_stop:\n","          print(\"Early stopping\")\n","          break\n","\n","      # Scores are added based on the best epoch considering early stopping to prevent overfitting\n","      best_epoch_index = best_epoch - 1   # Since epoch loop starts with 1\n","\n","      # TEST SUBJECTS EVALUATION\n","      print(f' #### Test Evaluation is starting for {test_outer_subjects} #### ')\n","      final_val_model = get_pretrained_harnet(class_num=N_CLASSES, model_name='harnet10')\n","      final_val_model = ModuleValidator.fix(final_val_model)\n","      final_val_model.load_state_dict(remove_module_prefix(best_model_state))\n","      final_val_model.to(device)\n","\n","      scaled_X_outer_test = best_scaler.transform(X_outer_test)\n","      test_data_loader = get_data_loader(scaled_X_outer_test, y_outer_test, BATCH_SIZE=BATCH_SIZE, shuffle=False)\n","      test_loss, test_acc, test_f1 = evaluate(final_val_model, test_data_loader, criterion, device)\n","\n","      test_outer_subject_list.append(test_outer_subjects)\n","      test_outer_losses.append(test_loss)\n","      test_outer_accuracies.append(test_acc)\n","      test_outer_f1s.append(test_f1)\n","      best_fold_train_losses.append(train_losses[best_epoch_index])\n","      best_fold_val_losses.append(val_losses[best_epoch_index])\n","      best_fold_val_f1s.append(val_f1s[best_epoch_index])\n","      best_fold_train_accuracies.append(train_accuracies[best_epoch_index])\n","      best_fold_val_accuracies.append(val_accuracies[best_epoch_index])\n","      best_fold_epochs.append(epochs_list[best_epoch_index])\n","      fold_train_subjects.append(train_subjects)\n","      fold_val_subjects.append(val_subjects)\n","      fold_details['Test Subjects'].append(test_outer_subjects)\n","      fold_details['Epoch_Results'].append(epoch_results)\n","      batch_sizes.append(BATCH_SIZE)\n","      l_rates.append(LRATE)\n","\n","\n","directory_name = 'downsampled_results_DP'\n","os.makedirs(directory_name, exist_ok=True)\n","\n","\n","today_time = dt.date.today().strftime(\"%Y%m%d\")\n","vers = f'{window_length_sec}_{sampling_rate_hz}_{overlap_ratio}_{today_time}'\n","\n","fold_details_df = pd.DataFrame(fold_details)\n","\n","summary_df = pd.DataFrame({'Test_Subjects':test_outer_subject_list,\n","                           \"Test_Losses\":test_outer_losses,\n","                           \"Best_Val_Losses\":best_fold_val_losses,\n","                           \"Best_Train_Losses\":best_fold_train_losses,\n","                           \"Test_Accuracies\":test_outer_accuracies,\n","                           \"Best_Val_Accuracies\":best_fold_val_accuracies,\n","                           \"Best_Train_Accuracies\":best_fold_train_accuracies,\n","                           \"Test_F1s\":test_outer_f1s,\n","                           \"Best_Val_F1s\":best_fold_val_f1s,\n","                           \"Best_Val_Epochs\":best_fold_epochs,\n","                           \"Batch_Size\":batch_sizes,\n","                           \"Learning_Rate\":l_rates\n","                           })\n","\n","if reports_save:\n","  fold_details_df.to_csv(f'{directory_name}/fold_details_DP_CH_NS_{noise_scale}_{vers}_Split_4-2-2_all_layers.csv')\n","  summary_df.to_csv(f'{directory_name}/summary_df_DP_CH_NS_{noise_scale}_{vers}_Split_4-2-2_all_layers.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8C_4pKFSRk0p","executionInfo":{"status":"ok","timestamp":1750148827728,"user_tz":-120,"elapsed":1270180,"user":{"displayName":"Ozan GÜNER","userId":"08667159980350915066"}},"outputId":"d1b3458e-29dd-4309-96d4-11a238172888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Noise scale: 10.0\n","-------------------------------------------------------------------------------------------------\n","Batch size: 32, Learning rate: 0.001\n","-------------------------------------------------------------------------------------------------\n","Outer Fold 1 is starting ...\n","Test subjects: ['subject102' 'subject107']\n","Train-Validation subjects: ['subject101' 'subject103' 'subject104' 'subject105' 'subject106'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject104' 'subject105']\n","Train subjects: ['subject101' 'subject103' 'subject106' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1416 (0%)]\tLoss: 6.528163\n","Train Epoch: 1 [240/1416 (22%)]\tLoss: 6.858725\n","Train Epoch: 1 [580/1416 (44%)]\tLoss: 4.444977\n","Train Epoch: 1 [1050/1416 (67%)]\tLoss: 4.002704\n","Train Epoch: 1 [1440/1416 (89%)]\tLoss: 4.203034\n","Epoch 1 - Training: Average loss: 4.6247, Accuracy: 11.82%\n","Evaluation set: Average loss: 3.7752, Accuracy: 77/743 (10.36%), F1-score: 0.0688\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1416 (0%)]\tLoss: 3.374773\n","Train Epoch: 2 [270/1416 (22%)]\tLoss: 4.679689\n","Train Epoch: 2 [680/1416 (44%)]\tLoss: 2.944252\n","Train Epoch: 2 [930/1416 (67%)]\tLoss: 3.485303\n","Train Epoch: 2 [960/1416 (89%)]\tLoss: 2.584692\n","Epoch 2 - Training: Average loss: 3.3945, Accuracy: 17.98%\n","Evaluation set: Average loss: 3.0978, Accuracy: 126/743 (16.96%), F1-score: 0.0996\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1416 (0%)]\tLoss: 2.871217\n","Train Epoch: 3 [310/1416 (22%)]\tLoss: 2.876049\n","Train Epoch: 3 [720/1416 (44%)]\tLoss: 2.434937\n","Train Epoch: 3 [600/1416 (67%)]\tLoss: 2.354049\n","Train Epoch: 3 [1160/1416 (89%)]\tLoss: 2.273857\n","Epoch 3 - Training: Average loss: 2.8818, Accuracy: 19.67%\n","Evaluation set: Average loss: 2.5616, Accuracy: 117/743 (15.75%), F1-score: 0.1025\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1416 (0%)]\tLoss: 2.241533\n","Train Epoch: 4 [280/1416 (22%)]\tLoss: 2.447241\n","Train Epoch: 4 [580/1416 (44%)]\tLoss: 2.948061\n","Train Epoch: 4 [810/1416 (67%)]\tLoss: 2.167184\n","Train Epoch: 4 [1040/1416 (89%)]\tLoss: 2.292119\n","Epoch 4 - Training: Average loss: 2.3804, Accuracy: 19.71%\n","Evaluation set: Average loss: 2.3434, Accuracy: 178/743 (23.96%), F1-score: 0.1168\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1416 (0%)]\tLoss: 2.508597\n","Train Epoch: 5 [300/1416 (22%)]\tLoss: 2.388088\n","Train Epoch: 5 [600/1416 (44%)]\tLoss: 1.944265\n","Train Epoch: 5 [990/1416 (67%)]\tLoss: 2.028044\n","Train Epoch: 5 [1320/1416 (89%)]\tLoss: 1.933146\n","Epoch 5 - Training: Average loss: 2.0419, Accuracy: 24.72%\n","Evaluation set: Average loss: 2.0832, Accuracy: 175/743 (23.55%), F1-score: 0.1181\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1416 (0%)]\tLoss: 1.899147\n","Train Epoch: 6 [340/1416 (22%)]\tLoss: 2.164623\n","Train Epoch: 6 [780/1416 (44%)]\tLoss: 2.127956\n","Train Epoch: 6 [1050/1416 (67%)]\tLoss: 1.956670\n","Train Epoch: 6 [1440/1416 (89%)]\tLoss: 1.926055\n","Epoch 6 - Training: Average loss: 2.0852, Accuracy: 24.58%\n","Evaluation set: Average loss: 2.0511, Accuracy: 165/743 (22.21%), F1-score: 0.1534\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1416 (0%)]\tLoss: 1.746622\n","Train Epoch: 7 [330/1416 (22%)]\tLoss: 1.980481\n","Train Epoch: 7 [720/1416 (44%)]\tLoss: 1.878425\n","Train Epoch: 7 [990/1416 (67%)]\tLoss: 2.149828\n","Train Epoch: 7 [1160/1416 (89%)]\tLoss: 1.891868\n","Epoch 7 - Training: Average loss: 1.9534, Accuracy: 28.91%\n","Evaluation set: Average loss: 1.9918, Accuracy: 186/743 (25.03%), F1-score: 0.1129\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1416 (0%)]\tLoss: 2.033278\n","Train Epoch: 8 [330/1416 (22%)]\tLoss: 1.942408\n","Train Epoch: 8 [880/1416 (44%)]\tLoss: 1.918698\n","Train Epoch: 8 [990/1416 (67%)]\tLoss: 2.137682\n","Train Epoch: 8 [1240/1416 (89%)]\tLoss: 1.896915\n","Epoch 8 - Training: Average loss: 2.0147, Accuracy: 25.02%\n","Evaluation set: Average loss: 2.0094, Accuracy: 170/743 (22.88%), F1-score: 0.1428\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1416 (0%)]\tLoss: 2.080866\n","Train Epoch: 9 [230/1416 (22%)]\tLoss: 2.053131\n","Train Epoch: 9 [540/1416 (44%)]\tLoss: 1.966463\n","Train Epoch: 9 [810/1416 (67%)]\tLoss: 1.997280\n","Train Epoch: 9 [920/1416 (89%)]\tLoss: 1.991303\n","Epoch 9 - Training: Average loss: 2.0016, Accuracy: 21.77%\n","Evaluation set: Average loss: 2.1600, Accuracy: 154/743 (20.73%), F1-score: 0.1456\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 10 [0/1416 (0%)]\tLoss: 2.058383\n","Train Epoch: 10 [320/1416 (22%)]\tLoss: 2.161531\n","Train Epoch: 10 [580/1416 (44%)]\tLoss: 1.975910\n","Train Epoch: 10 [600/1416 (67%)]\tLoss: 1.997444\n","Train Epoch: 10 [1240/1416 (89%)]\tLoss: 1.971937\n","Epoch 10 - Training: Average loss: 1.9551, Accuracy: 25.21%\n","Evaluation set: Average loss: 1.9337, Accuracy: 176/743 (23.69%), F1-score: 0.1222\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1416 (0%)]\tLoss: 1.824072\n","Train Epoch: 11 [290/1416 (22%)]\tLoss: 1.967204\n","Train Epoch: 11 [640/1416 (44%)]\tLoss: 1.735171\n","Train Epoch: 11 [660/1416 (67%)]\tLoss: 2.063343\n","Train Epoch: 11 [1160/1416 (89%)]\tLoss: 1.828701\n","Epoch 11 - Training: Average loss: 1.8687, Accuracy: 28.50%\n","Evaluation set: Average loss: 2.0551, Accuracy: 151/743 (20.32%), F1-score: 0.1240\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 12 [0/1416 (0%)]\tLoss: 1.804639\n","Train Epoch: 12 [290/1416 (22%)]\tLoss: 1.964744\n","Train Epoch: 12 [740/1416 (44%)]\tLoss: 1.760551\n","Train Epoch: 12 [1170/1416 (67%)]\tLoss: 1.752576\n","Train Epoch: 12 [1440/1416 (89%)]\tLoss: 1.854117\n","Epoch 12 - Training: Average loss: 1.7865, Accuracy: 29.38%\n","Evaluation set: Average loss: 1.7631, Accuracy: 300/743 (40.38%), F1-score: 0.3099\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1416 (0%)]\tLoss: 1.460708\n","Train Epoch: 13 [210/1416 (22%)]\tLoss: 1.888761\n","Train Epoch: 13 [580/1416 (44%)]\tLoss: 1.773095\n","Train Epoch: 13 [900/1416 (67%)]\tLoss: 1.678640\n","Train Epoch: 13 [1520/1416 (89%)]\tLoss: 1.838652\n","Epoch 13 - Training: Average loss: 1.7056, Accuracy: 42.15%\n","Evaluation set: Average loss: 1.8571, Accuracy: 213/743 (28.67%), F1-score: 0.1923\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 14 [0/1416 (0%)]\tLoss: 1.710698\n","Train Epoch: 14 [380/1416 (22%)]\tLoss: 1.710994\n","Train Epoch: 14 [700/1416 (44%)]\tLoss: 1.796011\n","Train Epoch: 14 [780/1416 (67%)]\tLoss: 1.871604\n","Train Epoch: 14 [1120/1416 (89%)]\tLoss: 1.761368\n","Epoch 14 - Training: Average loss: 1.7298, Accuracy: 32.14%\n","Evaluation set: Average loss: 1.7890, Accuracy: 242/743 (32.57%), F1-score: 0.2344\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 15 [0/1416 (0%)]\tLoss: 1.670947\n","Train Epoch: 15 [290/1416 (22%)]\tLoss: 1.876611\n","Train Epoch: 15 [480/1416 (44%)]\tLoss: 1.971759\n","Train Epoch: 15 [960/1416 (67%)]\tLoss: 2.221661\n","Train Epoch: 15 [1640/1416 (89%)]\tLoss: 1.981986\n","Epoch 15 - Training: Average loss: 1.7893, Accuracy: 31.79%\n","Evaluation set: Average loss: 1.8858, Accuracy: 176/743 (23.69%), F1-score: 0.1394\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 16 [0/1416 (0%)]\tLoss: 1.818066\n","Train Epoch: 16 [350/1416 (22%)]\tLoss: 1.606957\n","Train Epoch: 16 [680/1416 (44%)]\tLoss: 1.564652\n","Train Epoch: 16 [1170/1416 (67%)]\tLoss: 1.577398\n","Train Epoch: 16 [1400/1416 (89%)]\tLoss: 1.615678\n","Epoch 16 - Training: Average loss: 1.5842, Accuracy: 40.73%\n","Evaluation set: Average loss: 1.6679, Accuracy: 289/743 (38.90%), F1-score: 0.2984\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1416 (0%)]\tLoss: 1.625648\n","Train Epoch: 17 [350/1416 (22%)]\tLoss: 1.786358\n","Train Epoch: 17 [540/1416 (44%)]\tLoss: 1.794374\n","Train Epoch: 17 [1050/1416 (67%)]\tLoss: 1.739408\n","Train Epoch: 17 [1600/1416 (89%)]\tLoss: 1.781599\n","Epoch 17 - Training: Average loss: 1.6610, Accuracy: 40.45%\n","Evaluation set: Average loss: 1.8000, Accuracy: 280/743 (37.69%), F1-score: 0.2509\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1416 (0%)]\tLoss: 1.708921\n","Train Epoch: 18 [310/1416 (22%)]\tLoss: 1.748707\n","Train Epoch: 18 [640/1416 (44%)]\tLoss: 1.865313\n","Train Epoch: 18 [840/1416 (67%)]\tLoss: 1.734813\n","Train Epoch: 18 [1200/1416 (89%)]\tLoss: 1.719274\n","Epoch 18 - Training: Average loss: 1.7051, Accuracy: 35.60%\n","Evaluation set: Average loss: 1.8041, Accuracy: 254/743 (34.19%), F1-score: 0.2184\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 19 [0/1416 (0%)]\tLoss: 1.768889\n","Train Epoch: 19 [290/1416 (22%)]\tLoss: 1.519758\n","Train Epoch: 19 [540/1416 (44%)]\tLoss: 1.754192\n","Train Epoch: 19 [990/1416 (67%)]\tLoss: 1.513228\n","Train Epoch: 19 [1440/1416 (89%)]\tLoss: 1.515290\n","Epoch 19 - Training: Average loss: 1.6732, Accuracy: 38.82%\n","Evaluation set: Average loss: 1.7848, Accuracy: 261/743 (35.13%), F1-score: 0.2504\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 20 [0/1416 (0%)]\tLoss: 1.790985\n","Train Epoch: 20 [370/1416 (22%)]\tLoss: 1.629660\n","Train Epoch: 20 [800/1416 (44%)]\tLoss: 1.714204\n","Train Epoch: 20 [810/1416 (67%)]\tLoss: 1.567777\n","Train Epoch: 20 [1000/1416 (89%)]\tLoss: 1.652030\n","Epoch 20 - Training: Average loss: 1.7022, Accuracy: 38.50%\n","Evaluation set: Average loss: 1.8719, Accuracy: 211/743 (28.40%), F1-score: 0.2121\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.6321, Accuracy: 308/728 (42.31%), F1-score: 0.2996\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject103' 'subject106']\n","Train subjects: ['subject101' 'subject104' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1452 (0%)]\tLoss: 11.587958\n","Train Epoch: 1 [390/1452 (22%)]\tLoss: 10.498988\n","Train Epoch: 1 [720/1452 (43%)]\tLoss: 9.991079\n","Train Epoch: 1 [990/1452 (65%)]\tLoss: 8.217754\n","Train Epoch: 1 [1640/1452 (87%)]\tLoss: 7.588878\n","Epoch 1 - Training: Average loss: 9.5284, Accuracy: 6.01%\n","Evaluation set: Average loss: 7.2630, Accuracy: 91/707 (12.87%), F1-score: 0.0536\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1452 (0%)]\tLoss: 6.560805\n","Train Epoch: 2 [330/1452 (22%)]\tLoss: 7.955525\n","Train Epoch: 2 [620/1452 (43%)]\tLoss: 6.192909\n","Train Epoch: 2 [930/1452 (65%)]\tLoss: 7.674364\n","Train Epoch: 2 [1360/1452 (87%)]\tLoss: 6.027730\n","Epoch 2 - Training: Average loss: 6.3537, Accuracy: 13.46%\n","Evaluation set: Average loss: 5.1193, Accuracy: 129/707 (18.25%), F1-score: 0.0560\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1452 (0%)]\tLoss: 5.578252\n","Train Epoch: 3 [290/1452 (22%)]\tLoss: 3.563895\n","Train Epoch: 3 [880/1452 (43%)]\tLoss: 4.512965\n","Train Epoch: 3 [1080/1452 (65%)]\tLoss: 3.231468\n","Train Epoch: 3 [1040/1452 (87%)]\tLoss: 3.016627\n","Epoch 3 - Training: Average loss: 4.0946, Accuracy: 13.41%\n","Evaluation set: Average loss: 2.7205, Accuracy: 114/707 (16.12%), F1-score: 0.0829\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1452 (0%)]\tLoss: 2.960250\n","Train Epoch: 4 [300/1452 (22%)]\tLoss: 2.807137\n","Train Epoch: 4 [580/1452 (43%)]\tLoss: 2.766121\n","Train Epoch: 4 [1110/1452 (65%)]\tLoss: 2.545691\n","Train Epoch: 4 [1160/1452 (87%)]\tLoss: 2.276939\n","Epoch 4 - Training: Average loss: 2.6099, Accuracy: 15.55%\n","Evaluation set: Average loss: 2.4623, Accuracy: 130/707 (18.39%), F1-score: 0.0494\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1452 (0%)]\tLoss: 2.692275\n","Train Epoch: 5 [280/1452 (22%)]\tLoss: 2.427433\n","Train Epoch: 5 [640/1452 (43%)]\tLoss: 2.308680\n","Train Epoch: 5 [870/1452 (65%)]\tLoss: 2.158626\n","Train Epoch: 5 [1120/1452 (87%)]\tLoss: 1.763109\n","Epoch 5 - Training: Average loss: 2.3118, Accuracy: 16.14%\n","Evaluation set: Average loss: 2.1064, Accuracy: 137/707 (19.38%), F1-score: 0.1050\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1452 (0%)]\tLoss: 2.056600\n","Train Epoch: 6 [260/1452 (22%)]\tLoss: 2.040224\n","Train Epoch: 6 [540/1452 (43%)]\tLoss: 2.147312\n","Train Epoch: 6 [930/1452 (65%)]\tLoss: 2.192914\n","Train Epoch: 6 [1320/1452 (87%)]\tLoss: 2.210579\n","Epoch 6 - Training: Average loss: 2.1405, Accuracy: 15.99%\n","Evaluation set: Average loss: 2.0555, Accuracy: 143/707 (20.23%), F1-score: 0.1554\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1452 (0%)]\tLoss: 2.038210\n","Train Epoch: 7 [320/1452 (22%)]\tLoss: 2.076204\n","Train Epoch: 7 [780/1452 (43%)]\tLoss: 2.176721\n","Train Epoch: 7 [1140/1452 (65%)]\tLoss: 1.844635\n","Train Epoch: 7 [1080/1452 (87%)]\tLoss: 1.940349\n","Epoch 7 - Training: Average loss: 2.0166, Accuracy: 19.03%\n","Evaluation set: Average loss: 2.0454, Accuracy: 139/707 (19.66%), F1-score: 0.1862\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1452 (0%)]\tLoss: 2.068381\n","Train Epoch: 8 [320/1452 (22%)]\tLoss: 1.919338\n","Train Epoch: 8 [600/1452 (43%)]\tLoss: 2.059517\n","Train Epoch: 8 [1260/1452 (65%)]\tLoss: 1.988752\n","Train Epoch: 8 [1240/1452 (87%)]\tLoss: 1.917926\n","Epoch 8 - Training: Average loss: 2.0079, Accuracy: 20.04%\n","Evaluation set: Average loss: 2.0194, Accuracy: 139/707 (19.66%), F1-score: 0.1885\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1452 (0%)]\tLoss: 2.076070\n","Train Epoch: 9 [250/1452 (22%)]\tLoss: 2.140879\n","Train Epoch: 9 [560/1452 (43%)]\tLoss: 2.066686\n","Train Epoch: 9 [900/1452 (65%)]\tLoss: 2.035663\n","Train Epoch: 9 [1240/1452 (87%)]\tLoss: 2.370345\n","Epoch 9 - Training: Average loss: 2.1068, Accuracy: 15.50%\n","Evaluation set: Average loss: 2.1590, Accuracy: 75/707 (10.61%), F1-score: 0.0830\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1452 (0%)]\tLoss: 2.048408\n","Train Epoch: 10 [410/1452 (22%)]\tLoss: 2.035429\n","Train Epoch: 10 [580/1452 (43%)]\tLoss: 2.024591\n","Train Epoch: 10 [1140/1452 (65%)]\tLoss: 2.036193\n","Train Epoch: 10 [1280/1452 (87%)]\tLoss: 2.134260\n","Epoch 10 - Training: Average loss: 2.0714, Accuracy: 14.93%\n","Evaluation set: Average loss: 2.0675, Accuracy: 114/707 (16.12%), F1-score: 0.1326\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 11 [0/1452 (0%)]\tLoss: 2.137509\n","Train Epoch: 11 [380/1452 (22%)]\tLoss: 2.159418\n","Train Epoch: 11 [560/1452 (43%)]\tLoss: 1.881900\n","Train Epoch: 11 [720/1452 (65%)]\tLoss: 2.238845\n","Train Epoch: 11 [1080/1452 (87%)]\tLoss: 1.620774\n","Epoch 11 - Training: Average loss: 2.0411, Accuracy: 15.62%\n","Evaluation set: Average loss: 2.0870, Accuracy: 167/707 (23.62%), F1-score: 0.1785\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 12 [0/1452 (0%)]\tLoss: 2.042011\n","Train Epoch: 12 [230/1452 (22%)]\tLoss: 2.083166\n","Train Epoch: 12 [640/1452 (43%)]\tLoss: 1.845115\n","Train Epoch: 12 [780/1452 (65%)]\tLoss: 1.530583\n","Train Epoch: 12 [1440/1452 (87%)]\tLoss: 1.867002\n","Epoch 12 - Training: Average loss: 1.9960, Accuracy: 26.30%\n","Evaluation set: Average loss: 2.0399, Accuracy: 144/707 (20.37%), F1-score: 0.1640\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 13 [0/1452 (0%)]\tLoss: 2.156033\n","Train Epoch: 13 [380/1452 (22%)]\tLoss: 1.769909\n","Train Epoch: 13 [860/1452 (43%)]\tLoss: 2.168324\n","Train Epoch: 13 [1170/1452 (65%)]\tLoss: 1.842604\n","Train Epoch: 13 [1400/1452 (87%)]\tLoss: 1.953530\n","Epoch 13 - Training: Average loss: 1.9101, Accuracy: 28.42%\n","Evaluation set: Average loss: 2.0114, Accuracy: 158/707 (22.35%), F1-score: 0.1774\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1452 (0%)]\tLoss: 1.719985\n","Train Epoch: 14 [300/1452 (22%)]\tLoss: 1.931837\n","Train Epoch: 14 [620/1452 (43%)]\tLoss: 1.858805\n","Train Epoch: 14 [1110/1452 (65%)]\tLoss: 1.996701\n","Train Epoch: 14 [1320/1452 (87%)]\tLoss: 1.580201\n","Epoch 14 - Training: Average loss: 1.8743, Accuracy: 27.63%\n","Evaluation set: Average loss: 1.9683, Accuracy: 139/707 (19.66%), F1-score: 0.1735\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1452 (0%)]\tLoss: 1.711668\n","Train Epoch: 15 [360/1452 (22%)]\tLoss: 1.839737\n","Train Epoch: 15 [560/1452 (43%)]\tLoss: 1.812928\n","Train Epoch: 15 [1050/1452 (65%)]\tLoss: 1.996401\n","Train Epoch: 15 [680/1452 (87%)]\tLoss: 1.830600\n","Epoch 15 - Training: Average loss: 1.8400, Accuracy: 29.73%\n","Evaluation set: Average loss: 1.9437, Accuracy: 140/707 (19.80%), F1-score: 0.1787\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1452 (0%)]\tLoss: 1.880139\n","Train Epoch: 16 [350/1452 (22%)]\tLoss: 1.608911\n","Train Epoch: 16 [680/1452 (43%)]\tLoss: 1.818875\n","Train Epoch: 16 [1080/1452 (65%)]\tLoss: 1.886503\n","Train Epoch: 16 [1360/1452 (87%)]\tLoss: 1.676696\n","Epoch 16 - Training: Average loss: 1.8320, Accuracy: 30.03%\n","Evaluation set: Average loss: 1.9376, Accuracy: 139/707 (19.66%), F1-score: 0.1690\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1452 (0%)]\tLoss: 1.606553\n","Train Epoch: 17 [220/1452 (22%)]\tLoss: 2.022243\n","Train Epoch: 17 [640/1452 (43%)]\tLoss: 1.936270\n","Train Epoch: 17 [870/1452 (65%)]\tLoss: 1.955967\n","Train Epoch: 17 [1440/1452 (87%)]\tLoss: 1.894111\n","Epoch 17 - Training: Average loss: 1.8222, Accuracy: 29.72%\n","Evaluation set: Average loss: 1.9299, Accuracy: 137/707 (19.38%), F1-score: 0.1384\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1452 (0%)]\tLoss: 1.837612\n","Train Epoch: 18 [280/1452 (22%)]\tLoss: 1.771221\n","Train Epoch: 18 [700/1452 (43%)]\tLoss: 1.909598\n","Train Epoch: 18 [600/1452 (65%)]\tLoss: 1.726572\n","Train Epoch: 18 [1560/1452 (87%)]\tLoss: 1.899951\n","Epoch 18 - Training: Average loss: 1.8444, Accuracy: 29.12%\n","Evaluation set: Average loss: 1.9193, Accuracy: 130/707 (18.39%), F1-score: 0.1243\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1452 (0%)]\tLoss: 1.853005\n","Train Epoch: 19 [360/1452 (22%)]\tLoss: 2.000130\n","Train Epoch: 19 [760/1452 (43%)]\tLoss: 1.692233\n","Train Epoch: 19 [630/1452 (65%)]\tLoss: 1.945445\n","Train Epoch: 19 [1280/1452 (87%)]\tLoss: 1.845482\n","Epoch 19 - Training: Average loss: 1.8296, Accuracy: 28.23%\n","Evaluation set: Average loss: 1.9103, Accuracy: 132/707 (18.67%), F1-score: 0.1354\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1452 (0%)]\tLoss: 2.130137\n","Train Epoch: 20 [260/1452 (22%)]\tLoss: 1.956057\n","Train Epoch: 20 [600/1452 (43%)]\tLoss: 1.696091\n","Train Epoch: 20 [810/1452 (65%)]\tLoss: 1.790109\n","Train Epoch: 20 [1320/1452 (87%)]\tLoss: 1.791485\n","Epoch 20 - Training: Average loss: 1.7879, Accuracy: 32.05%\n","Evaluation set: Average loss: 1.8851, Accuracy: 140/707 (19.80%), F1-score: 0.1457\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.8046, Accuracy: 164/728 (22.53%), F1-score: 0.1579\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject101' 'subject108']\n","Train subjects: ['subject103' 'subject104' 'subject105' 'subject106']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1450 (0%)]\tLoss: 10.120683\n","Train Epoch: 1 [260/1450 (22%)]\tLoss: 7.255331\n","Train Epoch: 1 [680/1450 (43%)]\tLoss: 6.423759\n","Train Epoch: 1 [1350/1450 (65%)]\tLoss: 5.240855\n","Train Epoch: 1 [1000/1450 (87%)]\tLoss: 6.937910\n","Epoch 1 - Training: Average loss: 7.0083, Accuracy: 18.23%\n","Evaluation set: Average loss: 5.3736, Accuracy: 68/709 (9.59%), F1-score: 0.0396\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1450 (0%)]\tLoss: 4.362813\n","Train Epoch: 2 [290/1450 (22%)]\tLoss: 4.538776\n","Train Epoch: 2 [800/1450 (43%)]\tLoss: 4.146149\n","Train Epoch: 2 [660/1450 (65%)]\tLoss: 4.235235\n","Train Epoch: 2 [1680/1450 (87%)]\tLoss: 3.888698\n","Epoch 2 - Training: Average loss: 4.2582, Accuracy: 9.31%\n","Evaluation set: Average loss: 4.3672, Accuracy: 30/709 (4.23%), F1-score: 0.0207\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1450 (0%)]\tLoss: 5.347138\n","Train Epoch: 3 [400/1450 (22%)]\tLoss: 4.791976\n","Train Epoch: 3 [640/1450 (43%)]\tLoss: 4.831850\n","Train Epoch: 3 [900/1450 (65%)]\tLoss: 3.318114\n","Train Epoch: 3 [880/1450 (87%)]\tLoss: 3.738764\n","Epoch 3 - Training: Average loss: 3.8986, Accuracy: 17.35%\n","Evaluation set: Average loss: 3.6062, Accuracy: 123/709 (17.35%), F1-score: 0.0644\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1450 (0%)]\tLoss: 3.494523\n","Train Epoch: 4 [220/1450 (22%)]\tLoss: 3.438623\n","Train Epoch: 4 [680/1450 (43%)]\tLoss: 2.429859\n","Train Epoch: 4 [750/1450 (65%)]\tLoss: 3.417557\n","Train Epoch: 4 [1480/1450 (87%)]\tLoss: 2.836902\n","Epoch 4 - Training: Average loss: 2.9032, Accuracy: 19.85%\n","Evaluation set: Average loss: 2.8516, Accuracy: 136/709 (19.18%), F1-score: 0.0945\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1450 (0%)]\tLoss: 2.515909\n","Train Epoch: 5 [320/1450 (22%)]\tLoss: 2.107091\n","Train Epoch: 5 [780/1450 (43%)]\tLoss: 2.538424\n","Train Epoch: 5 [810/1450 (65%)]\tLoss: 2.997551\n","Train Epoch: 5 [1360/1450 (87%)]\tLoss: 2.553372\n","Epoch 5 - Training: Average loss: 2.6078, Accuracy: 21.88%\n","Evaluation set: Average loss: 2.6709, Accuracy: 90/709 (12.69%), F1-score: 0.0623\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1450 (0%)]\tLoss: 2.430208\n","Train Epoch: 6 [290/1450 (22%)]\tLoss: 2.331812\n","Train Epoch: 6 [780/1450 (43%)]\tLoss: 2.560610\n","Train Epoch: 6 [720/1450 (65%)]\tLoss: 2.139434\n","Train Epoch: 6 [1360/1450 (87%)]\tLoss: 2.332907\n","Epoch 6 - Training: Average loss: 2.2934, Accuracy: 18.59%\n","Evaluation set: Average loss: 2.2933, Accuracy: 122/709 (17.21%), F1-score: 0.0840\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1450 (0%)]\tLoss: 1.964211\n","Train Epoch: 7 [430/1450 (22%)]\tLoss: 2.064511\n","Train Epoch: 7 [700/1450 (43%)]\tLoss: 2.374360\n","Train Epoch: 7 [930/1450 (65%)]\tLoss: 2.002390\n","Train Epoch: 7 [1200/1450 (87%)]\tLoss: 2.399554\n","Epoch 7 - Training: Average loss: 2.1473, Accuracy: 19.71%\n","Evaluation set: Average loss: 2.3009, Accuracy: 115/709 (16.22%), F1-score: 0.0808\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 8 [0/1450 (0%)]\tLoss: 2.207159\n","Train Epoch: 8 [260/1450 (22%)]\tLoss: 2.483186\n","Train Epoch: 8 [480/1450 (43%)]\tLoss: 2.075629\n","Train Epoch: 8 [1140/1450 (65%)]\tLoss: 2.404955\n","Train Epoch: 8 [1400/1450 (87%)]\tLoss: 1.758028\n","Epoch 8 - Training: Average loss: 2.1836, Accuracy: 19.49%\n","Evaluation set: Average loss: 2.2813, Accuracy: 141/709 (19.89%), F1-score: 0.1474\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1450 (0%)]\tLoss: 2.189442\n","Train Epoch: 9 [300/1450 (22%)]\tLoss: 2.160450\n","Train Epoch: 9 [580/1450 (43%)]\tLoss: 2.079656\n","Train Epoch: 9 [1080/1450 (65%)]\tLoss: 1.935759\n","Train Epoch: 9 [1040/1450 (87%)]\tLoss: 2.285273\n","Epoch 9 - Training: Average loss: 2.0414, Accuracy: 25.93%\n","Evaluation set: Average loss: 2.2598, Accuracy: 157/709 (22.14%), F1-score: 0.1292\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1450 (0%)]\tLoss: 1.998498\n","Train Epoch: 10 [360/1450 (22%)]\tLoss: 2.267284\n","Train Epoch: 10 [680/1450 (43%)]\tLoss: 2.031788\n","Train Epoch: 10 [990/1450 (65%)]\tLoss: 2.041405\n","Train Epoch: 10 [1400/1450 (87%)]\tLoss: 1.851961\n","Epoch 10 - Training: Average loss: 2.0403, Accuracy: 23.30%\n","Evaluation set: Average loss: 2.0671, Accuracy: 116/709 (16.36%), F1-score: 0.1078\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1450 (0%)]\tLoss: 1.978446\n","Train Epoch: 11 [230/1450 (22%)]\tLoss: 1.719835\n","Train Epoch: 11 [740/1450 (43%)]\tLoss: 2.023373\n","Train Epoch: 11 [1050/1450 (65%)]\tLoss: 2.028889\n","Train Epoch: 11 [1720/1450 (87%)]\tLoss: 1.775892\n","Epoch 11 - Training: Average loss: 1.9672, Accuracy: 22.05%\n","Evaluation set: Average loss: 2.2845, Accuracy: 128/709 (18.05%), F1-score: 0.0776\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 12 [0/1450 (0%)]\tLoss: 2.375841\n","Train Epoch: 12 [320/1450 (22%)]\tLoss: 2.227022\n","Train Epoch: 12 [600/1450 (43%)]\tLoss: 2.279363\n","Train Epoch: 12 [900/1450 (65%)]\tLoss: 1.934206\n","Train Epoch: 12 [1240/1450 (87%)]\tLoss: 2.230964\n","Epoch 12 - Training: Average loss: 2.0848, Accuracy: 24.93%\n","Evaluation set: Average loss: 2.2420, Accuracy: 139/709 (19.61%), F1-score: 0.0969\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 13 [0/1450 (0%)]\tLoss: 2.224125\n","Train Epoch: 13 [280/1450 (22%)]\tLoss: 1.489057\n","Train Epoch: 13 [540/1450 (43%)]\tLoss: 1.967933\n","Train Epoch: 13 [750/1450 (65%)]\tLoss: 2.373910\n","Train Epoch: 13 [1400/1450 (87%)]\tLoss: 1.966371\n","Epoch 13 - Training: Average loss: 2.0468, Accuracy: 21.05%\n","Evaluation set: Average loss: 2.3072, Accuracy: 167/709 (23.55%), F1-score: 0.1246\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 14 [0/1450 (0%)]\tLoss: 1.903422\n","Train Epoch: 14 [320/1450 (22%)]\tLoss: 1.840556\n","Train Epoch: 14 [740/1450 (43%)]\tLoss: 1.833099\n","Train Epoch: 14 [960/1450 (65%)]\tLoss: 1.565682\n","Train Epoch: 14 [1400/1450 (87%)]\tLoss: 1.755130\n","Epoch 14 - Training: Average loss: 1.8740, Accuracy: 30.32%\n","Evaluation set: Average loss: 2.1686, Accuracy: 160/709 (22.57%), F1-score: 0.1200\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 15 [0/1450 (0%)]\tLoss: 2.298276\n","Train Epoch: 15 [290/1450 (22%)]\tLoss: 1.816532\n","Train Epoch: 15 [580/1450 (43%)]\tLoss: 1.877326\n","Train Epoch: 15 [810/1450 (65%)]\tLoss: 2.040751\n","Train Epoch: 15 [1400/1450 (87%)]\tLoss: 1.713174\n","Epoch 15 - Training: Average loss: 1.9390, Accuracy: 25.22%\n","Evaluation set: Average loss: 2.0878, Accuracy: 177/709 (24.96%), F1-score: 0.1418\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 16 [0/1450 (0%)]\tLoss: 1.804349\n","Train Epoch: 16 [260/1450 (22%)]\tLoss: 1.916169\n","Train Epoch: 16 [760/1450 (43%)]\tLoss: 2.160775\n","Train Epoch: 16 [960/1450 (65%)]\tLoss: 1.974584\n","Train Epoch: 16 [1080/1450 (87%)]\tLoss: 1.979990\n","Epoch 16 - Training: Average loss: 1.9168, Accuracy: 26.48%\n","Evaluation set: Average loss: 2.0594, Accuracy: 182/709 (25.67%), F1-score: 0.1572\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1450 (0%)]\tLoss: 1.778014\n","Train Epoch: 17 [360/1450 (22%)]\tLoss: 1.851010\n","Train Epoch: 17 [560/1450 (43%)]\tLoss: 1.969678\n","Train Epoch: 17 [810/1450 (65%)]\tLoss: 1.973810\n","Train Epoch: 17 [1240/1450 (87%)]\tLoss: 2.016970\n","Epoch 17 - Training: Average loss: 1.8736, Accuracy: 25.42%\n","Evaluation set: Average loss: 2.0192, Accuracy: 183/709 (25.81%), F1-score: 0.1644\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1450 (0%)]\tLoss: 1.896290\n","Train Epoch: 18 [310/1450 (22%)]\tLoss: 1.900482\n","Train Epoch: 18 [560/1450 (43%)]\tLoss: 1.815183\n","Train Epoch: 18 [750/1450 (65%)]\tLoss: 2.026369\n","Train Epoch: 18 [1600/1450 (87%)]\tLoss: 1.735410\n","Epoch 18 - Training: Average loss: 1.8146, Accuracy: 29.62%\n","Evaluation set: Average loss: 1.9788, Accuracy: 184/709 (25.95%), F1-score: 0.1709\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1450 (0%)]\tLoss: 1.849686\n","Train Epoch: 19 [390/1450 (22%)]\tLoss: 1.906915\n","Train Epoch: 19 [640/1450 (43%)]\tLoss: 1.917362\n","Train Epoch: 19 [990/1450 (65%)]\tLoss: 1.868599\n","Train Epoch: 19 [1320/1450 (87%)]\tLoss: 1.883867\n","Epoch 19 - Training: Average loss: 1.7921, Accuracy: 30.37%\n","Evaluation set: Average loss: 1.9483, Accuracy: 211/709 (29.76%), F1-score: 0.2071\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1450 (0%)]\tLoss: 1.708506\n","Train Epoch: 20 [250/1450 (22%)]\tLoss: 1.789906\n","Train Epoch: 20 [680/1450 (43%)]\tLoss: 1.936978\n","Train Epoch: 20 [750/1450 (65%)]\tLoss: 2.028172\n","Train Epoch: 20 [1200/1450 (87%)]\tLoss: 1.679289\n","Epoch 20 - Training: Average loss: 1.7797, Accuracy: 30.69%\n","Evaluation set: Average loss: 1.9266, Accuracy: 228/709 (32.16%), F1-score: 0.2219\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject102' 'subject107'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.9031, Accuracy: 236/728 (32.42%), F1-score: 0.2086\n","\n","Outer Fold 2 is starting ...\n","Test subjects: ['subject105' 'subject108']\n","Train-Validation subjects: ['subject101' 'subject102' 'subject103' 'subject104' 'subject106'\n"," 'subject107']\n","Fold 1 is starting ...\n","Validation subjects : ['subject106' 'subject107']\n","Train subjects: ['subject101' 'subject102' 'subject103' 'subject104']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1430 (0%)]\tLoss: 8.065762\n","Train Epoch: 1 [250/1430 (22%)]\tLoss: 4.872231\n","Train Epoch: 1 [640/1430 (44%)]\tLoss: 3.594726\n","Train Epoch: 1 [840/1430 (67%)]\tLoss: 5.475724\n","Train Epoch: 1 [1040/1430 (89%)]\tLoss: 5.303086\n","Epoch 1 - Training: Average loss: 5.5587, Accuracy: 15.53%\n","Evaluation set: Average loss: 4.8159, Accuracy: 115/714 (16.11%), F1-score: 0.0698\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1430 (0%)]\tLoss: 4.082659\n","Train Epoch: 2 [340/1430 (22%)]\tLoss: 4.555004\n","Train Epoch: 2 [760/1430 (44%)]\tLoss: 4.190449\n","Train Epoch: 2 [930/1430 (67%)]\tLoss: 4.578870\n","Train Epoch: 2 [1120/1430 (89%)]\tLoss: 4.312685\n","Epoch 2 - Training: Average loss: 4.4795, Accuracy: 17.18%\n","Evaluation set: Average loss: 4.0671, Accuracy: 129/714 (18.07%), F1-score: 0.0669\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1430 (0%)]\tLoss: 5.032490\n","Train Epoch: 3 [370/1430 (22%)]\tLoss: 3.404435\n","Train Epoch: 3 [860/1430 (44%)]\tLoss: 2.481355\n","Train Epoch: 3 [1110/1430 (67%)]\tLoss: 4.090750\n","Train Epoch: 3 [1160/1430 (89%)]\tLoss: 2.759920\n","Epoch 3 - Training: Average loss: 3.5166, Accuracy: 18.52%\n","Evaluation set: Average loss: 3.0949, Accuracy: 192/714 (26.89%), F1-score: 0.1270\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1430 (0%)]\tLoss: 3.312359\n","Train Epoch: 4 [310/1430 (22%)]\tLoss: 3.511334\n","Train Epoch: 4 [560/1430 (44%)]\tLoss: 3.142237\n","Train Epoch: 4 [1350/1430 (67%)]\tLoss: 2.824814\n","Train Epoch: 4 [1240/1430 (89%)]\tLoss: 3.248361\n","Epoch 4 - Training: Average loss: 3.0393, Accuracy: 24.30%\n","Evaluation set: Average loss: 2.8471, Accuracy: 233/714 (32.63%), F1-score: 0.1260\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1430 (0%)]\tLoss: 2.945889\n","Train Epoch: 5 [280/1430 (22%)]\tLoss: 2.303964\n","Train Epoch: 5 [720/1430 (44%)]\tLoss: 2.570846\n","Train Epoch: 5 [870/1430 (67%)]\tLoss: 2.895049\n","Train Epoch: 5 [1040/1430 (89%)]\tLoss: 2.277554\n","Epoch 5 - Training: Average loss: 2.5992, Accuracy: 30.83%\n","Evaluation set: Average loss: 2.4114, Accuracy: 251/714 (35.15%), F1-score: 0.1447\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1430 (0%)]\tLoss: 2.692071\n","Train Epoch: 6 [340/1430 (22%)]\tLoss: 2.234446\n","Train Epoch: 6 [620/1430 (44%)]\tLoss: 2.200477\n","Train Epoch: 6 [720/1430 (67%)]\tLoss: 2.155650\n","Train Epoch: 6 [920/1430 (89%)]\tLoss: 2.297686\n","Epoch 6 - Training: Average loss: 2.3134, Accuracy: 24.56%\n","Evaluation set: Average loss: 2.1993, Accuracy: 238/714 (33.33%), F1-score: 0.1363\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1430 (0%)]\tLoss: 2.109850\n","Train Epoch: 7 [370/1430 (22%)]\tLoss: 2.357957\n","Train Epoch: 7 [780/1430 (44%)]\tLoss: 2.347749\n","Train Epoch: 7 [960/1430 (67%)]\tLoss: 2.245770\n","Train Epoch: 7 [1680/1430 (89%)]\tLoss: 2.139559\n","Epoch 7 - Training: Average loss: 2.2109, Accuracy: 20.87%\n","Evaluation set: Average loss: 2.1861, Accuracy: 147/714 (20.59%), F1-score: 0.1451\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1430 (0%)]\tLoss: 2.485461\n","Train Epoch: 8 [360/1430 (22%)]\tLoss: 2.373280\n","Train Epoch: 8 [740/1430 (44%)]\tLoss: 2.189057\n","Train Epoch: 8 [1140/1430 (67%)]\tLoss: 2.050549\n","Train Epoch: 8 [1560/1430 (89%)]\tLoss: 1.975557\n","Epoch 8 - Training: Average loss: 2.1462, Accuracy: 21.25%\n","Evaluation set: Average loss: 2.0452, Accuracy: 195/714 (27.31%), F1-score: 0.1670\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1430 (0%)]\tLoss: 2.260723\n","Train Epoch: 9 [300/1430 (22%)]\tLoss: 1.859832\n","Train Epoch: 9 [780/1430 (44%)]\tLoss: 2.012534\n","Train Epoch: 9 [960/1430 (67%)]\tLoss: 2.084130\n","Train Epoch: 9 [1160/1430 (89%)]\tLoss: 2.109830\n","Epoch 9 - Training: Average loss: 2.0543, Accuracy: 25.49%\n","Evaluation set: Average loss: 1.9248, Accuracy: 256/714 (35.85%), F1-score: 0.2078\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","Train Epoch: 10 [0/1430 (0%)]\tLoss: 2.004354\n","Train Epoch: 10 [290/1430 (22%)]\tLoss: 2.024883\n","Train Epoch: 10 [780/1430 (44%)]\tLoss: 2.089168\n","Train Epoch: 10 [990/1430 (67%)]\tLoss: 1.832954\n","Train Epoch: 10 [1480/1430 (89%)]\tLoss: 1.826329\n","Epoch 10 - Training: Average loss: 2.0657, Accuracy: 22.36%\n","Evaluation set: Average loss: 2.0928, Accuracy: 152/714 (21.29%), F1-score: 0.1337\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 11 [0/1430 (0%)]\tLoss: 2.205844\n","Train Epoch: 11 [330/1430 (22%)]\tLoss: 2.133209\n","Train Epoch: 11 [620/1430 (44%)]\tLoss: 1.848707\n","Train Epoch: 11 [840/1430 (67%)]\tLoss: 2.005753\n","Train Epoch: 11 [1240/1430 (89%)]\tLoss: 2.076133\n","Epoch 11 - Training: Average loss: 2.0226, Accuracy: 26.51%\n","Evaluation set: Average loss: 2.0518, Accuracy: 203/714 (28.43%), F1-score: 0.1495\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 12 [0/1430 (0%)]\tLoss: 2.355875\n","Train Epoch: 12 [260/1430 (22%)]\tLoss: 1.741066\n","Train Epoch: 12 [620/1430 (44%)]\tLoss: 1.819851\n","Train Epoch: 12 [720/1430 (67%)]\tLoss: 2.021949\n","Train Epoch: 12 [1440/1430 (89%)]\tLoss: 2.217788\n","Epoch 12 - Training: Average loss: 2.0439, Accuracy: 29.46%\n","Evaluation set: Average loss: 2.0773, Accuracy: 211/714 (29.55%), F1-score: 0.2008\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 13 [0/1430 (0%)]\tLoss: 2.156979\n","Train Epoch: 13 [280/1430 (22%)]\tLoss: 2.397556\n","Train Epoch: 13 [760/1430 (44%)]\tLoss: 2.018988\n","Train Epoch: 13 [780/1430 (67%)]\tLoss: 2.080732\n","Train Epoch: 13 [1320/1430 (89%)]\tLoss: 2.098866\n","Epoch 13 - Training: Average loss: 2.1264, Accuracy: 24.68%\n","Evaluation set: Average loss: 1.9442, Accuracy: 193/714 (27.03%), F1-score: 0.1585\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 14 [0/1430 (0%)]\tLoss: 1.824359\n","Train Epoch: 14 [370/1430 (22%)]\tLoss: 2.128865\n","Train Epoch: 14 [840/1430 (44%)]\tLoss: 2.192015\n","Train Epoch: 14 [840/1430 (67%)]\tLoss: 2.201803\n","Train Epoch: 14 [1080/1430 (89%)]\tLoss: 1.809573\n","Epoch 14 - Training: Average loss: 2.0166, Accuracy: 26.95%\n","Evaluation set: Average loss: 1.8786, Accuracy: 229/714 (32.07%), F1-score: 0.1941\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1430 (0%)]\tLoss: 1.966417\n","Train Epoch: 15 [470/1430 (22%)]\tLoss: 2.044728\n","Train Epoch: 15 [640/1430 (44%)]\tLoss: 1.643090\n","Train Epoch: 15 [720/1430 (67%)]\tLoss: 1.897316\n","Train Epoch: 15 [1280/1430 (89%)]\tLoss: 2.253465\n","Epoch 15 - Training: Average loss: 1.9938, Accuracy: 28.46%\n","Evaluation set: Average loss: 1.8646, Accuracy: 222/714 (31.09%), F1-score: 0.1898\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1430 (0%)]\tLoss: 2.051730\n","Train Epoch: 16 [350/1430 (22%)]\tLoss: 1.787839\n","Train Epoch: 16 [720/1430 (44%)]\tLoss: 2.159880\n","Train Epoch: 16 [660/1430 (67%)]\tLoss: 2.242286\n","Train Epoch: 16 [1440/1430 (89%)]\tLoss: 1.975578\n","Epoch 16 - Training: Average loss: 1.9735, Accuracy: 30.62%\n","Evaluation set: Average loss: 1.8464, Accuracy: 230/714 (32.21%), F1-score: 0.1980\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1430 (0%)]\tLoss: 1.566203\n","Train Epoch: 17 [290/1430 (22%)]\tLoss: 2.003577\n","Train Epoch: 17 [740/1430 (44%)]\tLoss: 1.905578\n","Train Epoch: 17 [1290/1430 (67%)]\tLoss: 1.897411\n","Train Epoch: 17 [1240/1430 (89%)]\tLoss: 2.219882\n","Epoch 17 - Training: Average loss: 1.9636, Accuracy: 30.99%\n","Evaluation set: Average loss: 1.8324, Accuracy: 242/714 (33.89%), F1-score: 0.2123\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","Train Epoch: 18 [0/1430 (0%)]\tLoss: 1.983814\n","Train Epoch: 18 [350/1430 (22%)]\tLoss: 1.921218\n","Train Epoch: 18 [540/1430 (44%)]\tLoss: 2.160165\n","Train Epoch: 18 [780/1430 (67%)]\tLoss: 1.829481\n","Train Epoch: 18 [1320/1430 (89%)]\tLoss: 1.835975\n","Epoch 18 - Training: Average loss: 1.9683, Accuracy: 30.73%\n","Evaluation set: Average loss: 1.8232, Accuracy: 261/714 (36.55%), F1-score: 0.2377\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1430 (0%)]\tLoss: 2.011419\n","Train Epoch: 19 [370/1430 (22%)]\tLoss: 2.047172\n","Train Epoch: 19 [740/1430 (44%)]\tLoss: 1.898452\n","Train Epoch: 19 [1380/1430 (67%)]\tLoss: 1.942045\n","Train Epoch: 19 [1200/1430 (89%)]\tLoss: 1.736262\n","Epoch 19 - Training: Average loss: 1.9314, Accuracy: 34.90%\n","Evaluation set: Average loss: 1.8150, Accuracy: 268/714 (37.54%), F1-score: 0.2462\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1430 (0%)]\tLoss: 1.829648\n","Train Epoch: 20 [250/1430 (22%)]\tLoss: 1.790018\n","Train Epoch: 20 [500/1430 (44%)]\tLoss: 1.813301\n","Train Epoch: 20 [1020/1430 (67%)]\tLoss: 1.872911\n","Train Epoch: 20 [1000/1430 (89%)]\tLoss: 1.675724\n","Epoch 20 - Training: Average loss: 1.9039, Accuracy: 36.16%\n","Evaluation set: Average loss: 1.7898, Accuracy: 278/714 (38.94%), F1-score: 0.2537\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.8576, Accuracy: 267/743 (35.94%), F1-score: 0.2172\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject101' 'subject103']\n","Train subjects: ['subject102' 'subject104' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1451 (0%)]\tLoss: 10.932749\n","Train Epoch: 1 [190/1451 (22%)]\tLoss: 5.914743\n","Train Epoch: 1 [500/1451 (43%)]\tLoss: 9.040085\n","Train Epoch: 1 [1170/1451 (65%)]\tLoss: 7.830497\n","Train Epoch: 1 [1520/1451 (87%)]\tLoss: 6.489958\n","Epoch 1 - Training: Average loss: 7.5042, Accuracy: 15.40%\n","Evaluation set: Average loss: 5.1904, Accuracy: 155/693 (22.37%), F1-score: 0.1493\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1451 (0%)]\tLoss: 5.142646\n","Train Epoch: 2 [430/1451 (22%)]\tLoss: 5.028931\n","Train Epoch: 2 [800/1451 (43%)]\tLoss: 4.608726\n","Train Epoch: 2 [900/1451 (65%)]\tLoss: 4.632279\n","Train Epoch: 2 [1240/1451 (87%)]\tLoss: 4.662990\n","Epoch 2 - Training: Average loss: 4.6207, Accuracy: 17.38%\n","Evaluation set: Average loss: 3.4912, Accuracy: 106/693 (15.30%), F1-score: 0.0900\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1451 (0%)]\tLoss: 3.918739\n","Train Epoch: 3 [210/1451 (22%)]\tLoss: 2.621187\n","Train Epoch: 3 [840/1451 (43%)]\tLoss: 2.802204\n","Train Epoch: 3 [900/1451 (65%)]\tLoss: 3.097707\n","Train Epoch: 3 [1320/1451 (87%)]\tLoss: 2.926485\n","Epoch 3 - Training: Average loss: 3.2755, Accuracy: 14.37%\n","Evaluation set: Average loss: 2.7914, Accuracy: 132/693 (19.05%), F1-score: 0.0917\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1451 (0%)]\tLoss: 3.243819\n","Train Epoch: 4 [320/1451 (22%)]\tLoss: 2.643628\n","Train Epoch: 4 [800/1451 (43%)]\tLoss: 2.147013\n","Train Epoch: 4 [810/1451 (65%)]\tLoss: 2.358064\n","Train Epoch: 4 [1040/1451 (87%)]\tLoss: 2.113707\n","Epoch 4 - Training: Average loss: 2.5095, Accuracy: 23.79%\n","Evaluation set: Average loss: 2.4118, Accuracy: 117/693 (16.88%), F1-score: 0.0798\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1451 (0%)]\tLoss: 2.572876\n","Train Epoch: 5 [280/1451 (22%)]\tLoss: 2.664332\n","Train Epoch: 5 [680/1451 (43%)]\tLoss: 2.423440\n","Train Epoch: 5 [840/1451 (65%)]\tLoss: 2.052029\n","Train Epoch: 5 [1000/1451 (87%)]\tLoss: 2.137422\n","Epoch 5 - Training: Average loss: 2.2387, Accuracy: 20.18%\n","Evaluation set: Average loss: 1.9931, Accuracy: 174/693 (25.11%), F1-score: 0.1437\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1451 (0%)]\tLoss: 2.033530\n","Train Epoch: 6 [260/1451 (22%)]\tLoss: 1.862907\n","Train Epoch: 6 [420/1451 (43%)]\tLoss: 1.795748\n","Train Epoch: 6 [750/1451 (65%)]\tLoss: 2.092367\n","Train Epoch: 6 [1320/1451 (87%)]\tLoss: 1.913410\n","Epoch 6 - Training: Average loss: 1.8941, Accuracy: 35.14%\n","Evaluation set: Average loss: 1.8604, Accuracy: 207/693 (29.87%), F1-score: 0.1990\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1451 (0%)]\tLoss: 1.922741\n","Train Epoch: 7 [230/1451 (22%)]\tLoss: 1.754175\n","Train Epoch: 7 [620/1451 (43%)]\tLoss: 2.204606\n","Train Epoch: 7 [930/1451 (65%)]\tLoss: 1.768397\n","Train Epoch: 7 [1520/1451 (87%)]\tLoss: 1.879015\n","Epoch 7 - Training: Average loss: 1.9399, Accuracy: 32.65%\n","Evaluation set: Average loss: 1.9175, Accuracy: 171/693 (24.68%), F1-score: 0.1590\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 8 [0/1451 (0%)]\tLoss: 1.906249\n","Train Epoch: 8 [390/1451 (22%)]\tLoss: 1.899121\n","Train Epoch: 8 [680/1451 (43%)]\tLoss: 2.023945\n","Train Epoch: 8 [870/1451 (65%)]\tLoss: 1.821572\n","Train Epoch: 8 [1080/1451 (87%)]\tLoss: 2.004037\n","Epoch 8 - Training: Average loss: 1.9369, Accuracy: 28.38%\n","Evaluation set: Average loss: 1.8621, Accuracy: 207/693 (29.87%), F1-score: 0.2059\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 9 [0/1451 (0%)]\tLoss: 1.746327\n","Train Epoch: 9 [390/1451 (22%)]\tLoss: 2.020293\n","Train Epoch: 9 [540/1451 (43%)]\tLoss: 2.031590\n","Train Epoch: 9 [960/1451 (65%)]\tLoss: 2.074488\n","Train Epoch: 9 [1320/1451 (87%)]\tLoss: 2.013641\n","Epoch 9 - Training: Average loss: 2.0257, Accuracy: 29.27%\n","Evaluation set: Average loss: 2.0138, Accuracy: 249/693 (35.93%), F1-score: 0.2126\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 10 [0/1451 (0%)]\tLoss: 1.863892\n","Train Epoch: 10 [240/1451 (22%)]\tLoss: 1.774210\n","Train Epoch: 10 [620/1451 (43%)]\tLoss: 2.145196\n","Train Epoch: 10 [870/1451 (65%)]\tLoss: 2.031695\n","Train Epoch: 10 [1400/1451 (87%)]\tLoss: 1.972578\n","Epoch 10 - Training: Average loss: 2.0294, Accuracy: 31.02%\n","Evaluation set: Average loss: 2.0279, Accuracy: 246/693 (35.50%), F1-score: 0.2215\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 11 [0/1451 (0%)]\tLoss: 2.065740\n","Train Epoch: 11 [290/1451 (22%)]\tLoss: 1.938022\n","Train Epoch: 11 [660/1451 (43%)]\tLoss: 1.981932\n","Train Epoch: 11 [930/1451 (65%)]\tLoss: 2.351994\n","Train Epoch: 11 [1400/1451 (87%)]\tLoss: 1.996610\n","Epoch 11 - Training: Average loss: 2.0202, Accuracy: 31.72%\n","Evaluation set: Average loss: 2.0078, Accuracy: 241/693 (34.78%), F1-score: 0.2195\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 12 [0/1451 (0%)]\tLoss: 1.957809\n","Train Epoch: 12 [370/1451 (22%)]\tLoss: 1.847824\n","Train Epoch: 12 [580/1451 (43%)]\tLoss: 2.068145\n","Train Epoch: 12 [960/1451 (65%)]\tLoss: 1.806185\n","Train Epoch: 12 [1160/1451 (87%)]\tLoss: 1.891679\n","Epoch 12 - Training: Average loss: 1.9678, Accuracy: 31.90%\n","Evaluation set: Average loss: 1.9905, Accuracy: 231/693 (33.33%), F1-score: 0.2096\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 13 [0/1451 (0%)]\tLoss: 2.130563\n","Train Epoch: 13 [340/1451 (22%)]\tLoss: 1.997048\n","Train Epoch: 13 [660/1451 (43%)]\tLoss: 1.822943\n","Train Epoch: 13 [660/1451 (65%)]\tLoss: 1.789161\n","Train Epoch: 13 [1120/1451 (87%)]\tLoss: 2.091691\n","Epoch 13 - Training: Average loss: 2.0263, Accuracy: 31.18%\n","Evaluation set: Average loss: 2.0010, Accuracy: 231/693 (33.33%), F1-score: 0.2059\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","EarlyStopping counter: 7 out of 10\n","Train Epoch: 14 [0/1451 (0%)]\tLoss: 2.082464\n","Train Epoch: 14 [300/1451 (22%)]\tLoss: 2.309530\n","Train Epoch: 14 [660/1451 (43%)]\tLoss: 1.779767\n","Train Epoch: 14 [870/1451 (65%)]\tLoss: 2.080874\n","Train Epoch: 14 [1440/1451 (87%)]\tLoss: 2.042952\n","Epoch 14 - Training: Average loss: 1.9754, Accuracy: 31.57%\n","Evaluation set: Average loss: 1.9731, Accuracy: 232/693 (33.48%), F1-score: 0.2083\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 8 out of 10\n","Train Epoch: 15 [0/1451 (0%)]\tLoss: 1.991009\n","Train Epoch: 15 [390/1451 (22%)]\tLoss: 1.965647\n","Train Epoch: 15 [440/1451 (43%)]\tLoss: 1.660801\n","Train Epoch: 15 [810/1451 (65%)]\tLoss: 2.230029\n","Train Epoch: 15 [1080/1451 (87%)]\tLoss: 1.988106\n","Epoch 15 - Training: Average loss: 2.0269, Accuracy: 32.35%\n","Evaluation set: Average loss: 1.9724, Accuracy: 232/693 (33.48%), F1-score: 0.2090\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 9 out of 10\n","Train Epoch: 16 [0/1451 (0%)]\tLoss: 2.014693\n","Train Epoch: 16 [330/1451 (22%)]\tLoss: 1.769600\n","Train Epoch: 16 [380/1451 (43%)]\tLoss: 2.259327\n","Train Epoch: 16 [780/1451 (65%)]\tLoss: 1.962788\n","Train Epoch: 16 [800/1451 (87%)]\tLoss: 2.429699\n","Epoch 16 - Training: Average loss: 1.9644, Accuracy: 34.20%\n","Evaluation set: Average loss: 1.9688, Accuracy: 232/693 (33.48%), F1-score: 0.2110\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","EarlyStopping counter: 10 out of 10\n","Early stopping\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.8467, Accuracy: 244/743 (32.84%), F1-score: 0.2146\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject102' 'subject104']\n","Train subjects: ['subject101' 'subject103' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1407 (0%)]\tLoss: 13.921944\n","Train Epoch: 1 [340/1407 (23%)]\tLoss: 8.575091\n","Train Epoch: 1 [680/1407 (45%)]\tLoss: 7.816368\n","Train Epoch: 1 [900/1407 (68%)]\tLoss: 10.562866\n","Train Epoch: 1 [1400/1407 (91%)]\tLoss: 5.292127\n","Epoch 1 - Training: Average loss: 8.0173, Accuracy: 25.44%\n","Evaluation set: Average loss: 6.1969, Accuracy: 127/737 (17.23%), F1-score: 0.1224\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1407 (0%)]\tLoss: 5.900434\n","Train Epoch: 2 [460/1407 (23%)]\tLoss: 5.619053\n","Train Epoch: 2 [680/1407 (45%)]\tLoss: 5.182262\n","Train Epoch: 2 [540/1407 (68%)]\tLoss: 5.141479\n","Train Epoch: 2 [1360/1407 (91%)]\tLoss: 4.272774\n","Epoch 2 - Training: Average loss: 5.5296, Accuracy: 15.02%\n","Evaluation set: Average loss: 4.8293, Accuracy: 88/737 (11.94%), F1-score: 0.0795\n","\n","Epsilon Spent: 0.074, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1407 (0%)]\tLoss: 6.857754\n","Train Epoch: 3 [370/1407 (23%)]\tLoss: 3.846037\n","Train Epoch: 3 [700/1407 (45%)]\tLoss: 4.153084\n","Train Epoch: 3 [900/1407 (68%)]\tLoss: 4.437340\n","Train Epoch: 3 [880/1407 (91%)]\tLoss: 5.089573\n","Epoch 3 - Training: Average loss: 4.3774, Accuracy: 16.69%\n","Evaluation set: Average loss: 4.1298, Accuracy: 147/737 (19.95%), F1-score: 0.1025\n","\n","Epsilon Spent: 0.09, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1407 (0%)]\tLoss: 3.539736\n","Train Epoch: 4 [300/1407 (23%)]\tLoss: 4.280249\n","Train Epoch: 4 [800/1407 (45%)]\tLoss: 4.237324\n","Train Epoch: 4 [870/1407 (68%)]\tLoss: 3.493881\n","Train Epoch: 4 [1280/1407 (91%)]\tLoss: 3.130647\n","Epoch 4 - Training: Average loss: 3.5140, Accuracy: 19.63%\n","Evaluation set: Average loss: 2.8316, Accuracy: 131/737 (17.77%), F1-score: 0.0990\n","\n","Epsilon Spent: 0.103, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1407 (0%)]\tLoss: 3.254657\n","Train Epoch: 5 [250/1407 (23%)]\tLoss: 2.485828\n","Train Epoch: 5 [740/1407 (45%)]\tLoss: 2.815238\n","Train Epoch: 5 [780/1407 (68%)]\tLoss: 1.968704\n","Train Epoch: 5 [1360/1407 (91%)]\tLoss: 2.220667\n","Epoch 5 - Training: Average loss: 2.4530, Accuracy: 24.19%\n","Evaluation set: Average loss: 2.1568, Accuracy: 165/737 (22.39%), F1-score: 0.1385\n","\n","Epsilon Spent: 0.116, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1407 (0%)]\tLoss: 2.421908\n","Train Epoch: 6 [420/1407 (23%)]\tLoss: 2.136062\n","Train Epoch: 6 [740/1407 (45%)]\tLoss: 1.947536\n","Train Epoch: 6 [1020/1407 (68%)]\tLoss: 1.933729\n","Train Epoch: 6 [1320/1407 (91%)]\tLoss: 2.248363\n","Epoch 6 - Training: Average loss: 2.0779, Accuracy: 24.56%\n","Evaluation set: Average loss: 2.1449, Accuracy: 109/737 (14.79%), F1-score: 0.1323\n","\n","Epsilon Spent: 0.126, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1407 (0%)]\tLoss: 2.060455\n","Train Epoch: 7 [390/1407 (23%)]\tLoss: 1.929337\n","Train Epoch: 7 [560/1407 (45%)]\tLoss: 2.419311\n","Train Epoch: 7 [1140/1407 (68%)]\tLoss: 2.080706\n","Train Epoch: 7 [920/1407 (91%)]\tLoss: 2.089020\n","Epoch 7 - Training: Average loss: 2.1003, Accuracy: 19.68%\n","Evaluation set: Average loss: 2.0797, Accuracy: 100/737 (13.57%), F1-score: 0.1244\n","\n","Epsilon Spent: 0.137, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1407 (0%)]\tLoss: 2.153072\n","Train Epoch: 8 [350/1407 (23%)]\tLoss: 1.981959\n","Train Epoch: 8 [860/1407 (45%)]\tLoss: 2.101072\n","Train Epoch: 8 [810/1407 (68%)]\tLoss: 2.122302\n","Train Epoch: 8 [880/1407 (91%)]\tLoss: 2.287439\n","Epoch 8 - Training: Average loss: 2.0537, Accuracy: 20.88%\n","Evaluation set: Average loss: 2.0816, Accuracy: 200/737 (27.14%), F1-score: 0.1765\n","\n","Epsilon Spent: 0.146, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1407 (0%)]\tLoss: 1.960733\n","Train Epoch: 9 [320/1407 (23%)]\tLoss: 2.200469\n","Train Epoch: 9 [660/1407 (45%)]\tLoss: 2.007663\n","Train Epoch: 9 [1410/1407 (68%)]\tLoss: 2.068063\n","Train Epoch: 9 [1280/1407 (91%)]\tLoss: 2.032382\n","Epoch 9 - Training: Average loss: 2.0980, Accuracy: 24.77%\n","Evaluation set: Average loss: 2.1350, Accuracy: 167/737 (22.66%), F1-score: 0.1666\n","\n","Epsilon Spent: 0.155, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 10 [0/1407 (0%)]\tLoss: 2.274879\n","Train Epoch: 10 [330/1407 (23%)]\tLoss: 2.238163\n","Train Epoch: 10 [580/1407 (45%)]\tLoss: 2.188249\n","Train Epoch: 10 [870/1407 (68%)]\tLoss: 2.084886\n","Train Epoch: 10 [1280/1407 (91%)]\tLoss: 1.996020\n","Epoch 10 - Training: Average loss: 2.1229, Accuracy: 19.90%\n","Evaluation set: Average loss: 2.0502, Accuracy: 176/737 (23.88%), F1-score: 0.2207\n","\n","Epsilon Spent: 0.164, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1407 (0%)]\tLoss: 1.847301\n","Train Epoch: 11 [260/1407 (23%)]\tLoss: 1.686296\n","Train Epoch: 11 [580/1407 (45%)]\tLoss: 2.174101\n","Train Epoch: 11 [990/1407 (68%)]\tLoss: 2.212152\n","Train Epoch: 11 [1360/1407 (91%)]\tLoss: 2.037406\n","Epoch 11 - Training: Average loss: 1.9917, Accuracy: 29.38%\n","Evaluation set: Average loss: 1.9279, Accuracy: 238/737 (32.29%), F1-score: 0.2211\n","\n","Epsilon Spent: 0.172, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1407 (0%)]\tLoss: 1.583719\n","Train Epoch: 12 [390/1407 (23%)]\tLoss: 1.912007\n","Train Epoch: 12 [540/1407 (45%)]\tLoss: 1.901501\n","Train Epoch: 12 [630/1407 (68%)]\tLoss: 1.640227\n","Train Epoch: 12 [1200/1407 (91%)]\tLoss: 1.959686\n","Epoch 12 - Training: Average loss: 1.8753, Accuracy: 40.32%\n","Evaluation set: Average loss: 2.0133, Accuracy: 250/737 (33.92%), F1-score: 0.2475\n","\n","Epsilon Spent: 0.18, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 13 [0/1407 (0%)]\tLoss: 1.991798\n","Train Epoch: 13 [380/1407 (23%)]\tLoss: 1.984052\n","Train Epoch: 13 [840/1407 (45%)]\tLoss: 2.247254\n","Train Epoch: 13 [1050/1407 (68%)]\tLoss: 1.788819\n","Train Epoch: 13 [1000/1407 (91%)]\tLoss: 2.288803\n","Epoch 13 - Training: Average loss: 1.9998, Accuracy: 35.45%\n","Evaluation set: Average loss: 2.1583, Accuracy: 165/737 (22.39%), F1-score: 0.1208\n","\n","Epsilon Spent: 0.187, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 14 [0/1407 (0%)]\tLoss: 1.887768\n","Train Epoch: 14 [210/1407 (23%)]\tLoss: 1.929946\n","Train Epoch: 14 [940/1407 (45%)]\tLoss: 1.923443\n","Train Epoch: 14 [1230/1407 (68%)]\tLoss: 2.192829\n","Train Epoch: 14 [1240/1407 (91%)]\tLoss: 1.990471\n","Epoch 14 - Training: Average loss: 2.0665, Accuracy: 40.87%\n","Evaluation set: Average loss: 2.3457, Accuracy: 212/737 (28.77%), F1-score: 0.1679\n","\n","Epsilon Spent: 0.194, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 15 [0/1407 (0%)]\tLoss: 2.136254\n","Train Epoch: 15 [440/1407 (23%)]\tLoss: 2.327185\n","Train Epoch: 15 [700/1407 (45%)]\tLoss: 2.116917\n","Train Epoch: 15 [660/1407 (68%)]\tLoss: 1.802443\n","Train Epoch: 15 [1240/1407 (91%)]\tLoss: 2.434819\n","Epoch 15 - Training: Average loss: 2.2088, Accuracy: 25.37%\n","Evaluation set: Average loss: 2.2444, Accuracy: 183/737 (24.83%), F1-score: 0.1491\n","\n","Epsilon Spent: 0.201, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 16 [0/1407 (0%)]\tLoss: 2.525692\n","Train Epoch: 16 [320/1407 (23%)]\tLoss: 2.083821\n","Train Epoch: 16 [540/1407 (45%)]\tLoss: 2.282972\n","Train Epoch: 16 [1170/1407 (68%)]\tLoss: 2.401509\n","Train Epoch: 16 [1160/1407 (91%)]\tLoss: 2.195675\n","Epoch 16 - Training: Average loss: 2.1793, Accuracy: 25.97%\n","Evaluation set: Average loss: 2.1823, Accuracy: 178/737 (24.15%), F1-score: 0.1499\n","\n","Epsilon Spent: 0.208, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 17 [0/1407 (0%)]\tLoss: 2.206372\n","Train Epoch: 17 [330/1407 (23%)]\tLoss: 2.279261\n","Train Epoch: 17 [680/1407 (45%)]\tLoss: 1.835104\n","Train Epoch: 17 [960/1407 (68%)]\tLoss: 2.058846\n","Train Epoch: 17 [1520/1407 (91%)]\tLoss: 1.928076\n","Epoch 17 - Training: Average loss: 2.0730, Accuracy: 30.49%\n","Evaluation set: Average loss: 2.1358, Accuracy: 172/737 (23.34%), F1-score: 0.1267\n","\n","Epsilon Spent: 0.215, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 18 [0/1407 (0%)]\tLoss: 2.096175\n","Train Epoch: 18 [250/1407 (23%)]\tLoss: 2.176179\n","Train Epoch: 18 [640/1407 (45%)]\tLoss: 2.043734\n","Train Epoch: 18 [1230/1407 (68%)]\tLoss: 1.867573\n","Train Epoch: 18 [1000/1407 (91%)]\tLoss: 2.044790\n","Epoch 18 - Training: Average loss: 1.9375, Accuracy: 35.29%\n","Evaluation set: Average loss: 2.0977, Accuracy: 201/737 (27.27%), F1-score: 0.1742\n","\n","Epsilon Spent: 0.221, Noise_Scale: 10.0\n","EarlyStopping counter: 7 out of 10\n","Train Epoch: 19 [0/1407 (0%)]\tLoss: 1.985379\n","Train Epoch: 19 [310/1407 (23%)]\tLoss: 2.060930\n","Train Epoch: 19 [580/1407 (45%)]\tLoss: 1.950364\n","Train Epoch: 19 [900/1407 (68%)]\tLoss: 2.323688\n","Train Epoch: 19 [880/1407 (91%)]\tLoss: 2.224749\n","Epoch 19 - Training: Average loss: 2.0478, Accuracy: 31.44%\n","Evaluation set: Average loss: 2.0490, Accuracy: 209/737 (28.36%), F1-score: 0.1925\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 8 out of 10\n","Train Epoch: 20 [0/1407 (0%)]\tLoss: 1.927840\n","Train Epoch: 20 [310/1407 (23%)]\tLoss: 2.069502\n","Train Epoch: 20 [720/1407 (45%)]\tLoss: 1.931127\n","Train Epoch: 20 [780/1407 (68%)]\tLoss: 1.695654\n","Train Epoch: 20 [1480/1407 (91%)]\tLoss: 1.853449\n","Epoch 20 - Training: Average loss: 1.9500, Accuracy: 34.04%\n","Evaluation set: Average loss: 2.0434, Accuracy: 211/737 (28.63%), F1-score: 0.1951\n","\n","Epsilon Spent: 0.234, Noise_Scale: 10.0\n","EarlyStopping counter: 9 out of 10\n"," #### Test Evaluation is starting for ['subject105' 'subject108'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.9560, Accuracy: 237/743 (31.90%), F1-score: 0.2184\n","\n","Outer Fold 3 is starting ...\n","Test subjects: ['subject103' 'subject106']\n","Train-Validation subjects: ['subject101' 'subject102' 'subject104' 'subject105' 'subject107'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject104' 'subject105']\n","Train subjects: ['subject101' 'subject102' 'subject107' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1437 (0%)]\tLoss: 10.770754\n","Train Epoch: 1 [340/1437 (22%)]\tLoss: 11.905116\n","Train Epoch: 1 [620/1437 (44%)]\tLoss: 8.686177\n","Train Epoch: 1 [840/1437 (67%)]\tLoss: 7.046012\n","Train Epoch: 1 [1160/1437 (89%)]\tLoss: 7.671498\n","Epoch 1 - Training: Average loss: 9.0043, Accuracy: 8.77%\n","Evaluation set: Average loss: 6.3503, Accuracy: 94/743 (12.65%), F1-score: 0.0647\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1437 (0%)]\tLoss: 7.255921\n","Train Epoch: 2 [310/1437 (22%)]\tLoss: 5.629334\n","Train Epoch: 2 [640/1437 (44%)]\tLoss: 4.322739\n","Train Epoch: 2 [840/1437 (67%)]\tLoss: 4.526341\n","Train Epoch: 2 [1360/1437 (89%)]\tLoss: 4.128668\n","Epoch 2 - Training: Average loss: 5.1842, Accuracy: 18.93%\n","Evaluation set: Average loss: 4.1020, Accuracy: 166/743 (22.34%), F1-score: 0.1061\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1437 (0%)]\tLoss: 3.874672\n","Train Epoch: 3 [350/1437 (22%)]\tLoss: 3.619483\n","Train Epoch: 3 [700/1437 (44%)]\tLoss: 3.119879\n","Train Epoch: 3 [930/1437 (67%)]\tLoss: 3.914708\n","Train Epoch: 3 [1080/1437 (89%)]\tLoss: 3.534641\n","Epoch 3 - Training: Average loss: 3.7254, Accuracy: 23.00%\n","Evaluation set: Average loss: 3.0808, Accuracy: 165/743 (22.21%), F1-score: 0.1301\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1437 (0%)]\tLoss: 3.186969\n","Train Epoch: 4 [370/1437 (22%)]\tLoss: 3.028782\n","Train Epoch: 4 [720/1437 (44%)]\tLoss: 2.799020\n","Train Epoch: 4 [750/1437 (67%)]\tLoss: 3.123063\n","Train Epoch: 4 [1440/1437 (89%)]\tLoss: 2.306932\n","Epoch 4 - Training: Average loss: 2.8135, Accuracy: 14.63%\n","Evaluation set: Average loss: 2.3263, Accuracy: 116/743 (15.61%), F1-score: 0.1209\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1437 (0%)]\tLoss: 2.308660\n","Train Epoch: 5 [250/1437 (22%)]\tLoss: 2.413766\n","Train Epoch: 5 [640/1437 (44%)]\tLoss: 2.280736\n","Train Epoch: 5 [930/1437 (67%)]\tLoss: 2.402122\n","Train Epoch: 5 [880/1437 (89%)]\tLoss: 2.613018\n","Epoch 5 - Training: Average loss: 2.3900, Accuracy: 18.43%\n","Evaluation set: Average loss: 2.1596, Accuracy: 186/743 (25.03%), F1-score: 0.1573\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1437 (0%)]\tLoss: 2.047016\n","Train Epoch: 6 [300/1437 (22%)]\tLoss: 2.174359\n","Train Epoch: 6 [600/1437 (44%)]\tLoss: 2.194875\n","Train Epoch: 6 [900/1437 (67%)]\tLoss: 2.461876\n","Train Epoch: 6 [1200/1437 (89%)]\tLoss: 2.204729\n","Epoch 6 - Training: Average loss: 2.1989, Accuracy: 23.19%\n","Evaluation set: Average loss: 2.0937, Accuracy: 170/743 (22.88%), F1-score: 0.1410\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1437 (0%)]\tLoss: 2.029454\n","Train Epoch: 7 [310/1437 (22%)]\tLoss: 2.323467\n","Train Epoch: 7 [700/1437 (44%)]\tLoss: 2.132411\n","Train Epoch: 7 [960/1437 (67%)]\tLoss: 1.976984\n","Train Epoch: 7 [1280/1437 (89%)]\tLoss: 2.058223\n","Epoch 7 - Training: Average loss: 2.0253, Accuracy: 29.96%\n","Evaluation set: Average loss: 2.0820, Accuracy: 190/743 (25.57%), F1-score: 0.1490\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1437 (0%)]\tLoss: 1.845509\n","Train Epoch: 8 [360/1437 (22%)]\tLoss: 1.841088\n","Train Epoch: 8 [700/1437 (44%)]\tLoss: 1.851343\n","Train Epoch: 8 [1080/1437 (67%)]\tLoss: 1.794011\n","Train Epoch: 8 [1240/1437 (89%)]\tLoss: 1.916834\n","Epoch 8 - Training: Average loss: 1.9630, Accuracy: 37.75%\n","Evaluation set: Average loss: 1.9523, Accuracy: 247/743 (33.24%), F1-score: 0.2146\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1437 (0%)]\tLoss: 1.989856\n","Train Epoch: 9 [340/1437 (22%)]\tLoss: 1.685015\n","Train Epoch: 9 [840/1437 (44%)]\tLoss: 2.083961\n","Train Epoch: 9 [870/1437 (67%)]\tLoss: 2.293908\n","Train Epoch: 9 [1360/1437 (89%)]\tLoss: 1.988528\n","Epoch 9 - Training: Average loss: 1.9801, Accuracy: 32.11%\n","Evaluation set: Average loss: 1.9950, Accuracy: 226/743 (30.42%), F1-score: 0.2086\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1437 (0%)]\tLoss: 2.085922\n","Train Epoch: 10 [310/1437 (22%)]\tLoss: 2.034097\n","Train Epoch: 10 [520/1437 (44%)]\tLoss: 2.132415\n","Train Epoch: 10 [960/1437 (67%)]\tLoss: 2.122248\n","Train Epoch: 10 [1720/1437 (89%)]\tLoss: 1.836431\n","Epoch 10 - Training: Average loss: 1.9325, Accuracy: 33.93%\n","Evaluation set: Average loss: 2.1375, Accuracy: 211/743 (28.40%), F1-score: 0.1262\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 11 [0/1437 (0%)]\tLoss: 1.978753\n","Train Epoch: 11 [210/1437 (22%)]\tLoss: 2.015750\n","Train Epoch: 11 [680/1437 (44%)]\tLoss: 2.099756\n","Train Epoch: 11 [930/1437 (67%)]\tLoss: 2.290977\n","Train Epoch: 11 [1440/1437 (89%)]\tLoss: 2.111291\n","Epoch 11 - Training: Average loss: 2.0776, Accuracy: 28.49%\n","Evaluation set: Average loss: 1.9691, Accuracy: 218/743 (29.34%), F1-score: 0.1730\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 12 [0/1437 (0%)]\tLoss: 2.243598\n","Train Epoch: 12 [280/1437 (22%)]\tLoss: 1.870832\n","Train Epoch: 12 [540/1437 (44%)]\tLoss: 1.999163\n","Train Epoch: 12 [1020/1437 (67%)]\tLoss: 2.242921\n","Train Epoch: 12 [1280/1437 (89%)]\tLoss: 2.194536\n","Epoch 12 - Training: Average loss: 2.0371, Accuracy: 26.77%\n","Evaluation set: Average loss: 2.0697, Accuracy: 162/743 (21.80%), F1-score: 0.1262\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 13 [0/1437 (0%)]\tLoss: 2.044284\n","Train Epoch: 13 [290/1437 (22%)]\tLoss: 2.044231\n","Train Epoch: 13 [760/1437 (44%)]\tLoss: 1.924683\n","Train Epoch: 13 [840/1437 (67%)]\tLoss: 1.920009\n","Train Epoch: 13 [1160/1437 (89%)]\tLoss: 2.088567\n","Epoch 13 - Training: Average loss: 2.0044, Accuracy: 25.07%\n","Evaluation set: Average loss: 2.0060, Accuracy: 188/743 (25.30%), F1-score: 0.1514\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 14 [0/1437 (0%)]\tLoss: 1.982770\n","Train Epoch: 14 [360/1437 (22%)]\tLoss: 1.946656\n","Train Epoch: 14 [760/1437 (44%)]\tLoss: 2.054930\n","Train Epoch: 14 [960/1437 (67%)]\tLoss: 1.985130\n","Train Epoch: 14 [1280/1437 (89%)]\tLoss: 1.853301\n","Epoch 14 - Training: Average loss: 1.9243, Accuracy: 31.63%\n","Evaluation set: Average loss: 1.9601, Accuracy: 221/743 (29.74%), F1-score: 0.1856\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 15 [0/1437 (0%)]\tLoss: 1.668951\n","Train Epoch: 15 [250/1437 (22%)]\tLoss: 1.860953\n","Train Epoch: 15 [620/1437 (44%)]\tLoss: 1.939128\n","Train Epoch: 15 [780/1437 (67%)]\tLoss: 2.078273\n","Train Epoch: 15 [1480/1437 (89%)]\tLoss: 1.948746\n","Epoch 15 - Training: Average loss: 1.9283, Accuracy: 31.38%\n","Evaluation set: Average loss: 1.9538, Accuracy: 221/743 (29.74%), F1-score: 0.1993\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","EarlyStopping counter: 7 out of 10\n","Train Epoch: 16 [0/1437 (0%)]\tLoss: 1.959942\n","Train Epoch: 16 [330/1437 (22%)]\tLoss: 1.737468\n","Train Epoch: 16 [620/1437 (44%)]\tLoss: 2.112308\n","Train Epoch: 16 [600/1437 (67%)]\tLoss: 1.616503\n","Train Epoch: 16 [1000/1437 (89%)]\tLoss: 1.843614\n","Epoch 16 - Training: Average loss: 1.9154, Accuracy: 30.87%\n","Evaluation set: Average loss: 1.9461, Accuracy: 225/743 (30.28%), F1-score: 0.2192\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1437 (0%)]\tLoss: 1.833939\n","Train Epoch: 17 [240/1437 (22%)]\tLoss: 1.672242\n","Train Epoch: 17 [580/1437 (44%)]\tLoss: 1.932249\n","Train Epoch: 17 [750/1437 (67%)]\tLoss: 1.825302\n","Train Epoch: 17 [1200/1437 (89%)]\tLoss: 1.648268\n","Epoch 17 - Training: Average loss: 1.9004, Accuracy: 30.57%\n","Evaluation set: Average loss: 1.9483, Accuracy: 220/743 (29.61%), F1-score: 0.2202\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1437 (0%)]\tLoss: 1.864429\n","Train Epoch: 18 [220/1437 (22%)]\tLoss: 1.793981\n","Train Epoch: 18 [620/1437 (44%)]\tLoss: 2.026545\n","Train Epoch: 18 [930/1437 (67%)]\tLoss: 1.882967\n","Train Epoch: 18 [1600/1437 (89%)]\tLoss: 1.846182\n","Epoch 18 - Training: Average loss: 1.8865, Accuracy: 33.70%\n","Evaluation set: Average loss: 1.9447, Accuracy: 243/743 (32.71%), F1-score: 0.2338\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","Train Epoch: 19 [0/1437 (0%)]\tLoss: 1.923088\n","Train Epoch: 19 [350/1437 (22%)]\tLoss: 2.027007\n","Train Epoch: 19 [680/1437 (44%)]\tLoss: 1.684163\n","Train Epoch: 19 [600/1437 (67%)]\tLoss: 1.993778\n","Train Epoch: 19 [920/1437 (89%)]\tLoss: 1.747248\n","Epoch 19 - Training: Average loss: 1.9046, Accuracy: 32.30%\n","Evaluation set: Average loss: 1.9329, Accuracy: 249/743 (33.51%), F1-score: 0.2377\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1437 (0%)]\tLoss: 2.023860\n","Train Epoch: 20 [380/1437 (22%)]\tLoss: 1.911505\n","Train Epoch: 20 [520/1437 (44%)]\tLoss: 2.007001\n","Train Epoch: 20 [1020/1437 (67%)]\tLoss: 1.800374\n","Train Epoch: 20 [1360/1437 (89%)]\tLoss: 2.033910\n","Epoch 20 - Training: Average loss: 1.8993, Accuracy: 29.29%\n","Evaluation set: Average loss: 1.9554, Accuracy: 186/743 (25.03%), F1-score: 0.1779\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.8836, Accuracy: 245/707 (34.65%), F1-score: 0.2423\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject102' 'subject107']\n","Train subjects: ['subject101' 'subject104' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1452 (0%)]\tLoss: 20.864216\n","Train Epoch: 1 [270/1452 (22%)]\tLoss: 15.359638\n","Train Epoch: 1 [740/1452 (43%)]\tLoss: 12.136350\n","Train Epoch: 1 [810/1452 (65%)]\tLoss: 9.897938\n","Train Epoch: 1 [1560/1452 (87%)]\tLoss: 7.156351\n","Epoch 1 - Training: Average loss: 12.0794, Accuracy: 11.10%\n","Evaluation set: Average loss: 6.0504, Accuracy: 31/728 (4.26%), F1-score: 0.0182\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1452 (0%)]\tLoss: 6.726737\n","Train Epoch: 2 [230/1452 (22%)]\tLoss: 5.346132\n","Train Epoch: 2 [680/1452 (43%)]\tLoss: 3.298120\n","Train Epoch: 2 [870/1452 (65%)]\tLoss: 3.483757\n","Train Epoch: 2 [1080/1452 (87%)]\tLoss: 4.044627\n","Epoch 2 - Training: Average loss: 4.6299, Accuracy: 13.82%\n","Evaluation set: Average loss: 3.4802, Accuracy: 133/728 (18.27%), F1-score: 0.0459\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1452 (0%)]\tLoss: 3.814775\n","Train Epoch: 3 [310/1452 (22%)]\tLoss: 2.727742\n","Train Epoch: 3 [620/1452 (43%)]\tLoss: 2.097361\n","Train Epoch: 3 [810/1452 (65%)]\tLoss: 1.970056\n","Train Epoch: 3 [1120/1452 (87%)]\tLoss: 2.223231\n","Epoch 3 - Training: Average loss: 2.5803, Accuracy: 16.20%\n","Evaluation set: Average loss: 2.1692, Accuracy: 93/728 (12.77%), F1-score: 0.0952\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1452 (0%)]\tLoss: 2.205773\n","Train Epoch: 4 [210/1452 (22%)]\tLoss: 1.869069\n","Train Epoch: 4 [600/1452 (43%)]\tLoss: 2.120826\n","Train Epoch: 4 [990/1452 (65%)]\tLoss: 2.058833\n","Train Epoch: 4 [1080/1452 (87%)]\tLoss: 2.077075\n","Epoch 4 - Training: Average loss: 2.1654, Accuracy: 19.17%\n","Evaluation set: Average loss: 2.0211, Accuracy: 277/728 (38.05%), F1-score: 0.2755\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1452 (0%)]\tLoss: 2.383225\n","Train Epoch: 5 [390/1452 (22%)]\tLoss: 2.269037\n","Train Epoch: 5 [540/1452 (43%)]\tLoss: 2.182657\n","Train Epoch: 5 [960/1452 (65%)]\tLoss: 1.807560\n","Train Epoch: 5 [1400/1452 (87%)]\tLoss: 2.506114\n","Epoch 5 - Training: Average loss: 2.2013, Accuracy: 19.49%\n","Evaluation set: Average loss: 2.0507, Accuracy: 198/728 (27.20%), F1-score: 0.1734\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 6 [0/1452 (0%)]\tLoss: 1.885673\n","Train Epoch: 6 [240/1452 (22%)]\tLoss: 1.969207\n","Train Epoch: 6 [660/1452 (43%)]\tLoss: 2.023339\n","Train Epoch: 6 [840/1452 (65%)]\tLoss: 2.148615\n","Train Epoch: 6 [1160/1452 (87%)]\tLoss: 2.485853\n","Epoch 6 - Training: Average loss: 2.1582, Accuracy: 24.36%\n","Evaluation set: Average loss: 2.0596, Accuracy: 269/728 (36.95%), F1-score: 0.2393\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 7 [0/1452 (0%)]\tLoss: 2.557990\n","Train Epoch: 7 [300/1452 (22%)]\tLoss: 1.969509\n","Train Epoch: 7 [580/1452 (43%)]\tLoss: 2.510862\n","Train Epoch: 7 [1080/1452 (65%)]\tLoss: 1.945817\n","Train Epoch: 7 [1320/1452 (87%)]\tLoss: 2.098543\n","Epoch 7 - Training: Average loss: 2.1329, Accuracy: 31.67%\n","Evaluation set: Average loss: 1.8316, Accuracy: 356/728 (48.90%), F1-score: 0.3163\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1452 (0%)]\tLoss: 2.388263\n","Train Epoch: 8 [340/1452 (22%)]\tLoss: 1.810470\n","Train Epoch: 8 [700/1452 (43%)]\tLoss: 1.891391\n","Train Epoch: 8 [1110/1452 (65%)]\tLoss: 2.021431\n","Train Epoch: 8 [960/1452 (87%)]\tLoss: 1.768679\n","Epoch 8 - Training: Average loss: 1.9404, Accuracy: 34.49%\n","Evaluation set: Average loss: 1.7656, Accuracy: 255/728 (35.03%), F1-score: 0.2364\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1452 (0%)]\tLoss: 1.710666\n","Train Epoch: 9 [280/1452 (22%)]\tLoss: 1.963484\n","Train Epoch: 9 [660/1452 (43%)]\tLoss: 2.002321\n","Train Epoch: 9 [870/1452 (65%)]\tLoss: 1.879061\n","Train Epoch: 9 [1040/1452 (87%)]\tLoss: 2.260140\n","Epoch 9 - Training: Average loss: 2.0162, Accuracy: 28.75%\n","Evaluation set: Average loss: 1.9721, Accuracy: 329/728 (45.19%), F1-score: 0.3144\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1452 (0%)]\tLoss: 1.938101\n","Train Epoch: 10 [420/1452 (22%)]\tLoss: 1.991122\n","Train Epoch: 10 [440/1452 (43%)]\tLoss: 2.231894\n","Train Epoch: 10 [1080/1452 (65%)]\tLoss: 1.487789\n","Train Epoch: 10 [1280/1452 (87%)]\tLoss: 1.490099\n","Epoch 10 - Training: Average loss: 2.0248, Accuracy: 33.54%\n","Evaluation set: Average loss: 1.7084, Accuracy: 375/728 (51.51%), F1-score: 0.3895\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1452 (0%)]\tLoss: 1.521016\n","Train Epoch: 11 [270/1452 (22%)]\tLoss: 2.113026\n","Train Epoch: 11 [660/1452 (43%)]\tLoss: 2.135639\n","Train Epoch: 11 [1080/1452 (65%)]\tLoss: 1.645007\n","Train Epoch: 11 [1640/1452 (87%)]\tLoss: 1.732363\n","Epoch 11 - Training: Average loss: 1.8481, Accuracy: 37.97%\n","Evaluation set: Average loss: 1.7268, Accuracy: 330/728 (45.33%), F1-score: 0.2777\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 12 [0/1452 (0%)]\tLoss: 2.229460\n","Train Epoch: 12 [270/1452 (22%)]\tLoss: 1.818318\n","Train Epoch: 12 [700/1452 (43%)]\tLoss: 2.096259\n","Train Epoch: 12 [1230/1452 (65%)]\tLoss: 1.854154\n","Train Epoch: 12 [1520/1452 (87%)]\tLoss: 1.799809\n","Epoch 12 - Training: Average loss: 1.8737, Accuracy: 40.86%\n","Evaluation set: Average loss: 1.6433, Accuracy: 369/728 (50.69%), F1-score: 0.3601\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1452 (0%)]\tLoss: 1.917368\n","Train Epoch: 13 [390/1452 (22%)]\tLoss: 1.636360\n","Train Epoch: 13 [740/1452 (43%)]\tLoss: 1.824086\n","Train Epoch: 13 [1050/1452 (65%)]\tLoss: 1.644320\n","Train Epoch: 13 [1440/1452 (87%)]\tLoss: 1.731120\n","Epoch 13 - Training: Average loss: 1.7903, Accuracy: 39.39%\n","Evaluation set: Average loss: 1.6530, Accuracy: 307/728 (42.17%), F1-score: 0.3096\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 14 [0/1452 (0%)]\tLoss: 1.782178\n","Train Epoch: 14 [410/1452 (22%)]\tLoss: 1.957177\n","Train Epoch: 14 [540/1452 (43%)]\tLoss: 1.665868\n","Train Epoch: 14 [1170/1452 (65%)]\tLoss: 1.781371\n","Train Epoch: 14 [1160/1452 (87%)]\tLoss: 1.689420\n","Epoch 14 - Training: Average loss: 1.8635, Accuracy: 35.82%\n","Evaluation set: Average loss: 1.7737, Accuracy: 301/728 (41.35%), F1-score: 0.2622\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 15 [0/1452 (0%)]\tLoss: 1.879311\n","Train Epoch: 15 [340/1452 (22%)]\tLoss: 1.884864\n","Train Epoch: 15 [560/1452 (43%)]\tLoss: 1.928636\n","Train Epoch: 15 [1110/1452 (65%)]\tLoss: 1.994881\n","Train Epoch: 15 [1320/1452 (87%)]\tLoss: 2.350805\n","Epoch 15 - Training: Average loss: 1.9982, Accuracy: 32.47%\n","Evaluation set: Average loss: 1.5752, Accuracy: 319/728 (43.82%), F1-score: 0.3160\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1452 (0%)]\tLoss: 1.711844\n","Train Epoch: 16 [350/1452 (22%)]\tLoss: 1.804172\n","Train Epoch: 16 [680/1452 (43%)]\tLoss: 1.781950\n","Train Epoch: 16 [810/1452 (65%)]\tLoss: 1.745877\n","Train Epoch: 16 [1720/1452 (87%)]\tLoss: 1.934971\n","Epoch 16 - Training: Average loss: 1.7931, Accuracy: 33.08%\n","Evaluation set: Average loss: 1.6544, Accuracy: 288/728 (39.56%), F1-score: 0.2529\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 17 [0/1452 (0%)]\tLoss: 1.793469\n","Train Epoch: 17 [320/1452 (22%)]\tLoss: 2.029050\n","Train Epoch: 17 [520/1452 (43%)]\tLoss: 1.562270\n","Train Epoch: 17 [1290/1452 (65%)]\tLoss: 1.968613\n","Train Epoch: 17 [1120/1452 (87%)]\tLoss: 1.640369\n","Epoch 17 - Training: Average loss: 1.8306, Accuracy: 32.40%\n","Evaluation set: Average loss: 1.6844, Accuracy: 269/728 (36.95%), F1-score: 0.2444\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 18 [0/1452 (0%)]\tLoss: 1.928305\n","Train Epoch: 18 [340/1452 (22%)]\tLoss: 1.789948\n","Train Epoch: 18 [860/1452 (43%)]\tLoss: 1.682675\n","Train Epoch: 18 [1050/1452 (65%)]\tLoss: 2.038342\n","Train Epoch: 18 [1840/1452 (87%)]\tLoss: 1.972577\n","Epoch 18 - Training: Average loss: 1.8906, Accuracy: 33.13%\n","Evaluation set: Average loss: 1.8383, Accuracy: 299/728 (41.07%), F1-score: 0.2611\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 19 [0/1452 (0%)]\tLoss: 2.176035\n","Train Epoch: 19 [310/1452 (22%)]\tLoss: 2.266019\n","Train Epoch: 19 [460/1452 (43%)]\tLoss: 2.385486\n","Train Epoch: 19 [870/1452 (65%)]\tLoss: 1.972580\n","Train Epoch: 19 [840/1452 (87%)]\tLoss: 2.194876\n","Epoch 19 - Training: Average loss: 1.9671, Accuracy: 29.79%\n","Evaluation set: Average loss: 1.7742, Accuracy: 303/728 (41.62%), F1-score: 0.3098\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 20 [0/1452 (0%)]\tLoss: 1.915799\n","Train Epoch: 20 [360/1452 (22%)]\tLoss: 1.914351\n","Train Epoch: 20 [540/1452 (43%)]\tLoss: 2.248122\n","Train Epoch: 20 [780/1452 (65%)]\tLoss: 1.805850\n","Train Epoch: 20 [1480/1452 (87%)]\tLoss: 1.827179\n","Epoch 20 - Training: Average loss: 1.9340, Accuracy: 31.64%\n","Evaluation set: Average loss: 1.7684, Accuracy: 309/728 (42.45%), F1-score: 0.3099\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.7091, Accuracy: 269/707 (38.05%), F1-score: 0.2901\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject101' 'subject108']\n","Train subjects: ['subject102' 'subject104' 'subject105' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1471 (0%)]\tLoss: 9.742836\n","Train Epoch: 1 [320/1471 (22%)]\tLoss: 6.494500\n","Train Epoch: 1 [640/1471 (43%)]\tLoss: 5.375242\n","Train Epoch: 1 [1170/1471 (65%)]\tLoss: 5.821149\n","Train Epoch: 1 [920/1471 (87%)]\tLoss: 5.936109\n","Epoch 1 - Training: Average loss: 6.3146, Accuracy: 20.72%\n","Evaluation set: Average loss: 4.9113, Accuracy: 141/709 (19.89%), F1-score: 0.0875\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1471 (0%)]\tLoss: 4.882534\n","Train Epoch: 2 [270/1471 (22%)]\tLoss: 4.618705\n","Train Epoch: 2 [540/1471 (43%)]\tLoss: 3.542723\n","Train Epoch: 2 [1020/1471 (65%)]\tLoss: 4.414768\n","Train Epoch: 2 [1080/1471 (87%)]\tLoss: 3.693718\n","Epoch 2 - Training: Average loss: 4.3178, Accuracy: 22.97%\n","Evaluation set: Average loss: 3.8637, Accuracy: 132/709 (18.62%), F1-score: 0.0790\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1471 (0%)]\tLoss: 2.883440\n","Train Epoch: 3 [400/1471 (22%)]\tLoss: 3.127521\n","Train Epoch: 3 [780/1471 (43%)]\tLoss: 2.286844\n","Train Epoch: 3 [780/1471 (65%)]\tLoss: 2.362440\n","Train Epoch: 3 [1480/1471 (87%)]\tLoss: 2.771636\n","Epoch 3 - Training: Average loss: 3.1215, Accuracy: 21.86%\n","Evaluation set: Average loss: 2.8771, Accuracy: 124/709 (17.49%), F1-score: 0.0816\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1471 (0%)]\tLoss: 2.294710\n","Train Epoch: 4 [350/1471 (22%)]\tLoss: 3.387408\n","Train Epoch: 4 [660/1471 (43%)]\tLoss: 2.726694\n","Train Epoch: 4 [990/1471 (65%)]\tLoss: 2.575735\n","Train Epoch: 4 [1280/1471 (87%)]\tLoss: 2.936368\n","Epoch 4 - Training: Average loss: 2.6912, Accuracy: 22.10%\n","Evaluation set: Average loss: 2.7354, Accuracy: 120/709 (16.93%), F1-score: 0.0720\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1471 (0%)]\tLoss: 2.940084\n","Train Epoch: 5 [340/1471 (22%)]\tLoss: 3.287984\n","Train Epoch: 5 [480/1471 (43%)]\tLoss: 2.461609\n","Train Epoch: 5 [1080/1471 (65%)]\tLoss: 2.037551\n","Train Epoch: 5 [1800/1471 (87%)]\tLoss: 2.185619\n","Epoch 5 - Training: Average loss: 2.4767, Accuracy: 27.86%\n","Evaluation set: Average loss: 2.3700, Accuracy: 200/709 (28.21%), F1-score: 0.1314\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1471 (0%)]\tLoss: 2.229833\n","Train Epoch: 6 [220/1471 (22%)]\tLoss: 2.086417\n","Train Epoch: 6 [500/1471 (43%)]\tLoss: 2.058166\n","Train Epoch: 6 [1080/1471 (65%)]\tLoss: 2.070471\n","Train Epoch: 6 [1920/1471 (87%)]\tLoss: 2.001255\n","Epoch 6 - Training: Average loss: 2.2163, Accuracy: 28.77%\n","Evaluation set: Average loss: 2.1574, Accuracy: 170/709 (23.98%), F1-score: 0.1218\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1471 (0%)]\tLoss: 1.985284\n","Train Epoch: 7 [370/1471 (22%)]\tLoss: 2.086210\n","Train Epoch: 7 [560/1471 (43%)]\tLoss: 2.018396\n","Train Epoch: 7 [1170/1471 (65%)]\tLoss: 1.990342\n","Train Epoch: 7 [1280/1471 (87%)]\tLoss: 1.959765\n","Epoch 7 - Training: Average loss: 2.0088, Accuracy: 24.90%\n","Evaluation set: Average loss: 2.1153, Accuracy: 142/709 (20.03%), F1-score: 0.1080\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1471 (0%)]\tLoss: 2.182499\n","Train Epoch: 8 [250/1471 (22%)]\tLoss: 1.908797\n","Train Epoch: 8 [740/1471 (43%)]\tLoss: 2.075021\n","Train Epoch: 8 [1110/1471 (65%)]\tLoss: 2.113529\n","Train Epoch: 8 [1480/1471 (87%)]\tLoss: 2.173185\n","Epoch 8 - Training: Average loss: 2.0707, Accuracy: 21.44%\n","Evaluation set: Average loss: 2.0676, Accuracy: 123/709 (17.35%), F1-score: 0.1312\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1471 (0%)]\tLoss: 2.165072\n","Train Epoch: 9 [300/1471 (22%)]\tLoss: 2.267628\n","Train Epoch: 9 [720/1471 (43%)]\tLoss: 2.124083\n","Train Epoch: 9 [1020/1471 (65%)]\tLoss: 2.061411\n","Train Epoch: 9 [1360/1471 (87%)]\tLoss: 2.148502\n","Epoch 9 - Training: Average loss: 2.1252, Accuracy: 20.40%\n","Evaluation set: Average loss: 2.1110, Accuracy: 183/709 (25.81%), F1-score: 0.1187\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1471 (0%)]\tLoss: 2.196038\n","Train Epoch: 10 [240/1471 (22%)]\tLoss: 1.730090\n","Train Epoch: 10 [740/1471 (43%)]\tLoss: 2.076556\n","Train Epoch: 10 [810/1471 (65%)]\tLoss: 2.055228\n","Train Epoch: 10 [1360/1471 (87%)]\tLoss: 2.450794\n","Epoch 10 - Training: Average loss: 2.1948, Accuracy: 29.03%\n","Evaluation set: Average loss: 2.3796, Accuracy: 130/709 (18.34%), F1-score: 0.0733\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 11 [0/1471 (0%)]\tLoss: 2.545678\n","Train Epoch: 11 [310/1471 (22%)]\tLoss: 2.523896\n","Train Epoch: 11 [520/1471 (43%)]\tLoss: 2.207723\n","Train Epoch: 11 [1020/1471 (65%)]\tLoss: 2.109451\n","Train Epoch: 11 [2080/1471 (87%)]\tLoss: 2.252051\n","Epoch 11 - Training: Average loss: 2.1864, Accuracy: 25.60%\n","Evaluation set: Average loss: 2.1519, Accuracy: 140/709 (19.75%), F1-score: 0.1182\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 12 [0/1471 (0%)]\tLoss: 1.783630\n","Train Epoch: 12 [360/1471 (22%)]\tLoss: 2.169156\n","Train Epoch: 12 [660/1471 (43%)]\tLoss: 1.847282\n","Train Epoch: 12 [780/1471 (65%)]\tLoss: 2.281693\n","Train Epoch: 12 [1080/1471 (87%)]\tLoss: 2.518391\n","Epoch 12 - Training: Average loss: 2.0138, Accuracy: 26.85%\n","Evaluation set: Average loss: 2.2044, Accuracy: 193/709 (27.22%), F1-score: 0.1107\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 13 [0/1471 (0%)]\tLoss: 2.025291\n","Train Epoch: 13 [320/1471 (22%)]\tLoss: 2.133454\n","Train Epoch: 13 [700/1471 (43%)]\tLoss: 2.082261\n","Train Epoch: 13 [900/1471 (65%)]\tLoss: 1.974082\n","Train Epoch: 13 [1160/1471 (87%)]\tLoss: 1.937931\n","Epoch 13 - Training: Average loss: 2.1063, Accuracy: 30.07%\n","Evaluation set: Average loss: 2.1595, Accuracy: 193/709 (27.22%), F1-score: 0.1117\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 14 [0/1471 (0%)]\tLoss: 2.139859\n","Train Epoch: 14 [300/1471 (22%)]\tLoss: 1.997402\n","Train Epoch: 14 [500/1471 (43%)]\tLoss: 2.007406\n","Train Epoch: 14 [1110/1471 (65%)]\tLoss: 1.911577\n","Train Epoch: 14 [880/1471 (87%)]\tLoss: 1.793732\n","Epoch 14 - Training: Average loss: 2.0519, Accuracy: 31.49%\n","Evaluation set: Average loss: 2.1006, Accuracy: 185/709 (26.09%), F1-score: 0.1038\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 15 [0/1471 (0%)]\tLoss: 2.073124\n","Train Epoch: 15 [400/1471 (22%)]\tLoss: 1.985632\n","Train Epoch: 15 [700/1471 (43%)]\tLoss: 1.995072\n","Train Epoch: 15 [810/1471 (65%)]\tLoss: 1.792686\n","Train Epoch: 15 [1160/1471 (87%)]\tLoss: 2.004457\n","Epoch 15 - Training: Average loss: 2.0042, Accuracy: 30.86%\n","Evaluation set: Average loss: 2.0185, Accuracy: 194/709 (27.36%), F1-score: 0.1314\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1471 (0%)]\tLoss: 1.807267\n","Train Epoch: 16 [350/1471 (22%)]\tLoss: 1.672036\n","Train Epoch: 16 [660/1471 (43%)]\tLoss: 2.009023\n","Train Epoch: 16 [840/1471 (65%)]\tLoss: 1.761443\n","Train Epoch: 16 [1120/1471 (87%)]\tLoss: 2.165822\n","Epoch 16 - Training: Average loss: 1.9142, Accuracy: 34.84%\n","Evaluation set: Average loss: 2.0074, Accuracy: 179/709 (25.25%), F1-score: 0.1233\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1471 (0%)]\tLoss: 1.944570\n","Train Epoch: 17 [310/1471 (22%)]\tLoss: 1.859582\n","Train Epoch: 17 [640/1471 (43%)]\tLoss: 2.054407\n","Train Epoch: 17 [1050/1471 (65%)]\tLoss: 1.947079\n","Train Epoch: 17 [1480/1471 (87%)]\tLoss: 2.058875\n","Epoch 17 - Training: Average loss: 1.9091, Accuracy: 33.91%\n","Evaluation set: Average loss: 2.0142, Accuracy: 187/709 (26.38%), F1-score: 0.1356\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1471 (0%)]\tLoss: 1.702647\n","Train Epoch: 18 [330/1471 (22%)]\tLoss: 2.068386\n","Train Epoch: 18 [780/1471 (43%)]\tLoss: 1.756669\n","Train Epoch: 18 [1050/1471 (65%)]\tLoss: 1.836514\n","Train Epoch: 18 [1320/1471 (87%)]\tLoss: 1.993685\n","Epoch 18 - Training: Average loss: 1.8975, Accuracy: 33.87%\n","Evaluation set: Average loss: 2.0166, Accuracy: 166/709 (23.41%), F1-score: 0.1298\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 19 [0/1471 (0%)]\tLoss: 2.207551\n","Train Epoch: 19 [320/1471 (22%)]\tLoss: 2.039485\n","Train Epoch: 19 [560/1471 (43%)]\tLoss: 1.750924\n","Train Epoch: 19 [1170/1471 (65%)]\tLoss: 1.981036\n","Train Epoch: 19 [1480/1471 (87%)]\tLoss: 1.933995\n","Epoch 19 - Training: Average loss: 1.9462, Accuracy: 29.31%\n","Evaluation set: Average loss: 2.0013, Accuracy: 170/709 (23.98%), F1-score: 0.1314\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","Train Epoch: 20 [0/1471 (0%)]\tLoss: 1.668975\n","Train Epoch: 20 [370/1471 (22%)]\tLoss: 1.774800\n","Train Epoch: 20 [560/1471 (43%)]\tLoss: 2.226753\n","Train Epoch: 20 [750/1471 (65%)]\tLoss: 2.125156\n","Train Epoch: 20 [1440/1471 (87%)]\tLoss: 1.777350\n","Epoch 20 - Training: Average loss: 1.8832, Accuracy: 33.55%\n","Evaluation set: Average loss: 1.9740, Accuracy: 196/709 (27.64%), F1-score: 0.1507\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n"," #### Test Evaluation is starting for ['subject103' 'subject106'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.8677, Accuracy: 219/707 (30.98%), F1-score: 0.1706\n","\n","Outer Fold 4 is starting ...\n","Test subjects: ['subject101' 'subject104']\n","Train-Validation subjects: ['subject102' 'subject103' 'subject105' 'subject106' 'subject107'\n"," 'subject108']\n","Fold 1 is starting ...\n","Validation subjects : ['subject102' 'subject105']\n","Train subjects: ['subject103' 'subject106' 'subject107' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1426 (0%)]\tLoss: 8.558284\n","Train Epoch: 1 [240/1426 (22%)]\tLoss: 5.148421\n","Train Epoch: 1 [580/1426 (44%)]\tLoss: 4.070133\n","Train Epoch: 1 [780/1426 (67%)]\tLoss: 3.139795\n","Train Epoch: 1 [1520/1426 (89%)]\tLoss: 4.508760\n","Epoch 1 - Training: Average loss: 5.2842, Accuracy: 23.24%\n","Evaluation set: Average loss: 4.7179, Accuracy: 182/752 (24.20%), F1-score: 0.1073\n","\n","Epsilon Spent: 0.054, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1426 (0%)]\tLoss: 4.506814\n","Train Epoch: 2 [330/1426 (22%)]\tLoss: 4.951448\n","Train Epoch: 2 [760/1426 (44%)]\tLoss: 4.381931\n","Train Epoch: 2 [930/1426 (67%)]\tLoss: 3.750310\n","Train Epoch: 2 [1280/1426 (89%)]\tLoss: 3.689573\n","Epoch 2 - Training: Average loss: 4.1082, Accuracy: 23.96%\n","Evaluation set: Average loss: 3.5599, Accuracy: 154/752 (20.48%), F1-score: 0.1160\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1426 (0%)]\tLoss: 3.511554\n","Train Epoch: 3 [330/1426 (22%)]\tLoss: 2.870009\n","Train Epoch: 3 [700/1426 (44%)]\tLoss: 3.349334\n","Train Epoch: 3 [840/1426 (67%)]\tLoss: 2.811321\n","Train Epoch: 3 [1480/1426 (89%)]\tLoss: 3.290777\n","Epoch 3 - Training: Average loss: 3.0353, Accuracy: 29.21%\n","Evaluation set: Average loss: 3.1006, Accuracy: 143/752 (19.02%), F1-score: 0.0986\n","\n","Epsilon Spent: 0.089, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1426 (0%)]\tLoss: 2.382928\n","Train Epoch: 4 [250/1426 (22%)]\tLoss: 2.694260\n","Train Epoch: 4 [580/1426 (44%)]\tLoss: 3.312453\n","Train Epoch: 4 [930/1426 (67%)]\tLoss: 2.056477\n","Train Epoch: 4 [1080/1426 (89%)]\tLoss: 3.375354\n","Epoch 4 - Training: Average loss: 2.7609, Accuracy: 31.60%\n","Evaluation set: Average loss: 2.8670, Accuracy: 177/752 (23.54%), F1-score: 0.1402\n","\n","Epsilon Spent: 0.102, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1426 (0%)]\tLoss: 3.336290\n","Train Epoch: 5 [270/1426 (22%)]\tLoss: 3.093935\n","Train Epoch: 5 [740/1426 (44%)]\tLoss: 2.723779\n","Train Epoch: 5 [1020/1426 (67%)]\tLoss: 2.534895\n","Train Epoch: 5 [1400/1426 (89%)]\tLoss: 2.327675\n","Epoch 5 - Training: Average loss: 2.6427, Accuracy: 26.87%\n","Evaluation set: Average loss: 2.6758, Accuracy: 193/752 (25.66%), F1-score: 0.1213\n","\n","Epsilon Spent: 0.114, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1426 (0%)]\tLoss: 3.008531\n","Train Epoch: 6 [410/1426 (22%)]\tLoss: 2.387892\n","Train Epoch: 6 [540/1426 (44%)]\tLoss: 2.106211\n","Train Epoch: 6 [1080/1426 (67%)]\tLoss: 2.358424\n","Train Epoch: 6 [1080/1426 (89%)]\tLoss: 2.157646\n","Epoch 6 - Training: Average loss: 2.3736, Accuracy: 31.39%\n","Evaluation set: Average loss: 2.2778, Accuracy: 161/752 (21.41%), F1-score: 0.1432\n","\n","Epsilon Spent: 0.125, Noise_Scale: 10.0\n","Train Epoch: 7 [0/1426 (0%)]\tLoss: 1.920313\n","Train Epoch: 7 [370/1426 (22%)]\tLoss: 2.366417\n","Train Epoch: 7 [540/1426 (44%)]\tLoss: 2.028719\n","Train Epoch: 7 [780/1426 (67%)]\tLoss: 2.184257\n","Train Epoch: 7 [1040/1426 (89%)]\tLoss: 2.242710\n","Epoch 7 - Training: Average loss: 2.1596, Accuracy: 25.55%\n","Evaluation set: Average loss: 2.1725, Accuracy: 144/752 (19.15%), F1-score: 0.1187\n","\n","Epsilon Spent: 0.135, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1426 (0%)]\tLoss: 2.090162\n","Train Epoch: 8 [310/1426 (22%)]\tLoss: 2.350507\n","Train Epoch: 8 [600/1426 (44%)]\tLoss: 2.291697\n","Train Epoch: 8 [750/1426 (67%)]\tLoss: 1.998492\n","Train Epoch: 8 [840/1426 (89%)]\tLoss: 2.082853\n","Epoch 8 - Training: Average loss: 2.0334, Accuracy: 30.12%\n","Evaluation set: Average loss: 2.1217, Accuracy: 173/752 (23.01%), F1-score: 0.1350\n","\n","Epsilon Spent: 0.144, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1426 (0%)]\tLoss: 1.942307\n","Train Epoch: 9 [170/1426 (22%)]\tLoss: 1.852145\n","Train Epoch: 9 [560/1426 (44%)]\tLoss: 2.081342\n","Train Epoch: 9 [1140/1426 (67%)]\tLoss: 2.414577\n","Train Epoch: 9 [1240/1426 (89%)]\tLoss: 1.790393\n","Epoch 9 - Training: Average loss: 2.1416, Accuracy: 27.77%\n","Evaluation set: Average loss: 2.1718, Accuracy: 159/752 (21.14%), F1-score: 0.1100\n","\n","Epsilon Spent: 0.153, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1426 (0%)]\tLoss: 1.829834\n","Train Epoch: 10 [300/1426 (22%)]\tLoss: 2.186596\n","Train Epoch: 10 [600/1426 (44%)]\tLoss: 1.988418\n","Train Epoch: 10 [1140/1426 (67%)]\tLoss: 2.049979\n","Train Epoch: 10 [1440/1426 (89%)]\tLoss: 1.779453\n","Epoch 10 - Training: Average loss: 2.0187, Accuracy: 26.65%\n","Evaluation set: Average loss: 2.0732, Accuracy: 213/752 (28.32%), F1-score: 0.1653\n","\n","Epsilon Spent: 0.162, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1426 (0%)]\tLoss: 2.044460\n","Train Epoch: 11 [270/1426 (22%)]\tLoss: 2.434070\n","Train Epoch: 11 [560/1426 (44%)]\tLoss: 2.070409\n","Train Epoch: 11 [600/1426 (67%)]\tLoss: 1.712659\n","Train Epoch: 11 [1120/1426 (89%)]\tLoss: 1.831558\n","Epoch 11 - Training: Average loss: 1.9909, Accuracy: 34.48%\n","Evaluation set: Average loss: 2.1100, Accuracy: 230/752 (30.59%), F1-score: 0.1855\n","\n","Epsilon Spent: 0.17, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 12 [0/1426 (0%)]\tLoss: 1.804222\n","Train Epoch: 12 [390/1426 (22%)]\tLoss: 2.041988\n","Train Epoch: 12 [600/1426 (44%)]\tLoss: 2.107131\n","Train Epoch: 12 [1200/1426 (67%)]\tLoss: 1.987496\n","Train Epoch: 12 [1200/1426 (89%)]\tLoss: 2.134196\n","Epoch 12 - Training: Average loss: 1.9437, Accuracy: 34.35%\n","Evaluation set: Average loss: 2.1969, Accuracy: 213/752 (28.32%), F1-score: 0.1550\n","\n","Epsilon Spent: 0.177, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 13 [0/1426 (0%)]\tLoss: 2.136262\n","Train Epoch: 13 [330/1426 (22%)]\tLoss: 2.161645\n","Train Epoch: 13 [600/1426 (44%)]\tLoss: 2.113223\n","Train Epoch: 13 [990/1426 (67%)]\tLoss: 1.879845\n","Train Epoch: 13 [1200/1426 (89%)]\tLoss: 2.197783\n","Epoch 13 - Training: Average loss: 2.0660, Accuracy: 30.14%\n","Evaluation set: Average loss: 2.2253, Accuracy: 187/752 (24.87%), F1-score: 0.1476\n","\n","Epsilon Spent: 0.185, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 14 [0/1426 (0%)]\tLoss: 2.136356\n","Train Epoch: 14 [290/1426 (22%)]\tLoss: 2.123615\n","Train Epoch: 14 [580/1426 (44%)]\tLoss: 2.033902\n","Train Epoch: 14 [1050/1426 (67%)]\tLoss: 1.669846\n","Train Epoch: 14 [1200/1426 (89%)]\tLoss: 1.878220\n","Epoch 14 - Training: Average loss: 2.0271, Accuracy: 32.72%\n","Evaluation set: Average loss: 2.2532, Accuracy: 189/752 (25.13%), F1-score: 0.1335\n","\n","Epsilon Spent: 0.192, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 15 [0/1426 (0%)]\tLoss: 2.082741\n","Train Epoch: 15 [360/1426 (22%)]\tLoss: 1.828522\n","Train Epoch: 15 [560/1426 (44%)]\tLoss: 2.229657\n","Train Epoch: 15 [930/1426 (67%)]\tLoss: 1.739481\n","Train Epoch: 15 [1440/1426 (89%)]\tLoss: 2.147888\n","Epoch 15 - Training: Average loss: 2.0145, Accuracy: 33.38%\n","Evaluation set: Average loss: 2.2384, Accuracy: 185/752 (24.60%), F1-score: 0.1300\n","\n","Epsilon Spent: 0.199, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 16 [0/1426 (0%)]\tLoss: 1.765152\n","Train Epoch: 16 [290/1426 (22%)]\tLoss: 1.974610\n","Train Epoch: 16 [860/1426 (44%)]\tLoss: 2.056472\n","Train Epoch: 16 [900/1426 (67%)]\tLoss: 2.175111\n","Train Epoch: 16 [1240/1426 (89%)]\tLoss: 2.344476\n","Epoch 16 - Training: Average loss: 2.0274, Accuracy: 34.90%\n","Evaluation set: Average loss: 2.2122, Accuracy: 192/752 (25.53%), F1-score: 0.1352\n","\n","Epsilon Spent: 0.206, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n","Train Epoch: 17 [0/1426 (0%)]\tLoss: 2.264845\n","Train Epoch: 17 [400/1426 (22%)]\tLoss: 2.032902\n","Train Epoch: 17 [600/1426 (44%)]\tLoss: 1.957750\n","Train Epoch: 17 [810/1426 (67%)]\tLoss: 2.559541\n","Train Epoch: 17 [920/1426 (89%)]\tLoss: 1.757411\n","Epoch 17 - Training: Average loss: 1.9921, Accuracy: 35.27%\n","Evaluation set: Average loss: 2.1609, Accuracy: 207/752 (27.53%), F1-score: 0.1627\n","\n","Epsilon Spent: 0.212, Noise_Scale: 10.0\n","EarlyStopping counter: 7 out of 10\n","Train Epoch: 18 [0/1426 (0%)]\tLoss: 2.345284\n","Train Epoch: 18 [350/1426 (22%)]\tLoss: 2.153208\n","Train Epoch: 18 [500/1426 (44%)]\tLoss: 1.723248\n","Train Epoch: 18 [1200/1426 (67%)]\tLoss: 2.084629\n","Train Epoch: 18 [1080/1426 (89%)]\tLoss: 1.824945\n","Epoch 18 - Training: Average loss: 1.9699, Accuracy: 34.92%\n","Evaluation set: Average loss: 2.1508, Accuracy: 202/752 (26.86%), F1-score: 0.1641\n","\n","Epsilon Spent: 0.219, Noise_Scale: 10.0\n","EarlyStopping counter: 8 out of 10\n","Train Epoch: 19 [0/1426 (0%)]\tLoss: 1.663032\n","Train Epoch: 19 [320/1426 (22%)]\tLoss: 1.847459\n","Train Epoch: 19 [560/1426 (44%)]\tLoss: 2.058216\n","Train Epoch: 19 [750/1426 (67%)]\tLoss: 1.732490\n","Train Epoch: 19 [1200/1426 (89%)]\tLoss: 1.960847\n","Epoch 19 - Training: Average loss: 1.9083, Accuracy: 36.40%\n","Evaluation set: Average loss: 2.1498, Accuracy: 201/752 (26.73%), F1-score: 0.1612\n","\n","Epsilon Spent: 0.225, Noise_Scale: 10.0\n","EarlyStopping counter: 9 out of 10\n","Train Epoch: 20 [0/1426 (0%)]\tLoss: 1.744219\n","Train Epoch: 20 [380/1426 (22%)]\tLoss: 1.703757\n","Train Epoch: 20 [340/1426 (44%)]\tLoss: 1.979672\n","Train Epoch: 20 [960/1426 (67%)]\tLoss: 1.890380\n","Train Epoch: 20 [1520/1426 (89%)]\tLoss: 1.680697\n","Epoch 20 - Training: Average loss: 1.8998, Accuracy: 36.82%\n","Evaluation set: Average loss: 2.1448, Accuracy: 202/752 (26.86%), F1-score: 0.1622\n","\n","Epsilon Spent: 0.231, Noise_Scale: 10.0\n","EarlyStopping counter: 10 out of 10\n","Early stopping\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 2.1227, Accuracy: 193/709 (27.22%), F1-score: 0.1687\n","\n","Fold 2 is starting ...\n","Validation subjects : ['subject103' 'subject108']\n","Train subjects: ['subject102' 'subject105' 'subject106' 'subject107']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1466 (0%)]\tLoss: 9.523889\n","Train Epoch: 1 [330/1466 (22%)]\tLoss: 7.358198\n","Train Epoch: 1 [640/1466 (43%)]\tLoss: 4.464529\n","Train Epoch: 1 [690/1466 (65%)]\tLoss: 4.654994\n","Train Epoch: 1 [1400/1466 (87%)]\tLoss: 3.863255\n","Epoch 1 - Training: Average loss: 6.0763, Accuracy: 22.50%\n","Evaluation set: Average loss: 4.6257, Accuracy: 254/712 (35.67%), F1-score: 0.1741\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1466 (0%)]\tLoss: 4.893763\n","Train Epoch: 2 [330/1466 (22%)]\tLoss: 4.016230\n","Train Epoch: 2 [560/1466 (43%)]\tLoss: 4.189834\n","Train Epoch: 2 [840/1466 (65%)]\tLoss: 3.182706\n","Train Epoch: 2 [1000/1466 (87%)]\tLoss: 4.183959\n","Epoch 2 - Training: Average loss: 4.2657, Accuracy: 33.69%\n","Evaluation set: Average loss: 3.5630, Accuracy: 227/712 (31.88%), F1-score: 0.1501\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1466 (0%)]\tLoss: 4.021269\n","Train Epoch: 3 [430/1466 (22%)]\tLoss: 4.073126\n","Train Epoch: 3 [540/1466 (43%)]\tLoss: 3.017301\n","Train Epoch: 3 [1110/1466 (65%)]\tLoss: 2.842145\n","Train Epoch: 3 [920/1466 (87%)]\tLoss: 1.730503\n","Epoch 3 - Training: Average loss: 3.0582, Accuracy: 29.94%\n","Evaluation set: Average loss: 2.2506, Accuracy: 245/712 (34.41%), F1-score: 0.1636\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1466 (0%)]\tLoss: 2.411093\n","Train Epoch: 4 [320/1466 (22%)]\tLoss: 2.254106\n","Train Epoch: 4 [620/1466 (43%)]\tLoss: 2.235253\n","Train Epoch: 4 [1080/1466 (65%)]\tLoss: 1.940807\n","Train Epoch: 4 [1560/1466 (87%)]\tLoss: 2.041632\n","Epoch 4 - Training: Average loss: 2.1307, Accuracy: 26.22%\n","Evaluation set: Average loss: 1.9780, Accuracy: 165/712 (23.17%), F1-score: 0.1526\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1466 (0%)]\tLoss: 1.891247\n","Train Epoch: 5 [300/1466 (22%)]\tLoss: 2.085256\n","Train Epoch: 5 [560/1466 (43%)]\tLoss: 2.018336\n","Train Epoch: 5 [1080/1466 (65%)]\tLoss: 2.161884\n","Train Epoch: 5 [1640/1466 (87%)]\tLoss: 2.038394\n","Epoch 5 - Training: Average loss: 2.0341, Accuracy: 21.54%\n","Evaluation set: Average loss: 2.0039, Accuracy: 190/712 (26.69%), F1-score: 0.1445\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 6 [0/1466 (0%)]\tLoss: 2.486967\n","Train Epoch: 6 [310/1466 (22%)]\tLoss: 2.408545\n","Train Epoch: 6 [500/1466 (43%)]\tLoss: 2.044832\n","Train Epoch: 6 [1050/1466 (65%)]\tLoss: 2.083258\n","Train Epoch: 6 [1720/1466 (87%)]\tLoss: 2.064611\n","Epoch 6 - Training: Average loss: 2.0475, Accuracy: 33.68%\n","Evaluation set: Average loss: 2.0417, Accuracy: 233/712 (32.72%), F1-score: 0.1927\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 7 [0/1466 (0%)]\tLoss: 2.141006\n","Train Epoch: 7 [380/1466 (22%)]\tLoss: 1.993666\n","Train Epoch: 7 [420/1466 (43%)]\tLoss: 2.179121\n","Train Epoch: 7 [1110/1466 (65%)]\tLoss: 1.944229\n","Train Epoch: 7 [1120/1466 (87%)]\tLoss: 2.149704\n","Epoch 7 - Training: Average loss: 1.9792, Accuracy: 31.96%\n","Evaluation set: Average loss: 1.9495, Accuracy: 262/712 (36.80%), F1-score: 0.1927\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1466 (0%)]\tLoss: 2.019131\n","Train Epoch: 8 [330/1466 (22%)]\tLoss: 1.888030\n","Train Epoch: 8 [660/1466 (43%)]\tLoss: 1.664668\n","Train Epoch: 8 [810/1466 (65%)]\tLoss: 2.290588\n","Train Epoch: 8 [1280/1466 (87%)]\tLoss: 2.295291\n","Epoch 8 - Training: Average loss: 1.9459, Accuracy: 32.65%\n","Evaluation set: Average loss: 1.9679, Accuracy: 222/712 (31.18%), F1-score: 0.1750\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 9 [0/1466 (0%)]\tLoss: 2.315664\n","Train Epoch: 9 [270/1466 (22%)]\tLoss: 1.694729\n","Train Epoch: 9 [780/1466 (43%)]\tLoss: 1.900780\n","Train Epoch: 9 [990/1466 (65%)]\tLoss: 2.147347\n","Train Epoch: 9 [1240/1466 (87%)]\tLoss: 1.950767\n","Epoch 9 - Training: Average loss: 1.9923, Accuracy: 31.36%\n","Evaluation set: Average loss: 2.0403, Accuracy: 238/712 (33.43%), F1-score: 0.1727\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 10 [0/1466 (0%)]\tLoss: 1.590059\n","Train Epoch: 10 [330/1466 (22%)]\tLoss: 1.782188\n","Train Epoch: 10 [700/1466 (43%)]\tLoss: 1.936255\n","Train Epoch: 10 [1020/1466 (65%)]\tLoss: 2.042551\n","Train Epoch: 10 [1200/1466 (87%)]\tLoss: 2.115071\n","Epoch 10 - Training: Average loss: 1.9730, Accuracy: 32.95%\n","Evaluation set: Average loss: 2.0748, Accuracy: 232/712 (32.58%), F1-score: 0.1682\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 11 [0/1466 (0%)]\tLoss: 1.987007\n","Train Epoch: 11 [280/1466 (22%)]\tLoss: 1.682159\n","Train Epoch: 11 [580/1466 (43%)]\tLoss: 2.001864\n","Train Epoch: 11 [900/1466 (65%)]\tLoss: 2.033677\n","Train Epoch: 11 [1280/1466 (87%)]\tLoss: 1.719373\n","Epoch 11 - Training: Average loss: 2.0245, Accuracy: 31.64%\n","Evaluation set: Average loss: 1.9812, Accuracy: 254/712 (35.67%), F1-score: 0.2133\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 12 [0/1466 (0%)]\tLoss: 1.827723\n","Train Epoch: 12 [420/1466 (22%)]\tLoss: 1.885726\n","Train Epoch: 12 [560/1466 (43%)]\tLoss: 1.685517\n","Train Epoch: 12 [1200/1466 (65%)]\tLoss: 1.875986\n","Train Epoch: 12 [1600/1466 (87%)]\tLoss: 1.913239\n","Epoch 12 - Training: Average loss: 1.9523, Accuracy: 35.52%\n","Evaluation set: Average loss: 1.9386, Accuracy: 274/712 (38.48%), F1-score: 0.2435\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","Train Epoch: 13 [0/1466 (0%)]\tLoss: 2.142598\n","Train Epoch: 13 [300/1466 (22%)]\tLoss: 1.918387\n","Train Epoch: 13 [940/1466 (43%)]\tLoss: 2.061063\n","Train Epoch: 13 [1050/1466 (65%)]\tLoss: 1.690317\n","Train Epoch: 13 [1240/1466 (87%)]\tLoss: 2.021486\n","Epoch 13 - Training: Average loss: 1.9042, Accuracy: 38.37%\n","Evaluation set: Average loss: 1.9211, Accuracy: 276/712 (38.76%), F1-score: 0.2406\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1466 (0%)]\tLoss: 2.125564\n","Train Epoch: 14 [290/1466 (22%)]\tLoss: 1.945222\n","Train Epoch: 14 [620/1466 (43%)]\tLoss: 1.675855\n","Train Epoch: 14 [870/1466 (65%)]\tLoss: 2.116450\n","Train Epoch: 14 [1280/1466 (87%)]\tLoss: 2.061073\n","Epoch 14 - Training: Average loss: 1.9277, Accuracy: 34.77%\n","Evaluation set: Average loss: 1.9163, Accuracy: 271/712 (38.06%), F1-score: 0.2275\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1466 (0%)]\tLoss: 1.882538\n","Train Epoch: 15 [360/1466 (22%)]\tLoss: 1.653580\n","Train Epoch: 15 [560/1466 (43%)]\tLoss: 1.864761\n","Train Epoch: 15 [810/1466 (65%)]\tLoss: 1.709944\n","Train Epoch: 15 [1480/1466 (87%)]\tLoss: 1.760650\n","Epoch 15 - Training: Average loss: 1.8552, Accuracy: 36.53%\n","Evaluation set: Average loss: 1.8943, Accuracy: 263/712 (36.94%), F1-score: 0.2021\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","Train Epoch: 16 [0/1466 (0%)]\tLoss: 2.183527\n","Train Epoch: 16 [320/1466 (22%)]\tLoss: 1.667051\n","Train Epoch: 16 [800/1466 (43%)]\tLoss: 1.964535\n","Train Epoch: 16 [660/1466 (65%)]\tLoss: 1.586803\n","Train Epoch: 16 [1240/1466 (87%)]\tLoss: 1.848565\n","Epoch 16 - Training: Average loss: 1.8516, Accuracy: 34.68%\n","Evaluation set: Average loss: 1.8840, Accuracy: 255/712 (35.81%), F1-score: 0.2085\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","Train Epoch: 17 [0/1466 (0%)]\tLoss: 1.907620\n","Train Epoch: 17 [310/1466 (22%)]\tLoss: 1.720834\n","Train Epoch: 17 [620/1466 (43%)]\tLoss: 1.855898\n","Train Epoch: 17 [960/1466 (65%)]\tLoss: 1.777528\n","Train Epoch: 17 [1520/1466 (87%)]\tLoss: 1.788639\n","Epoch 17 - Training: Average loss: 1.8632, Accuracy: 33.94%\n","Evaluation set: Average loss: 1.9161, Accuracy: 239/712 (33.57%), F1-score: 0.1706\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 18 [0/1466 (0%)]\tLoss: 1.696214\n","Train Epoch: 18 [340/1466 (22%)]\tLoss: 1.872986\n","Train Epoch: 18 [380/1466 (43%)]\tLoss: 1.828711\n","Train Epoch: 18 [1020/1466 (65%)]\tLoss: 2.080795\n","Train Epoch: 18 [1360/1466 (87%)]\tLoss: 1.877618\n","Epoch 18 - Training: Average loss: 1.9050, Accuracy: 33.94%\n","Evaluation set: Average loss: 1.9092, Accuracy: 250/712 (35.11%), F1-score: 0.1696\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 19 [0/1466 (0%)]\tLoss: 1.836608\n","Train Epoch: 19 [310/1466 (22%)]\tLoss: 2.143175\n","Train Epoch: 19 [680/1466 (43%)]\tLoss: 1.760782\n","Train Epoch: 19 [1140/1466 (65%)]\tLoss: 1.668996\n","Train Epoch: 19 [1240/1466 (87%)]\tLoss: 1.905948\n","Epoch 19 - Training: Average loss: 1.8742, Accuracy: 32.71%\n","Evaluation set: Average loss: 1.9307, Accuracy: 236/712 (33.15%), F1-score: 0.1725\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 20 [0/1466 (0%)]\tLoss: 2.098038\n","Train Epoch: 20 [230/1466 (22%)]\tLoss: 1.955923\n","Train Epoch: 20 [800/1466 (43%)]\tLoss: 1.822149\n","Train Epoch: 20 [1350/1466 (65%)]\tLoss: 1.746972\n","Train Epoch: 20 [1080/1466 (87%)]\tLoss: 2.216668\n","Epoch 20 - Training: Average loss: 1.8417, Accuracy: 35.25%\n","Evaluation set: Average loss: 1.9161, Accuracy: 244/712 (34.27%), F1-score: 0.1962\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.9668, Accuracy: 248/709 (34.98%), F1-score: 0.2176\n","\n","Fold 3 is starting ...\n","Validation subjects : ['subject106' 'subject107']\n","Train subjects: ['subject102' 'subject103' 'subject105' 'subject108']\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Train Epoch: 1 [0/1464 (0%)]\tLoss: 10.417626\n","Train Epoch: 1 [340/1464 (22%)]\tLoss: 7.374006\n","Train Epoch: 1 [360/1464 (43%)]\tLoss: 11.279621\n","Train Epoch: 1 [660/1464 (65%)]\tLoss: 7.705981\n","Train Epoch: 1 [1160/1464 (87%)]\tLoss: 8.153136\n","Epoch 1 - Training: Average loss: 8.5263, Accuracy: 17.94%\n","Evaluation set: Average loss: 6.7295, Accuracy: 112/714 (15.69%), F1-score: 0.0915\n","\n","Epsilon Spent: 0.053, Noise_Scale: 10.0\n","Train Epoch: 2 [0/1464 (0%)]\tLoss: 5.850788\n","Train Epoch: 2 [280/1464 (22%)]\tLoss: 7.768642\n","Train Epoch: 2 [700/1464 (43%)]\tLoss: 4.879311\n","Train Epoch: 2 [900/1464 (65%)]\tLoss: 5.730858\n","Train Epoch: 2 [1440/1464 (87%)]\tLoss: 5.852603\n","Epoch 2 - Training: Average loss: 5.4159, Accuracy: 14.23%\n","Evaluation set: Average loss: 4.7527, Accuracy: 84/714 (11.76%), F1-score: 0.0643\n","\n","Epsilon Spent: 0.073, Noise_Scale: 10.0\n","Train Epoch: 3 [0/1464 (0%)]\tLoss: 4.129768\n","Train Epoch: 3 [250/1464 (22%)]\tLoss: 3.812306\n","Train Epoch: 3 [580/1464 (43%)]\tLoss: 2.872992\n","Train Epoch: 3 [930/1464 (65%)]\tLoss: 4.721138\n","Train Epoch: 3 [1200/1464 (87%)]\tLoss: 2.981153\n","Epoch 3 - Training: Average loss: 3.9461, Accuracy: 17.33%\n","Evaluation set: Average loss: 3.4163, Accuracy: 131/714 (18.35%), F1-score: 0.0943\n","\n","Epsilon Spent: 0.088, Noise_Scale: 10.0\n","Train Epoch: 4 [0/1464 (0%)]\tLoss: 4.394393\n","Train Epoch: 4 [320/1464 (22%)]\tLoss: 2.854069\n","Train Epoch: 4 [800/1464 (43%)]\tLoss: 2.914053\n","Train Epoch: 4 [990/1464 (65%)]\tLoss: 2.815521\n","Train Epoch: 4 [1080/1464 (87%)]\tLoss: 2.783186\n","Epoch 4 - Training: Average loss: 3.0135, Accuracy: 11.08%\n","Evaluation set: Average loss: 2.6731, Accuracy: 132/714 (18.49%), F1-score: 0.0572\n","\n","Epsilon Spent: 0.101, Noise_Scale: 10.0\n","Train Epoch: 5 [0/1464 (0%)]\tLoss: 2.028447\n","Train Epoch: 5 [240/1464 (22%)]\tLoss: 2.897937\n","Train Epoch: 5 [800/1464 (43%)]\tLoss: 2.675780\n","Train Epoch: 5 [960/1464 (65%)]\tLoss: 2.171824\n","Train Epoch: 5 [1360/1464 (87%)]\tLoss: 2.433822\n","Epoch 5 - Training: Average loss: 2.4186, Accuracy: 16.80%\n","Evaluation set: Average loss: 2.2450, Accuracy: 141/714 (19.75%), F1-score: 0.1481\n","\n","Epsilon Spent: 0.113, Noise_Scale: 10.0\n","Train Epoch: 6 [0/1464 (0%)]\tLoss: 2.328041\n","Train Epoch: 6 [300/1464 (22%)]\tLoss: 2.326672\n","Train Epoch: 6 [500/1464 (43%)]\tLoss: 2.352659\n","Train Epoch: 6 [900/1464 (65%)]\tLoss: 1.936705\n","Train Epoch: 6 [1160/1464 (87%)]\tLoss: 2.182945\n","Epoch 6 - Training: Average loss: 2.3095, Accuracy: 16.87%\n","Evaluation set: Average loss: 2.2735, Accuracy: 161/714 (22.55%), F1-score: 0.1390\n","\n","Epsilon Spent: 0.124, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 7 [0/1464 (0%)]\tLoss: 2.466183\n","Train Epoch: 7 [240/1464 (22%)]\tLoss: 2.659391\n","Train Epoch: 7 [760/1464 (43%)]\tLoss: 2.298817\n","Train Epoch: 7 [1290/1464 (65%)]\tLoss: 2.155731\n","Train Epoch: 7 [1400/1464 (87%)]\tLoss: 1.923718\n","Epoch 7 - Training: Average loss: 2.2638, Accuracy: 13.64%\n","Evaluation set: Average loss: 2.0007, Accuracy: 147/714 (20.59%), F1-score: 0.1677\n","\n","Epsilon Spent: 0.134, Noise_Scale: 10.0\n","Train Epoch: 8 [0/1464 (0%)]\tLoss: 2.089352\n","Train Epoch: 8 [350/1464 (22%)]\tLoss: 1.970816\n","Train Epoch: 8 [680/1464 (43%)]\tLoss: 1.989888\n","Train Epoch: 8 [960/1464 (65%)]\tLoss: 2.050531\n","Train Epoch: 8 [1600/1464 (87%)]\tLoss: 1.931911\n","Epoch 8 - Training: Average loss: 1.9735, Accuracy: 26.12%\n","Evaluation set: Average loss: 1.8752, Accuracy: 266/714 (37.25%), F1-score: 0.2408\n","\n","Epsilon Spent: 0.143, Noise_Scale: 10.0\n","Train Epoch: 9 [0/1464 (0%)]\tLoss: 2.167564\n","Train Epoch: 9 [340/1464 (22%)]\tLoss: 2.224622\n","Train Epoch: 9 [700/1464 (43%)]\tLoss: 2.070749\n","Train Epoch: 9 [1020/1464 (65%)]\tLoss: 2.172086\n","Train Epoch: 9 [1040/1464 (87%)]\tLoss: 2.479649\n","Epoch 9 - Training: Average loss: 2.1050, Accuracy: 23.66%\n","Evaluation set: Average loss: 2.1297, Accuracy: 208/714 (29.13%), F1-score: 0.1429\n","\n","Epsilon Spent: 0.152, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 10 [0/1464 (0%)]\tLoss: 2.270055\n","Train Epoch: 10 [360/1464 (22%)]\tLoss: 2.215463\n","Train Epoch: 10 [740/1464 (43%)]\tLoss: 2.179227\n","Train Epoch: 10 [720/1464 (65%)]\tLoss: 1.805418\n","Train Epoch: 10 [1240/1464 (87%)]\tLoss: 2.009146\n","Epoch 10 - Training: Average loss: 2.0156, Accuracy: 31.56%\n","Evaluation set: Average loss: 1.7960, Accuracy: 248/714 (34.73%), F1-score: 0.2493\n","\n","Epsilon Spent: 0.16, Noise_Scale: 10.0\n","Train Epoch: 11 [0/1464 (0%)]\tLoss: 1.950645\n","Train Epoch: 11 [360/1464 (22%)]\tLoss: 2.088234\n","Train Epoch: 11 [680/1464 (43%)]\tLoss: 2.011860\n","Train Epoch: 11 [990/1464 (65%)]\tLoss: 2.042619\n","Train Epoch: 11 [1280/1464 (87%)]\tLoss: 1.937737\n","Epoch 11 - Training: Average loss: 1.9776, Accuracy: 25.33%\n","Evaluation set: Average loss: 1.7719, Accuracy: 260/714 (36.41%), F1-score: 0.2878\n","\n","Epsilon Spent: 0.168, Noise_Scale: 10.0\n","Train Epoch: 12 [0/1464 (0%)]\tLoss: 1.824005\n","Train Epoch: 12 [300/1464 (22%)]\tLoss: 2.019241\n","Train Epoch: 12 [800/1464 (43%)]\tLoss: 2.090541\n","Train Epoch: 12 [750/1464 (65%)]\tLoss: 2.329281\n","Train Epoch: 12 [1320/1464 (87%)]\tLoss: 2.201858\n","Epoch 12 - Training: Average loss: 1.9929, Accuracy: 28.01%\n","Evaluation set: Average loss: 1.9509, Accuracy: 147/714 (20.59%), F1-score: 0.1365\n","\n","Epsilon Spent: 0.175, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 13 [0/1464 (0%)]\tLoss: 2.094977\n","Train Epoch: 13 [330/1464 (22%)]\tLoss: 1.902267\n","Train Epoch: 13 [740/1464 (43%)]\tLoss: 1.635606\n","Train Epoch: 13 [1410/1464 (65%)]\tLoss: 1.782774\n","Train Epoch: 13 [1200/1464 (87%)]\tLoss: 1.558647\n","Epoch 13 - Training: Average loss: 1.8764, Accuracy: 27.27%\n","Evaluation set: Average loss: 1.6839, Accuracy: 305/714 (42.72%), F1-score: 0.3224\n","\n","Epsilon Spent: 0.183, Noise_Scale: 10.0\n","Train Epoch: 14 [0/1464 (0%)]\tLoss: 1.479338\n","Train Epoch: 14 [220/1464 (22%)]\tLoss: 2.013143\n","Train Epoch: 14 [640/1464 (43%)]\tLoss: 1.909910\n","Train Epoch: 14 [1140/1464 (65%)]\tLoss: 1.597292\n","Train Epoch: 14 [1080/1464 (87%)]\tLoss: 1.443570\n","Epoch 14 - Training: Average loss: 1.6939, Accuracy: 38.30%\n","Evaluation set: Average loss: 1.5583, Accuracy: 319/714 (44.68%), F1-score: 0.3472\n","\n","Epsilon Spent: 0.19, Noise_Scale: 10.0\n","Train Epoch: 15 [0/1464 (0%)]\tLoss: 1.602004\n","Train Epoch: 15 [280/1464 (22%)]\tLoss: 1.788806\n","Train Epoch: 15 [500/1464 (43%)]\tLoss: 1.672636\n","Train Epoch: 15 [1050/1464 (65%)]\tLoss: 1.923149\n","Train Epoch: 15 [1080/1464 (87%)]\tLoss: 1.604397\n","Epoch 15 - Training: Average loss: 1.7396, Accuracy: 36.62%\n","Evaluation set: Average loss: 1.7144, Accuracy: 213/714 (29.83%), F1-score: 0.1887\n","\n","Epsilon Spent: 0.197, Noise_Scale: 10.0\n","EarlyStopping counter: 1 out of 10\n","Train Epoch: 16 [0/1464 (0%)]\tLoss: 1.825521\n","Train Epoch: 16 [270/1464 (22%)]\tLoss: 2.154669\n","Train Epoch: 16 [600/1464 (43%)]\tLoss: 1.631426\n","Train Epoch: 16 [1050/1464 (65%)]\tLoss: 1.706973\n","Train Epoch: 16 [1520/1464 (87%)]\tLoss: 1.799949\n","Epoch 16 - Training: Average loss: 1.7583, Accuracy: 33.08%\n","Evaluation set: Average loss: 1.6095, Accuracy: 291/714 (40.76%), F1-score: 0.2787\n","\n","Epsilon Spent: 0.203, Noise_Scale: 10.0\n","EarlyStopping counter: 2 out of 10\n","Train Epoch: 17 [0/1464 (0%)]\tLoss: 1.613720\n","Train Epoch: 17 [450/1464 (22%)]\tLoss: 1.916072\n","Train Epoch: 17 [640/1464 (43%)]\tLoss: 1.446212\n","Train Epoch: 17 [840/1464 (65%)]\tLoss: 1.615185\n","Train Epoch: 17 [1600/1464 (87%)]\tLoss: 1.794372\n","Epoch 17 - Training: Average loss: 1.7409, Accuracy: 37.71%\n","Evaluation set: Average loss: 1.7108, Accuracy: 280/714 (39.22%), F1-score: 0.2874\n","\n","Epsilon Spent: 0.21, Noise_Scale: 10.0\n","EarlyStopping counter: 3 out of 10\n","Train Epoch: 18 [0/1464 (0%)]\tLoss: 1.945198\n","Train Epoch: 18 [380/1464 (22%)]\tLoss: 1.485791\n","Train Epoch: 18 [620/1464 (43%)]\tLoss: 2.041186\n","Train Epoch: 18 [1080/1464 (65%)]\tLoss: 1.659674\n","Train Epoch: 18 [1160/1464 (87%)]\tLoss: 1.794271\n","Epoch 18 - Training: Average loss: 1.7670, Accuracy: 37.58%\n","Evaluation set: Average loss: 1.7247, Accuracy: 269/714 (37.68%), F1-score: 0.2769\n","\n","Epsilon Spent: 0.216, Noise_Scale: 10.0\n","EarlyStopping counter: 4 out of 10\n","Train Epoch: 19 [0/1464 (0%)]\tLoss: 1.814665\n","Train Epoch: 19 [360/1464 (22%)]\tLoss: 1.660931\n","Train Epoch: 19 [480/1464 (43%)]\tLoss: 1.499514\n","Train Epoch: 19 [720/1464 (65%)]\tLoss: 2.010097\n","Train Epoch: 19 [1520/1464 (87%)]\tLoss: 1.923176\n","Epoch 19 - Training: Average loss: 1.6906, Accuracy: 41.99%\n","Evaluation set: Average loss: 1.7062, Accuracy: 264/714 (36.97%), F1-score: 0.2650\n","\n","Epsilon Spent: 0.222, Noise_Scale: 10.0\n","EarlyStopping counter: 5 out of 10\n","Train Epoch: 20 [0/1464 (0%)]\tLoss: 1.803804\n","Train Epoch: 20 [310/1464 (22%)]\tLoss: 1.275593\n","Train Epoch: 20 [760/1464 (43%)]\tLoss: 1.826290\n","Train Epoch: 20 [1020/1464 (65%)]\tLoss: 1.564877\n","Train Epoch: 20 [1240/1464 (87%)]\tLoss: 1.799224\n","Epoch 20 - Training: Average loss: 1.7100, Accuracy: 38.78%\n","Evaluation set: Average loss: 1.6773, Accuracy: 271/714 (37.96%), F1-score: 0.2724\n","\n","Epsilon Spent: 0.228, Noise_Scale: 10.0\n","EarlyStopping counter: 6 out of 10\n"," #### Test Evaluation is starting for ['subject101' 'subject104'] #### \n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/OxWearables/ssl-wearables/zipball/main\" to /root/.cache/torch/hub/main.zip\n"]},{"output_type":"stream","name":"stdout","text":["131 Weights loaded\n","Evaluation set: Average loss: 1.7818, Accuracy: 270/709 (38.08%), F1-score: 0.3065\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tasO2_z5oEPR"},"execution_count":null,"outputs":[]}]}